{
    "version": "https://jsonfeed.org/version/1",
    "title": "Keep Moving • All posts by \"ai\" category",
    "description": "🌸学习笔记🌸",
    "home_page_url": "http://qianqiu-cell.github.io",
    "items": [
        {
            "id": "http://qianqiu-cell.github.io/2024/07/23/AI/Prompt_engineering/",
            "url": "http://qianqiu-cell.github.io/2024/07/23/AI/Prompt_engineering/",
            "title": "大模型提示词工程（Prompt Engineering）",
            "date_published": "2024-07-22T16:00:00.000Z",
            "content_html": "<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL3dzeWFkYy9nZW5lcmF0aXZlLWFpLWZvci1iZWdpbm5lcnM=\">https://github.com/wsyadc/generative-ai-for-beginners</span></p>\n<h1 id=\"一-什么是提示词工程\"><a class=\"markdownIt-Anchor\" href=\"#一-什么是提示词工程\">#</a> 一、什么是提示词工程</h1>\n<p>  提示工程被定义为设计和优化文本输入（提示）以提供一致且高质量响应（完成）的过程，以实现特定的应用目标和模型。提示工程是创建将产生所需结果的提示的过程。 提示工程不仅仅是编写文本提示。提示工程不是一门工程学科，它更像是一组可以应用以获得所需结果的技术。我们可以将其视为一个两步过程：</p>\n<ul>\n<li>为特定模型和目标设计初始提示</li>\n<li>迭代地优化提示以提高响应质量</li>\n</ul>\n<p>  这必然是一个需要用户直觉和努力的试错过程，以获得最佳结果。那么，为什么这很重要？要回答这个问题，我们首先需要理解三个概念：</p>\n<ul>\n<li>Tokenization = 模型如何 “看到” 提示</li>\n<li>Base LLMs = 基础模型如何 “处理” 提示</li>\n<li>Instruction-Tuned LLMs = 模型现在如何看到 “任务”</li>\n</ul>\n<h1 id=\"二-为什么我们需要提示词工程\"><a class=\"markdownIt-Anchor\" href=\"#二-为什么我们需要提示词工程\">#</a> 二、为什么我们需要提示词工程</h1>\n<p>  现在我们知道了 LLMs 如何处理提示，让我们谈谈为什么我们需要提示工程。 答案在于，当前的 LLMs 的算法也有许多挑战，如果不及时优化，就很难实现 “可靠且一致的补全”。 例如：</p>\n<ul>\n<li>\n<p>== 模型响应是随机的。== 相同的提示可能会针对不同的模型或模型版本产生不同的响应。 甚至可能在不同时间使用相同模型产生不同的结果。 提示工程技术可以通过提供更好帮助我们最大限度地减少这些变化所带来的影响。</p>\n</li>\n<li>\n<p>== 模型可以产生幻觉响应。== 模型是使用大型但有限数据集进行预训练的，这意味着它们缺乏有关训练范围之外的概念的知识。 因此，它们可能会产生不准确、虚构或与已知事实直接矛盾的完成结果。 提示工程技术可以帮助用户识别和减轻幻觉，例如通过向人工智能询问出处或推理过程。</p>\n</li>\n<li>\n<p>== 模型功能会有所不同。 == 较新的模型或模型迭代将具有更丰富的功能，但也会带来独特的怪癖以及成本和复杂性方面的平衡。 提示工程可以帮助我们开发最佳实践和工作流程，以可扩展和无缝的方式消除差异并适应特定于模型的要求。</p>\n</li>\n</ul>\n<h1 id=\"三-提示工程的技巧\"><a class=\"markdownIt-Anchor\" href=\"#三-提示工程的技巧\">#</a> 三、提示工程的技巧</h1>\n<p>  简单提示的局限性：简单提示可能无法得到你想要的结果，原因如下：（1）大话题；（2）没有限定输出格式。我们可以使用一些基本技巧来提示 LLM。</p>\n<h2 id=\"31-zero-shot-prompting-零样本提示\"><a class=\"markdownIt-Anchor\" href=\"#31-zero-shot-prompting-零样本提示\">#</a> 3.1 Zero-shot prompting （零样本提示）</h2>\n<p>  这种提示风格非常简单，它只有一个提示。当你开始学习 LLM 时，可能就会用到这种方法。下面是一个例子：</p>\n<ul>\n<li>Prompt: “What is Algebra?”</li>\n<li>Answer: “Algebra is a branch of mathematics that studies mathematical symbols and the rules for manipulating these symbols.”</li>\n</ul>\n<h2 id=\"32-few-shot-prompting-少样本提示\"><a class=\"markdownIt-Anchor\" href=\"#32-few-shot-prompting-少样本提示\">#</a> 3.2 Few-shot prompting （少样本提示）</h2>\n<p>  这种提示方式通过在提出请求的同时提供一些示例来帮助模型。它由单个提示和附加的特定任务数据组成。下面是一个例子：</p>\n<ul>\n<li>Prompt: &quot;以莎士比亚的风格写一首诗。下面是一些莎士比亚十四行诗的例子：十四行诗第 18 首：&quot; 我要把你比作夏日吗？你更可爱，更有节制…' 第 116 首十四行诗：&quot; 让我不要为真正心灵的结合设置障碍。爱不是爱，当它发现改变时就会改变…' 十四行诗第 132 首：“我爱你的眼睛，它们怜悯我，知道你的心在折磨我，对我不屑一顾… 现在，请写一首关于月亮之美的十四行诗。”</li>\n<li>Answer：“在天空中，月亮闪烁着柔和的光芒，散发着温柔的光辉，…”</li>\n</ul>\n<p>  示例为 LLM 提供了所需输出的背景、格式或风格。它们有助于模型理解具体任务，并生成更准确、更相关的回复。</p>\n<h2 id=\"33-chain-of-thought-cot-思维链\"><a class=\"markdownIt-Anchor\" href=\"#33-chain-of-thought-cot-思维链\">#</a> 3.3 Chain-of-thought （CoT, 思维链）</h2>\n<p>  链式思维是一种非常有趣的技术，因为它涉及让大型语言模型（LLM）经过一系列步骤。这个想法是以一种方式指导 LLM，使其理解如何完成某项任务。请考虑以下带有和不带链式思维的示例：</p>\n<ul>\n<li>Prompt: “Alice has 5 apples, throws 3 apples, gives 2 to Bob and Bob gives one back, how many apples does Alice have?”</li>\n<li>Answer: 5</li>\n</ul>\n<p>  LLM 给出的答案为 5，这是不正确的。 根据计算结果 (5 -3 -2 + 1 = 1)，正确答案是 1 个苹果。</p>\n<p>  那么我们怎样才能教 LLM 正确地做到这一点呢？让我们尝试一下思维链。 应用思维链意味着：</p>\n<p>  给 LLM 一个类似的例子。展示计算结果，以及如何正确计算。提供原始提示。</p>\n<ul>\n<li>Prompt: “Lisa has 7 apples, throws 1 apple, gives 4 apples to Bart and Bart gives one back: 7 -1 = 6 6 -4 = 2 2 +1 = 3<br>\nAlice has 5 apples, throws 3 apples, gives 2 to Bob and Bob gives one back, how many apples does Alice have?”</li>\n<li>Answer: 1</li>\n</ul>\n<p>  请注意我们如何用另一个示例、计算和原始提示编写更长的提示，然后得出正确答案 1。正如您所看到的，思维链是一种非常强大的技术。</p>\n<p>  其他更加丰富的 CoT，如零样本思维链，自洽性等可以参考<span class=\"exturl\" data-url=\"aHR0cHM6Ly9wcm9tcHRkZXYuYWkvemgtSGFucy9kb2NzL2ludGVybWVkaWF0ZS9zZWxmX2NvbnNpc3RlbmN5\"> https://promptdev.ai/zh-Hans/docs/intermediate/self_consistency</span>。</p>\n<h2 id=\"34-generated-knowledge-知识生成\"><a class=\"markdownIt-Anchor\" href=\"#34-generated-knowledge-知识生成\">#</a> 3.4 Generated knowledge （知识生成）</h2>\n<p>  生成的知识方法（Generated Knowledge Approach）1 要求 LLM 在生成响应之前生成与问题相关的可能有用的信息。该方法由两个中间步骤组成，即<mark>知识生成和知识集成</mark>。</p>\n<p><img data-src=\"/images/AI/Prompt_engineering/3.4.1.png\" alt=\"\"></p>\n<p>（1）知识生成</p>\n<p>  在知识生成步骤中，要求 LLM 生成有关问题的一组事实。大语言模型将以 few-shot 方式进行提示，如下所示。使用相同提示生成 M 个不同的完成。</p>\n<p><img data-src=\"/images/AI/Prompt_engineering/3.4.2.png\" alt=\"\"></p>\n<p>（2）知识集成</p>\n<p>  接下来，我们生成 “知识增强” 问题，并用它们提示 LLM 获得最终答案。最好的理解方法是通过一个例子来说明。</p>\n<p>  假设我们正在尝试回答问题 “大多数袋鼠有 <mask> 肢体”。假设在知识生成步骤中，我们生成了 2 个知识（M=2）：</p>\n<ul>\n<li>\n<p>知识 1：“袋鼠是生活在澳大利亚的有袋动物。”</p>\n</li>\n<li>\n<p>知识 2：“袋鼠是有 5 条肢体的有袋动物。”</p>\n</li>\n</ul>\n<p>  现在，我们将每个知识与问题连接起来，生成知识增强的问题：</p>\n<ul>\n<li>\n<p>知识增强问题 1：“大多数袋鼠有 <mask> 肢体。袋鼠是生活在澳大利亚的有袋动物。”</p>\n</li>\n<li>\n<p>知识增强问题 2：“大多数袋鼠有 <mask> 肢体。袋鼠是有 5 条肢体的有袋动物。”</p>\n</li>\n</ul>\n<p>  然后，我们用这些知识增强的问题提示 LLM，并获得最终答案的提案：</p>\n<ul>\n<li>\n<p>答案 1：“4”</p>\n</li>\n<li>\n<p>答案 2：“5”</p>\n</li>\n</ul>\n<p>  我们选择概率最高的答案作为最终答案。最高概率可能是答案令牌的 softmax 概率，或答案令牌的对数概率。</p>\n<h2 id=\"35-least-to-most-ltm-从少到多\"><a class=\"markdownIt-Anchor\" href=\"#35-least-to-most-ltm-从少到多\">#</a> 3.5 Least to Most （LtM, 从少到多）</h2>\n<p>  从最少到最多提示 (LtM) 1 使 CoT 提示更进一步，首先将问题分解为子问题，然后解决每个问题。这是一种受现实世界儿童教育策略启发的技术。</p>\n<p>  与 CoT 提示一样，要解决的问题被分解为一组相互构建的子问题。第二步，将这些子问题一一解决。与思维链相反，先前子问题的解决方案被输入到尝试解决下一个问题的提示中。</p>\n<p><img data-src=\"/images/AI/Prompt_engineering/3.5.1.png\" alt=\"\"></p>\n<h2 id=\"36-self-refine-critique-the-results-自我完善质疑结果\"><a class=\"markdownIt-Anchor\" href=\"#36-self-refine-critique-the-results-自我完善质疑结果\">#</a> 3.6 Self-refine, critique the results （自我完善，质疑结果）</h2>\n<p>  对于生成式人工智能和 LLMs，你不能相信其输出。 你需要验证一下。 毕竟， LLMs 只是向您展示下一个最有可能说的话，而不是正确的内容。 因此，一个好主意是要求 LLMs 自我批评，这引导我们自我完善技术。</p>\n<p>  其工作原理是按照以下步骤操作：</p>\n<ul>\n<li>要求 LLM 解决问题的初始提示</li>\n<li>LLM 产生答案</li>\n<li>质疑答案并要求人工智能改进</li>\n<li>LLM 再次回答，这次考虑了质疑并提出了解决方案</li>\n</ul>\n<p>  您可以根据需要多次重复此过程。</p>\n<h2 id=\"37-maieutic-prompting-多维度的提示\"><a class=\"markdownIt-Anchor\" href=\"#37-maieutic-prompting-多维度的提示\">#</a> 3.7 Maieutic prompting （多维度的提示）</h2>\n<p>  多维度的提示是一种类似于自我完善的技术，但它更多的是要求 LLMs 解释自己。 目标是减少 LLMs 输出不一致，以确保得出正确的答案。 要遵循的工作流程是：</p>\n<ul>\n<li>请 LLM 回答问题</li>\n<li>对于答案的每一部分，请 LLM 更深入地解释。</li>\n<li>如果存在不一致，则丢弃不一致的部分。</li>\n</ul>\n<p>  重复 2 和 3，直到您完成所有部分并对答案感到满意为止。</p>\n<h1 id=\"四-提示的关键要素\"><a class=\"markdownIt-Anchor\" href=\"#四-提示的关键要素\">#</a> 四、提示的关键要素</h1>\n<p>  在之前的页面中，我们已经讨论了几种不同的提示策略。本页将提供一般建议，这些建议对于提示的实际编写很重要</p>\n<p>（1）基本事实的重要性不大</p>\n<p>  令人惊讶的是，在提示中提供少量 exemplars 时，实际答案 (gold) 并不重要。即使在样本中提供随机标签，性能也几乎不受影响。</p>\n<p>（2）标签空间很重要</p>\n<p>  尽管样本中的黄金标签并不重要，但 labelspace 很重要。即使从标签空间中提供随机标签，也有助于大语言模型更好地理解标签空间并提高结果。此外，正确地在示例中表示标签空间的分布很重要。与在示例中从标签空间中均匀采样不同，最好按照标签的真实分布进行采样。</p>\n<p>（3）格式很重要</p>\n<p>  样本的格式或许是最重要的部分，因为它指示大语言格式如何正确地格式化其对提示的答案。</p>\n<p>  例如，请考虑以下样本。它们使用全大写的单词作为答案。尽管这些答案完全错误（2+2 不是 50），但 GPT-3 正确地回答了最后一个问题，并按照其他样本的格式进行回答。</p>\n<figure class=\"highlight markdown\"><figcaption data-lang=\"markdown\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>2+2等于多少？ </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>五十</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>20+5等于多少？</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>四十三</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>12+9等于多少？</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>二十一</pre></td></tr></table></figure><p>  以下是一些值得考虑的良好做法：</p>\n<ul>\n<li>指定上下文。 上下文很重要，您可以指定的领域、主题等越多越好。</li>\n<li>限制输出。 如果您想要特定数量的项目或特定长度，请指定。</li>\n<li>指定内容和方式。 请记住提及您想要什么以及您想要如何实现，例如 “创建一个包含路由产品和客户的 Python Web API，将其分为 3 个文件”。</li>\n<li>使用模板。 通常，您会希望使用公司的数据来丰富提示。 使用模板来执行此操作。 模板可以包含用实际数据替换的变量。</li>\n<li>拼写正确。 LLMs 可能会为您提供正确的答案，但如果您拼写正确，您会得到更好的答案。</li>\n</ul>\n<h1 id=\"五-din-sql和pet-sql\"><a class=\"markdownIt-Anchor\" href=\"#五-din-sql和pet-sql\">#</a> 五、DIN-SQL 和 PET-SQL</h1>\n<p>  用于参赛《中兴捧月大赛 - 精言妙喻》，主要参考论文有 DIN-SQL：《DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction》，PET-SQL：《PET-SQL: A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency》。两篇论文的主要思路如下：</p>\n<p><img data-src=\"/images/AI/Prompt_engineering/5.1.jpg\" alt=\"\"></p>\n<h1 id=\"六-中兴捧月大赛-精言妙喻个人初赛代码及思路\"><a class=\"markdownIt-Anchor\" href=\"#六-中兴捧月大赛-精言妙喻个人初赛代码及思路\">#</a> 六、《中兴捧月大赛 - 精言妙喻》个人初赛代码及思路</h1>\n<p>  具体文件可见 U 盘备份–&gt; 科研文件–&gt;9、第十四届中兴捧月全球精英挑战赛等。</p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/05/16/AI/LLM/",
            "url": "http://qianqiu-cell.github.io/2024/05/16/AI/LLM/",
            "title": "大模型LLM学习",
            "date_published": "2024-05-15T16:00:00.000Z",
            "content_html": "<p><img data-src=\"/images/AI/LLM/0.1.jpg\" alt=\"\"></p>\n<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly93YXlsYW5kemhhbmcuZ2l0aHViLmlvL2VuL3RyYW5zZm9ybWVyLWFyY2hpdGVjdHVyZS5odG1sIzQtNy1jYWxjdWxhdGUtdi1hdHRlbnRpb24=\">https://waylandzhang.github.io/en/transformer-architecture.html#4-7-calculate-v-attention</span>、<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vMzU0NjYxMTUyNzQ1MzE2MT9zcG1faWRfZnJvbT0zMzMuNzg4LjAuMA==\">https://space.bilibili.com/3546611527453161?spm_id_from=333.788.0.0</span></p>\n<p>   <code>Transformer</code>  模型由两部分组成：编码器和解码器。一般来说，仅编码器的架构精通于从文本中提取信息，用于分类和回归等任务，而仅解码器的模型专门用于生成文本。例如，<mark>专注于文本生成的 <code>GPT</code>  属于仅解码器模型的类别</mark>。</p>\n<p>   <code>Transformer</code>  的大致过程如下：</p>\n<ul>\n<li>首先，我们需要一系列输入字符作为训练数据。这些输入被转换成矢量嵌入格式。</li>\n<li>接下来，我们将位置编码添加到矢量嵌入中，以捕获序列中每个字符的位置。</li>\n<li>随后，该模型通过一系列计算操作处理这些输入嵌入，最终为给定的输入文本生成可能的下一个字符的概率分布。</li>\n<li>该模型根据训练数据集中的实际后续特征来评估预测结果，并相应地调整概率或 “权重”。</li>\n<li>最后，该模型迭代地细化这个过程，不断更新其参数，以提高未来预测的精度。</li>\n</ul>\n<h1 id=\"一-tokenizer\"><a class=\"markdownIt-Anchor\" href=\"#一-tokenizer\">#</a> 一、Tokenizer</h1>\n<p>   <code>Tokenizer</code>  分词算法是 <code>NLP</code>  大模型最基础的组件，基于 <code>Tokenizer</code>  可以<mark>将文本转换成独立的 <code>token</code>  列表，进而转换成输入的向量成为计算机可以理解的输入形式</mark>。</p>\n<p>   <code>tiktoken</code>  是一种快速  <code>BPE</code>  标记器，可与 <code>OpenAI</code>  模型一起使用。</p>\n<p>   <code>tiktoken</code>  使用方法为：</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> tiktoken</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\"># Using TikToken (Same as GPT3) to tokenize the source text</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>encoding <span class=\"token operator\">=</span> tiktoken<span class=\"token punctuation\">.</span>get_encoding<span class=\"token punctuation\">(</span><span class=\"token string\">\"cl100k_base\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># text 保存了 str 变量类型的文本内容 --> 输出为以单词为单位的 int 列表</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>tokenized_text <span class=\"token operator\">=</span> encoding<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\"># 将 tokenized_text 转换为 Tensor.int64 类型的张量</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>tokenized_text <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span>tokenized_text<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">long</span><span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>  上述的代码提供了 <code>encoding</code>  的编码过程，同时还可以根据 <code>tokenized</code>  的编码结果进行解码，只需要通过 <code>decode</code>  函数输入 <code>int</code>  类型的列表集合返回原始的 str 类型文本</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 输出单个编码对应的 str 文本</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>encoding<span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>tokenized_text<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\"># 输出多个编码对应的 str 文本</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>encoding<span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span>tokenized_text<span class=\"token punctuation\">.</span>tolist<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"二-embedding\"><a class=\"markdownIt-Anchor\" href=\"#二-embedding\">#</a> 二、Embedding</h1>\n<p>   <code>Tokenize</code>  完的下一步就是将 <code>token</code>  的 <code>one-hot</code>  编码转换成更 <code>dense</code>  的 <code>embedding</code>  编码。</p>\n<p>   <code>Embedding</code>  矩阵的本质就是一个查找表。由于输入向量是 <code>one-hot</code>  的， <code>embedding</code>  矩阵中有且仅有一行被激活。行间互不干扰。如下图所示，假设词汇表一共有 <code>6</code>  个词，则 <code>one-hot</code>  表示的长度为 <code>6</code> 。现在我们有三个单词组成一个句子，则输入矩阵的形状为 <code>(3,6)</code>  。然后我们学出来一个 <code>embedding</code>  矩阵，根据上面的推导，如果我们的 <code>embedding size</code> （编码向量的长度）为 <code>4</code> ，则 <code>embedding</code>  矩阵的形状应该为 <code>(6,4)</code> 。这样乘出来的输出矩阵的形状应为 <code>(3,4)</code> 。</p>\n<p><img data-src=\"/images/AI/LLM/2.1.jpg\" alt=\"\"></p>\n<p>  对于第一个单词 <code>I</code> ，假设其 <code>one-hot</code>  编码为 <code>[0,0,1,0,0,0]</code> ，将其与 <code>embedding</code>  矩阵相乘，相当于取出 <code>embedding</code>  矩阵的第 <code>3</code>  行（ <code>index</code>  为 <code>2</code> ）。同理，对于单词 <code>love</code> ，相当于取出 <code>embedding</code>  矩阵的第二行（ <code>index</code>  为 <code>1</code> ）。因此 <code>embedding</code>  矩阵的本质是一个查找表，每个单词会定位这个表中的某一行，而这一行就是这个单词学习到的在嵌入空间的语义。</p>\n<p>  首先准备所需要的数据，在 transformer 的解码器中，需要输入 <code>n_batch * context_length * d_model</code>  维度的 <code>Tensor</code>  数据，其中 <code>n_batch</code>  表示批次大小， <code>contex_length</code>  表示一次输入的单次数量， <code>d_model</code>  表示编码向量的长度。将 <code>Tokenizer</code>  中获得的 <code>tokenized_text</code>  进行数据预处理：</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># Split train and validation</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>split_idx <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>tokenized_text<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">0.9</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>train_data <span class=\"token operator\">=</span> tokenized_text<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>split_idx<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>val_data <span class=\"token operator\">=</span> tokenized_text<span class=\"token punctuation\">[</span>split_idx<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\"># Get input embedding batch</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>data <span class=\"token operator\">=</span> train_data</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>idxs <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>randint<span class=\"token punctuation\">(</span>low<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> high<span class=\"token operator\">=</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> context_length<span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>x_batch <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>stack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>idx<span class=\"token punctuation\">:</span>idx <span class=\"token operator\">+</span> context_length<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> idx <span class=\"token keyword\">in</span> idxs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>y_batch <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>stack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>idx <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>idx <span class=\"token operator\">+</span> context_length <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> idx <span class=\"token keyword\">in</span> idxs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>  之后便可以利用 <code>torch</code>  中的 <code>nn.Embedding</code>  函数构造 <code>Embedding</code>  层。其中 <code>Embedding.weight.data</code>  是一个 <code>max_token_value * d_model</code>  维度的 <code>Tensor</code>  变量，是模型需要训练的参数，同时也是上图中对应的 <code>Embedding</code>  查找表。</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># define input embedding table</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\"># 获取 tokenized_text 中的最大值 + 1，用于构造 Embedding 的行</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>max_token_value <span class=\"token operator\">=</span> tokenized_text<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 使用 nn.Embedding 函数构造 Embedding 层</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\"># `Embedding.weight.data` 是一个 `max_token_value * d_model` 维度的 `Tensor` 变量</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>token_embedding_lookup_table <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>num_embeddings<span class=\"token operator\">=</span>max_token_value<span class=\"token punctuation\">,</span> embedding_dim<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token comment\"># 通过输入 x_batch 或 y_batch 即可获得对应的 Embedding 编码结果</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token comment\"># x_batch_embedding 和 y_batch_embedding 是 `n_batch * context_length * d_model` 维度的 `Tensor` 数据</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>x_batch_embedding <span class=\"token operator\">=</span> token_embedding_lookup_table<span class=\"token punctuation\">(</span>x_batch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>y_batch_embedding <span class=\"token operator\">=</span> token_embedding_lookup_table<span class=\"token punctuation\">(</span>y_batch<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"三-position-encoding\"><a class=\"markdownIt-Anchor\" href=\"#三-position-encoding\">#</a> 三、Position Encoding</h1>\n<p>  在 <code>transformer</code>  的 <code>encoder</code>  和 <code>decoder</code>  的输入层中，均使用了 <code>Positional Encoding</code> ，使得最终的输入满足： <code>input = input_embedding + positional_encoding</code> 。</p>\n<p>   <code>Transformer</code>  位置编码的定义为：</p>\n<p><img data-src=\"/images/AI/LLM/3.1.png\" alt=\"\"></p>\n<p>  实现位置编码的代码为：</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># get positional encoding</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>position_encoding_lookup_table <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span>context_length<span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\"># unsqueeze 用来扩充一个维度，为了后面的逐元素计算时的广播机制</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>position <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> context_length<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>unsqueeze<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\"># 根据公式计算位置编码</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>div_term <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">-</span>math<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span><span class=\"token number\">10000.0</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> d_model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>position_encoding_lookup_table<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>sin<span class=\"token punctuation\">(</span>position <span class=\"token operator\">*</span> div_term<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>position_encoding_lookup_table<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cos<span class=\"token punctuation\">(</span>position <span class=\"token operator\">*</span> div_term<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token comment\"># 将 context_length*d_model 的矩阵复制 n_epoch 次，形成 n_epoch*context_length*d_model 的矩阵</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>position_encoding_lookup_table <span class=\"token operator\">=</span> position_encoding_lookup_table<span class=\"token punctuation\">.</span>unsqueeze<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>expand<span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>  在获得位置编码之后即可将位置编码与 <code>Embedding</code>  进行相加，获得最终输入至网络的输入：</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># add positional encoding to the input_embedding</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>x <span class=\"token operator\">=</span> x_batch_embedding <span class=\"token operator\">+</span> position_encoding_lookup_table</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>y <span class=\"token operator\">=</span> y_batch_embedding <span class=\"token operator\">+</span> position_encoding_lookup_table</pre></td></tr></table></figure><h1 id=\"四-transformer-block\"><a class=\"markdownIt-Anchor\" href=\"#四-transformer-block\">#</a> 四、Transformer Block</h1>\n<p><img data-src=\"/images/AI/LLM/4.1.png\" alt=\"\"></p>\n<p>  通过第三步，我们获得了输入 <code>x</code> ，下一步是开始实现多头注意力块（ <code>Muti-head Attention block</code> ）。</p>\n<p>   <code>Transformer</code>  模型的强大来源于 <code>self-attention</code> ，通过 <code>self-attention</code> ， <code>Transformer</code>  模型可以关注到 <code>input</code>  更加重要的部分。</p>\n<p>   <code>Multi-head attention</code>  由几个单独的 <code>heads</code>  堆叠在一起组成。所有 heads 都接收到完全相同的输入，尽管它们在计算过程中使用了自己的特定权重集。在处理输入之后，来自所有 <code>heads</code>  的输出被级联，然后通过线性层。</p>\n<p>   <code>heads</code>  的工作方式是通过三个独特的层处理，即查询（ <code>Q</code> ）、键（ <code>K</code> ）和值（ <code>V</code> ）。 <code>Attention</code>  的计算公式可以从论文《 <code>Attention is all you need</code> 》中得到：</p>\n<p><img data-src=\"/images/AI/LLM/4.2.png\" alt=\"\"></p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># get Q, K, V</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\"># 所谓的多头就是把 d_model 切成多份，每一个头里面有一部分维度，然后去做这一部分的计算，最后再把所有的计算合并在一起</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>head_size <span class=\"token operator\">=</span> d_model <span class=\"token operator\">//</span> num_heads  <span class=\"token comment\"># head size should be divisible by d_model</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># (1) 计算 Q,K,V 矩阵</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>key_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>query_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>value_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token comment\"># [batch_size, context_length, d_model]</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>q <span class=\"token operator\">=</span> query_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>k <span class=\"token operator\">=</span> key_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>v <span class=\"token operator\">=</span> value_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token comment\"># [batch_size, context_length, num_heads, head_size]</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>q <span class=\"token operator\">=</span> q<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> num_heads<span class=\"token punctuation\">,</span> head_size<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>k <span class=\"token operator\">=</span> k<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> num_heads<span class=\"token punctuation\">,</span> head_size<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>v <span class=\"token operator\">=</span> v<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> num_heads<span class=\"token punctuation\">,</span> head_size<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre><span class=\"token comment\"># [batch_size, num_heads, context_length, head_size]</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>q <span class=\"token operator\">=</span> q<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>k <span class=\"token operator\">=</span> k<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>v <span class=\"token operator\">=</span> v<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre><span class=\"token comment\"># (2) 通过 Q @ K^T /sqrt (d_k) 计算 Attention</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>attention_score <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>q @ k<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1.0</span> <span class=\"token operator\">/</span> math<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>head_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre><span class=\"token comment\"># (3) 计算 Mask</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>mask <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>triu<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>ones<span class=\"token punctuation\">(</span>context_length<span class=\"token punctuation\">,</span> context_length<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> diagonal<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">bool</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>attention_score <span class=\"token operator\">=</span> attention_score<span class=\"token punctuation\">.</span>masked_fill<span class=\"token punctuation\">(</span>mask<span class=\"token punctuation\">,</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span><span class=\"token string\">'-inf'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre><span class=\"token comment\"># (4) 计算 Softmax</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre><span class=\"token comment\"># [batch_size, num_heads, context_length, context_length]</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>attention_score <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>attention_score<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre><span class=\"token comment\"># (5) 通过 $V 计算 A</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre><span class=\"token comment\"># [batch_size, num_heads, context_length, head_size]</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>A <span class=\"token operator\">=</span> attention_score @ v</pre></td></tr><tr><td data-num=\"31\"></td><td><pre><span class=\"token comment\"># (6) 计算 Concatenate</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre><span class=\"token comment\"># [batch_size, context_length, num_heads, head_size]</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>A <span class=\"token operator\">=</span> A<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre><span class=\"token comment\"># [batch_size, context_length, d_model]</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>A <span class=\"token operator\">=</span> A<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre><span class=\"token comment\"># (7) 通过 Wo 计算 Output</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre><span class=\"token comment\"># Define the output weight matrix</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre>Wo <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre><span class=\"token comment\"># [batch_size, context_length, d_model]</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>output <span class=\"token operator\">=</span> Wo<span class=\"token punctuation\">(</span>A<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"五-residual-connection-and-layer-normalization\"><a class=\"markdownIt-Anchor\" href=\"#五-residual-connection-and-layer-normalization\">#</a> 五、Residual Connection and Layer Normalization</h1>\n<p>  残差连接，有时被称为 <code>skip connection</code> ，是让原始输入 <code>X</code>  绕过一个或多个层的连接。通过将原始输入 <code>x</code>  与步骤四多头注意力层的输出 <code>output</code>  相加即可完成操作。</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo>=</mo><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo>+</mo><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">output = output + x\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.80952em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.80952em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span></span></p>\n<p>  在残差连接之后，过程进入层归一化。层归一化（ <code>LayerNorm</code> ）是一种用于对网络中每一层的输出进行归一化的技术。其方法是减去输出的均值，并除以输出的标准差。使用这种技术是为了防止某一层的输出变得过大或过小，从而避免网络的不稳定性。</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># Add residual connection</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>output <span class=\"token operator\">=</span> output <span class=\"token operator\">+</span> X</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># Add Layer Normalization</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>layer_norm <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>LayerNorm<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>output <span class=\"token operator\">=</span> layer_norm<span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"六-feed-forward-network\"><a class=\"markdownIt-Anchor\" href=\"#六-feed-forward-network\">#</a> 六、Feed-Forward Network</h1>\n<p>  一旦我们获得了归一化的注意力权重（概率分数），它将被传递到一个位置级前馈网络中进行处理。前馈神经网络（ <code>FFN</code> ）由两个线性层和它们之间的 ReLU 激活函数组成。</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># update x</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>x <span class=\"token operator\">=</span> output</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># Define Feed Forward Network</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>output <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">,</span> d_model <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>output <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>output <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>d_model <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>output <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>dropout<span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">,</span> p<span class=\"token operator\">=</span>dropout<span class=\"token punctuation\">,</span> train<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\"># Add residual connection</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>output <span class=\"token operator\">=</span> output <span class=\"token operator\">+</span> x</pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token comment\"># Add Layer Normalization</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>layer_norm <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>LayerNorm<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>output <span class=\"token operator\">=</span> layer_norm<span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"七-repeat-step-4-to-6\"><a class=\"markdownIt-Anchor\" href=\"#七-repeat-step-4-to-6\">#</a> 七、Repeat step 4 to 6</h1>\n<p>  以上我们完成的只是一个 <code>transformer</code>  块。在实际应用中，我们会将多个 <code>transformer</code>  块堆叠在一起，形成一个 <code>transformer</code>  解码器。</p>\n<p>  实际上，我们应该将代码封装到类中，并使用 <code>PyTorch</code>  的 <code>nn.Module</code>  来构建我们的 <code>transformer</code>  解码器。但为了演示，我们只使用一个块。</p>\n<h1 id=\"八-output-probabilities\"><a class=\"markdownIt-Anchor\" href=\"#八-output-probabilities\">#</a> 八、Output Probabilities</h1>\n<p>  应用最后一个线性层来获得我们的 <code>logits</code> ：</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>logits <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">,</span> max_token_value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>  最后一步是对逻辑回归输出进行 <code>softmax</code>  操作，以获得每个 <code>token</code>  的概率：</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># torch.softmax usually used during inference, during training we use torch.nn.CrossEntropyLoss</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\"># but for illustration purpose, we'll use torch.softmax here</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>probabilities <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>logits<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"full-working-code\"><a class=\"markdownIt-Anchor\" href=\"#full-working-code\">#</a> Full Working Code</h1>\n<p>  完整的代码可以参考 <code>github</code> : <span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL3dheWxhbmR6aGFuZy9UcmFuc2Zvcm1lci1mcm9tLXNjcmF0Y2g=\">https://github.com/waylandzhang/Transformer-from-scratch</span></p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> os</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> requests</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">import</span> math</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">import</span> tiktoken</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">import</span> torch</pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">as</span> nn</pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token keyword\">from</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">import</span> functional <span class=\"token keyword\">as</span> F</pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token comment\"># Hyperparameters</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>batch_size <span class=\"token operator\">=</span> <span class=\"token number\">4</span>  <span class=\"token comment\"># How many batches per training step</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>context_length <span class=\"token operator\">=</span> <span class=\"token number\">16</span>  <span class=\"token comment\"># Length of the token chunk each batch</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>d_model <span class=\"token operator\">=</span> <span class=\"token number\">64</span>  <span class=\"token comment\"># The size of our model token embeddings</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>num_blocks <span class=\"token operator\">=</span> <span class=\"token number\">8</span>  <span class=\"token comment\"># Number of transformer blocks</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>num_heads <span class=\"token operator\">=</span> <span class=\"token number\">4</span>  <span class=\"token comment\"># Number of heads in Multi-head attention</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>learning_rate <span class=\"token operator\">=</span> <span class=\"token number\">1e-3</span>  <span class=\"token comment\"># 0.001</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>dropout <span class=\"token operator\">=</span> <span class=\"token number\">0.1</span>  <span class=\"token comment\"># Dropout rate</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>max_iters <span class=\"token operator\">=</span> <span class=\"token number\">5000</span>  <span class=\"token comment\"># Total of training iterations &lt;- Change this to smaller number for testing</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>eval_interval <span class=\"token operator\">=</span> <span class=\"token number\">50</span>  <span class=\"token comment\"># How often to evaluate</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>eval_iters <span class=\"token operator\">=</span> <span class=\"token number\">20</span>  <span class=\"token comment\"># Number of iterations to average for evaluation</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>device <span class=\"token operator\">=</span> <span class=\"token string\">'cuda'</span> <span class=\"token keyword\">if</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>is_available<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">else</span> <span class=\"token string\">'cpu'</span>  <span class=\"token comment\"># Use GPU if it's available.</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>TORCH_SEED <span class=\"token operator\">=</span> <span class=\"token number\">1337</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>torch<span class=\"token punctuation\">.</span>manual_seed<span class=\"token punctuation\">(</span>TORCH_SEED<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre></pre></td></tr><tr><td data-num=\"24\"></td><td><pre><span class=\"token comment\"># Load training data</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre><span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>exists<span class=\"token punctuation\">(</span><span class=\"token string\">'data/sales_textbook.txt'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>    url <span class=\"token operator\">=</span> <span class=\"token string\">'https://huggingface.co/datasets/goendalf666/sales-textbook_for_convincing_and_selling/raw/main/sales_textbook.txt'</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'data/sales_textbook.txt'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'w'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>        f<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span>requests<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span>url<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre></pre></td></tr><tr><td data-num=\"30\"></td><td><pre><span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'data/sales_textbook.txt'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>    text <span class=\"token operator\">=</span> f<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre></pre></td></tr><tr><td data-num=\"33\"></td><td><pre><span class=\"token comment\"># Using TikToken (Same as GPT3) to tokenize the source text</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>encoding <span class=\"token operator\">=</span> tiktoken<span class=\"token punctuation\">.</span>get_encoding<span class=\"token punctuation\">(</span><span class=\"token string\">\"cl100k_base\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>tokenized_text <span class=\"token operator\">=</span> encoding<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>max_token_value <span class=\"token operator\">=</span> <span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>tokenized_text<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span>  <span class=\"token comment\"># the maximum value of the tokenized numbers</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>tokenized_text <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span>tokenized_text<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">long</span><span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># put tokenized text into tensor</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre></pre></td></tr><tr><td data-num=\"39\"></td><td><pre><span class=\"token comment\"># Split train and validation</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>split_idx <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>tokenized_text<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">0.9</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>train_data <span class=\"token operator\">=</span> tokenized_text<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>split_idx<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre>val_data <span class=\"token operator\">=</span> tokenized_text<span class=\"token punctuation\">[</span>split_idx<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"43\"></td><td><pre></pre></td></tr><tr><td data-num=\"44\"></td><td><pre></pre></td></tr><tr><td data-num=\"45\"></td><td><pre><span class=\"token comment\"># Define Feed Forward Network</span></pre></td></tr><tr><td data-num=\"46\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">FeedForward</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"47\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"48\"></td><td><pre>        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"49\"></td><td><pre>        self<span class=\"token punctuation\">.</span>d_model <span class=\"token operator\">=</span> d_model</pre></td></tr><tr><td data-num=\"50\"></td><td><pre>        self<span class=\"token punctuation\">.</span>dropout <span class=\"token operator\">=</span> dropout</pre></td></tr><tr><td data-num=\"51\"></td><td><pre>        self<span class=\"token punctuation\">.</span>ffn <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"52\"></td><td><pre>            nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"53\"></td><td><pre>            nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"54\"></td><td><pre>            nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"55\"></td><td><pre>            nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>dropout<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"56\"></td><td><pre>        <span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"57\"></td><td><pre></pre></td></tr><tr><td data-num=\"58\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"59\"></td><td><pre>        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>ffn<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"60\"></td><td><pre></pre></td></tr><tr><td data-num=\"61\"></td><td><pre></pre></td></tr><tr><td data-num=\"62\"></td><td><pre><span class=\"token comment\"># Define Scaled Dot Product Attention</span></pre></td></tr><tr><td data-num=\"63\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">Attention</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"64\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> head_size<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"65\"></td><td><pre>        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"66\"></td><td><pre>        self<span class=\"token punctuation\">.</span>d_model <span class=\"token operator\">=</span> d_model</pre></td></tr><tr><td data-num=\"67\"></td><td><pre>        self<span class=\"token punctuation\">.</span>head_size <span class=\"token operator\">=</span> head_size</pre></td></tr><tr><td data-num=\"68\"></td><td><pre>        self<span class=\"token punctuation\">.</span>context_length <span class=\"token operator\">=</span> context_length</pre></td></tr><tr><td data-num=\"69\"></td><td><pre>        self<span class=\"token punctuation\">.</span>dropout <span class=\"token operator\">=</span> dropout</pre></td></tr><tr><td data-num=\"70\"></td><td><pre></pre></td></tr><tr><td data-num=\"71\"></td><td><pre>        self<span class=\"token punctuation\">.</span>key_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>head_size<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"72\"></td><td><pre>        self<span class=\"token punctuation\">.</span>query_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>head_size<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"73\"></td><td><pre>        self<span class=\"token punctuation\">.</span>value_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>head_size<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"74\"></td><td><pre>        self<span class=\"token punctuation\">.</span>register_buffer<span class=\"token punctuation\">(</span><span class=\"token string\">'tril'</span><span class=\"token punctuation\">,</span> torch<span class=\"token punctuation\">.</span>tril<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"75\"></td><td><pre>            torch<span class=\"token punctuation\">.</span>ones<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>context_length<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>context_length<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># Lower triangular mask</span></pre></td></tr><tr><td data-num=\"76\"></td><td><pre>        self<span class=\"token punctuation\">.</span>dropout_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>dropout<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"77\"></td><td><pre></pre></td></tr><tr><td data-num=\"78\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"79\"></td><td><pre>        B<span class=\"token punctuation\">,</span> T<span class=\"token punctuation\">,</span> C <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>shape  <span class=\"token comment\"># Batch size, Time steps(current context_length), Channels(dimensions)</span></pre></td></tr><tr><td data-num=\"80\"></td><td><pre>        <span class=\"token keyword\">assert</span> T <span class=\"token operator\">&lt;=</span> self<span class=\"token punctuation\">.</span>context_length</pre></td></tr><tr><td data-num=\"81\"></td><td><pre>        <span class=\"token keyword\">assert</span> C <span class=\"token operator\">==</span> self<span class=\"token punctuation\">.</span>d_model</pre></td></tr><tr><td data-num=\"82\"></td><td><pre>        q <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>query_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"83\"></td><td><pre>        k <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>key_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"84\"></td><td><pre>        v <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>value_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"85\"></td><td><pre></pre></td></tr><tr><td data-num=\"86\"></td><td><pre>        <span class=\"token comment\"># Scaled dot product attention: Q @ K^T / sqrt(d_k)</span></pre></td></tr><tr><td data-num=\"87\"></td><td><pre>        weights <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>q @ k<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1.0</span> <span class=\"token operator\">/</span> math<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>k<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"88\"></td><td><pre>        <span class=\"token comment\"># Apply masked attention</span></pre></td></tr><tr><td data-num=\"89\"></td><td><pre>        weights <span class=\"token operator\">=</span> weights<span class=\"token punctuation\">.</span>masked_fill<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>tril<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>T<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span>T<span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span><span class=\"token string\">'-inf'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"90\"></td><td><pre>        weights <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span><span class=\"token builtin\">input</span><span class=\"token operator\">=</span>weights<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"91\"></td><td><pre>        weights <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>dropout_layer<span class=\"token punctuation\">(</span>weights<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"92\"></td><td><pre></pre></td></tr><tr><td data-num=\"93\"></td><td><pre>        <span class=\"token comment\"># Apply dot product attention: weights @ V</span></pre></td></tr><tr><td data-num=\"94\"></td><td><pre>        out <span class=\"token operator\">=</span> weights @ v</pre></td></tr><tr><td data-num=\"95\"></td><td><pre>        <span class=\"token keyword\">return</span> out</pre></td></tr><tr><td data-num=\"96\"></td><td><pre></pre></td></tr><tr><td data-num=\"97\"></td><td><pre></pre></td></tr><tr><td data-num=\"98\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">MultiHeadAttention</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"99\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> head_size<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"100\"></td><td><pre>        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"101\"></td><td><pre>        self<span class=\"token punctuation\">.</span>num_heads <span class=\"token operator\">=</span> num_heads</pre></td></tr><tr><td data-num=\"102\"></td><td><pre>        self<span class=\"token punctuation\">.</span>head_size <span class=\"token operator\">=</span> head_size</pre></td></tr><tr><td data-num=\"103\"></td><td><pre>        self<span class=\"token punctuation\">.</span>d_model <span class=\"token operator\">=</span> d_model</pre></td></tr><tr><td data-num=\"104\"></td><td><pre>        self<span class=\"token punctuation\">.</span>context_length <span class=\"token operator\">=</span> context_length</pre></td></tr><tr><td data-num=\"105\"></td><td><pre>        self<span class=\"token punctuation\">.</span>dropout <span class=\"token operator\">=</span> dropout</pre></td></tr><tr><td data-num=\"106\"></td><td><pre></pre></td></tr><tr><td data-num=\"107\"></td><td><pre>        self<span class=\"token punctuation\">.</span>heads <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>ModuleList<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>Attention<span class=\"token punctuation\">(</span>head_size<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>head_size<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>num_heads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"108\"></td><td><pre>        self<span class=\"token punctuation\">.</span>projection_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"109\"></td><td><pre>        self<span class=\"token punctuation\">.</span>dropout_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>dropout<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"110\"></td><td><pre></pre></td></tr><tr><td data-num=\"111\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"112\"></td><td><pre>        out <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>h<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> h <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>heads<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"113\"></td><td><pre>        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>projection_layer<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"114\"></td><td><pre>        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>dropout_layer<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"115\"></td><td><pre>        <span class=\"token keyword\">return</span> out</pre></td></tr><tr><td data-num=\"116\"></td><td><pre></pre></td></tr><tr><td data-num=\"117\"></td><td><pre></pre></td></tr><tr><td data-num=\"118\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">TransformerBlock</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"119\"></td><td><pre></pre></td></tr><tr><td data-num=\"120\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> num_heads<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"121\"></td><td><pre>        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"122\"></td><td><pre>        self<span class=\"token punctuation\">.</span>d_model <span class=\"token operator\">=</span> d_model</pre></td></tr><tr><td data-num=\"123\"></td><td><pre>        self<span class=\"token punctuation\">.</span>context_length <span class=\"token operator\">=</span> context_length</pre></td></tr><tr><td data-num=\"124\"></td><td><pre>        self<span class=\"token punctuation\">.</span>head_size <span class=\"token operator\">=</span> d_model <span class=\"token operator\">//</span> num_heads  <span class=\"token comment\"># head size should be divisible by d_model</span></pre></td></tr><tr><td data-num=\"125\"></td><td><pre>        self<span class=\"token punctuation\">.</span>num_heads <span class=\"token operator\">=</span> num_heads</pre></td></tr><tr><td data-num=\"126\"></td><td><pre>        self<span class=\"token punctuation\">.</span>dropout <span class=\"token operator\">=</span> dropout</pre></td></tr><tr><td data-num=\"127\"></td><td><pre></pre></td></tr><tr><td data-num=\"128\"></td><td><pre>        self<span class=\"token punctuation\">.</span>multi_head_attention_layer <span class=\"token operator\">=</span> MultiHeadAttention<span class=\"token punctuation\">(</span>head_size<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>head_size<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"129\"></td><td><pre>        self<span class=\"token punctuation\">.</span>feed_forward_layer <span class=\"token operator\">=</span> FeedForward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"130\"></td><td><pre>        self<span class=\"token punctuation\">.</span>layer_norm_1 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>LayerNorm<span class=\"token punctuation\">(</span>normalized_shape<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"131\"></td><td><pre>        self<span class=\"token punctuation\">.</span>layer_norm_2 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>LayerNorm<span class=\"token punctuation\">(</span>normalized_shape<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"132\"></td><td><pre></pre></td></tr><tr><td data-num=\"133\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"134\"></td><td><pre>        <span class=\"token comment\"># Note: The order of the operations is different from the original Transformer paper</span></pre></td></tr><tr><td data-num=\"135\"></td><td><pre>        <span class=\"token comment\"># The order here is: LayerNorm -> Multi-head attention -> LayerNorm -> Feed forward</span></pre></td></tr><tr><td data-num=\"136\"></td><td><pre>        x <span class=\"token operator\">=</span> x <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>multi_head_attention_layer<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>layer_norm_1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># Residual connection</span></pre></td></tr><tr><td data-num=\"137\"></td><td><pre>        x <span class=\"token operator\">=</span> x <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>feed_forward_layer<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>layer_norm_2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># Residual connection</span></pre></td></tr><tr><td data-num=\"138\"></td><td><pre>        <span class=\"token keyword\">return</span> x</pre></td></tr><tr><td data-num=\"139\"></td><td><pre></pre></td></tr><tr><td data-num=\"140\"></td><td><pre></pre></td></tr><tr><td data-num=\"141\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">TransformerLanguageModel</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"142\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"143\"></td><td><pre>        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"144\"></td><td><pre>        self<span class=\"token punctuation\">.</span>d_model <span class=\"token operator\">=</span> d_model</pre></td></tr><tr><td data-num=\"145\"></td><td><pre>        self<span class=\"token punctuation\">.</span>context_length <span class=\"token operator\">=</span> context_length</pre></td></tr><tr><td data-num=\"146\"></td><td><pre>        self<span class=\"token punctuation\">.</span>num_heads <span class=\"token operator\">=</span> num_heads</pre></td></tr><tr><td data-num=\"147\"></td><td><pre>        self<span class=\"token punctuation\">.</span>num_blocks <span class=\"token operator\">=</span> num_blocks</pre></td></tr><tr><td data-num=\"148\"></td><td><pre>        self<span class=\"token punctuation\">.</span>dropout <span class=\"token operator\">=</span> dropout</pre></td></tr><tr><td data-num=\"149\"></td><td><pre>        self<span class=\"token punctuation\">.</span>max_token_value <span class=\"token operator\">=</span> max_token_value</pre></td></tr><tr><td data-num=\"150\"></td><td><pre>        <span class=\"token comment\"># Set up token embedding look-up table</span></pre></td></tr><tr><td data-num=\"151\"></td><td><pre>        self<span class=\"token punctuation\">.</span>token_embedding_lookup_table <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>num_embeddings<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>max_token_value <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> embedding_dim<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"152\"></td><td><pre></pre></td></tr><tr><td data-num=\"153\"></td><td><pre>        <span class=\"token comment\"># Run all the transformer blocks</span></pre></td></tr><tr><td data-num=\"154\"></td><td><pre>        <span class=\"token comment\"># Different from original paper, here we add a final layer norm after all the blocks</span></pre></td></tr><tr><td data-num=\"155\"></td><td><pre>        self<span class=\"token punctuation\">.</span>transformer_blocks <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span><span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"156\"></td><td><pre>                <span class=\"token punctuation\">[</span>TransformerBlock<span class=\"token punctuation\">(</span>num_heads<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>num_heads<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>num_blocks<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span></pre></td></tr><tr><td data-num=\"157\"></td><td><pre>                <span class=\"token punctuation\">[</span>nn<span class=\"token punctuation\">.</span>LayerNorm<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"158\"></td><td><pre>        <span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"159\"></td><td><pre>        self<span class=\"token punctuation\">.</span>language_model_out_linear_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>max_token_value<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"160\"></td><td><pre></pre></td></tr><tr><td data-num=\"161\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> idx<span class=\"token punctuation\">,</span> targets<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"162\"></td><td><pre>        B<span class=\"token punctuation\">,</span> T <span class=\"token operator\">=</span> idx<span class=\"token punctuation\">.</span>shape</pre></td></tr><tr><td data-num=\"163\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"164\"></td><td><pre>        # Set up position embedding look-up table</pre></td></tr><tr><td data-num=\"165\"></td><td><pre>        # following the same approach as the original Transformer paper (Sine and Cosine functions)</pre></td></tr><tr><td data-num=\"166\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"167\"></td><td><pre>        position_encoding_lookup_table <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>context_length<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"168\"></td><td><pre>        position <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>context_length<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>unsqueeze<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"169\"></td><td><pre>        div_term <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">-</span>math<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span><span class=\"token number\">10000.0</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"170\"></td><td><pre>        position_encoding_lookup_table<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>sin<span class=\"token punctuation\">(</span>position <span class=\"token operator\">*</span> div_term<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"171\"></td><td><pre>        position_encoding_lookup_table<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cos<span class=\"token punctuation\">(</span>position <span class=\"token operator\">*</span> div_term<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"172\"></td><td><pre>        <span class=\"token comment\"># change position_encoding_lookup_table from (context_length, d_model) to (T, d_model)</span></pre></td></tr><tr><td data-num=\"173\"></td><td><pre>        position_embedding <span class=\"token operator\">=</span> position_encoding_lookup_table<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>T<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"174\"></td><td><pre>        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>token_embedding_lookup_table<span class=\"token punctuation\">(</span>idx<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> position_embedding</pre></td></tr><tr><td data-num=\"175\"></td><td><pre>        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>transformer_blocks<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"176\"></td><td><pre>        <span class=\"token comment\"># The \"logits\" are the output values of our model before applying softmax</span></pre></td></tr><tr><td data-num=\"177\"></td><td><pre>        logits <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>language_model_out_linear_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"178\"></td><td><pre></pre></td></tr><tr><td data-num=\"179\"></td><td><pre>        <span class=\"token keyword\">if</span> targets <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"180\"></td><td><pre>            B<span class=\"token punctuation\">,</span> T<span class=\"token punctuation\">,</span> C <span class=\"token operator\">=</span> logits<span class=\"token punctuation\">.</span>shape</pre></td></tr><tr><td data-num=\"181\"></td><td><pre>            logits_reshaped <span class=\"token operator\">=</span> logits<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>B <span class=\"token operator\">*</span> T<span class=\"token punctuation\">,</span> C<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"182\"></td><td><pre>            targets_reshaped <span class=\"token operator\">=</span> targets<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>B <span class=\"token operator\">*</span> T<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"183\"></td><td><pre>            loss <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>cross_entropy<span class=\"token punctuation\">(</span><span class=\"token builtin\">input</span><span class=\"token operator\">=</span>logits_reshaped<span class=\"token punctuation\">,</span> target<span class=\"token operator\">=</span>targets_reshaped<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"184\"></td><td><pre>        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"185\"></td><td><pre>            loss <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span></pre></td></tr><tr><td data-num=\"186\"></td><td><pre>        <span class=\"token keyword\">return</span> logits<span class=\"token punctuation\">,</span> loss</pre></td></tr><tr><td data-num=\"187\"></td><td><pre></pre></td></tr><tr><td data-num=\"188\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">generate</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> idx<span class=\"token punctuation\">,</span> max_new_tokens<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"189\"></td><td><pre>        <span class=\"token comment\"># idx is (B,T) array of indices in the current context</span></pre></td></tr><tr><td data-num=\"190\"></td><td><pre>        <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>max_new_tokens<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"191\"></td><td><pre>            <span class=\"token comment\"># Crop idx to the max size of our positional embeddings table</span></pre></td></tr><tr><td data-num=\"192\"></td><td><pre>            idx_crop <span class=\"token operator\">=</span> idx<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span>self<span class=\"token punctuation\">.</span>context_length<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"193\"></td><td><pre>            <span class=\"token comment\"># Get predictions</span></pre></td></tr><tr><td data-num=\"194\"></td><td><pre>            logits<span class=\"token punctuation\">,</span> loss <span class=\"token operator\">=</span> self<span class=\"token punctuation\">(</span>idx_crop<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"195\"></td><td><pre>            <span class=\"token comment\"># Get the last time step from logits where the dimensions of the logits are (B,T,C)</span></pre></td></tr><tr><td data-num=\"196\"></td><td><pre>            logits_last_timestep <span class=\"token operator\">=</span> logits<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"197\"></td><td><pre>            <span class=\"token comment\"># Apply softmax to get probabilities</span></pre></td></tr><tr><td data-num=\"198\"></td><td><pre>            probs <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span><span class=\"token builtin\">input</span><span class=\"token operator\">=</span>logits_last_timestep<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"199\"></td><td><pre>            <span class=\"token comment\"># Sample from the probabilities' distribution.</span></pre></td></tr><tr><td data-num=\"200\"></td><td><pre>            idx_next <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>multinomial<span class=\"token punctuation\">(</span><span class=\"token builtin\">input</span><span class=\"token operator\">=</span>probs<span class=\"token punctuation\">,</span> num_samples<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"201\"></td><td><pre>            <span class=\"token comment\"># Append the sampled indexes idx_next to idx</span></pre></td></tr><tr><td data-num=\"202\"></td><td><pre>            idx <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>idx<span class=\"token punctuation\">,</span> idx_next<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"203\"></td><td><pre>        <span class=\"token keyword\">return</span> idx</pre></td></tr><tr><td data-num=\"204\"></td><td><pre></pre></td></tr><tr><td data-num=\"205\"></td><td><pre></pre></td></tr><tr><td data-num=\"206\"></td><td><pre><span class=\"token comment\"># Initialize the model</span></pre></td></tr><tr><td data-num=\"207\"></td><td><pre>model <span class=\"token operator\">=</span> TransformerLanguageModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"208\"></td><td><pre>model <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"209\"></td><td><pre></pre></td></tr><tr><td data-num=\"210\"></td><td><pre></pre></td></tr><tr><td data-num=\"211\"></td><td><pre><span class=\"token comment\"># Get input embedding batch</span></pre></td></tr><tr><td data-num=\"212\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">get_batch</span><span class=\"token punctuation\">(</span>split<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"213\"></td><td><pre>    data <span class=\"token operator\">=</span> train_data <span class=\"token keyword\">if</span> split <span class=\"token operator\">==</span> <span class=\"token string\">'train'</span> <span class=\"token keyword\">else</span> val_data</pre></td></tr><tr><td data-num=\"214\"></td><td><pre>    idxs <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>randint<span class=\"token punctuation\">(</span>low<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> high<span class=\"token operator\">=</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> context_length<span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"215\"></td><td><pre>    x <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>stack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>idx<span class=\"token punctuation\">:</span>idx <span class=\"token operator\">+</span> context_length<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> idx <span class=\"token keyword\">in</span> idxs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"216\"></td><td><pre>    y <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>stack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>idx <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>idx <span class=\"token operator\">+</span> context_length <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> idx <span class=\"token keyword\">in</span> idxs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"217\"></td><td><pre>    <span class=\"token keyword\">return</span> x<span class=\"token punctuation\">,</span> y</pre></td></tr><tr><td data-num=\"218\"></td><td><pre></pre></td></tr><tr><td data-num=\"219\"></td><td><pre></pre></td></tr><tr><td data-num=\"220\"></td><td><pre><span class=\"token comment\"># Calculate loss</span></pre></td></tr><tr><td data-num=\"221\"></td><td><pre><span class=\"token decorator annotation punctuation\">@torch<span class=\"token punctuation\">.</span>no_grad</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"222\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">estimate_loss</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"223\"></td><td><pre>    out <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"224\"></td><td><pre>    model<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"225\"></td><td><pre>    <span class=\"token keyword\">for</span> split <span class=\"token keyword\">in</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'train'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'valid'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"226\"></td><td><pre>        losses <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span>eval_iters<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"227\"></td><td><pre>        <span class=\"token keyword\">for</span> k <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>eval_iters<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"228\"></td><td><pre>            x_batch<span class=\"token punctuation\">,</span> y_batch <span class=\"token operator\">=</span> get_batch<span class=\"token punctuation\">(</span>split<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"229\"></td><td><pre>            logits<span class=\"token punctuation\">,</span> loss <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>x_batch<span class=\"token punctuation\">,</span> y_batch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"230\"></td><td><pre>            losses<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> loss<span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"231\"></td><td><pre>        out<span class=\"token punctuation\">[</span>split<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> losses<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"232\"></td><td><pre>    model<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"233\"></td><td><pre>    <span class=\"token keyword\">return</span> out</pre></td></tr><tr><td data-num=\"234\"></td><td><pre></pre></td></tr><tr><td data-num=\"235\"></td><td><pre></pre></td></tr><tr><td data-num=\"236\"></td><td><pre><span class=\"token comment\"># Use AdamW optimizer</span></pre></td></tr><tr><td data-num=\"237\"></td><td><pre>optimizer <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>optim<span class=\"token punctuation\">.</span>AdamW<span class=\"token punctuation\">(</span>params<span class=\"token operator\">=</span>model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span>learning_rate<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"238\"></td><td><pre>tracked_losses <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"239\"></td><td><pre><span class=\"token keyword\">for</span> step <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>max_iters<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"240\"></td><td><pre>    <span class=\"token keyword\">if</span> step <span class=\"token operator\">%</span> eval_iters <span class=\"token operator\">==</span> <span class=\"token number\">0</span> <span class=\"token keyword\">or</span> step <span class=\"token operator\">==</span> max_iters <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"241\"></td><td><pre>        losses <span class=\"token operator\">=</span> estimate_loss<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"242\"></td><td><pre>        tracked_losses<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>losses<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"243\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Step:'</span><span class=\"token punctuation\">,</span> step<span class=\"token punctuation\">,</span> <span class=\"token string\">'Training Loss:'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>losses<span class=\"token punctuation\">[</span><span class=\"token string\">'train'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Validation Loss:'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"244\"></td><td><pre>              <span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>losses<span class=\"token punctuation\">[</span><span class=\"token string\">'valid'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"245\"></td><td><pre></pre></td></tr><tr><td data-num=\"246\"></td><td><pre>    xb<span class=\"token punctuation\">,</span> yb <span class=\"token operator\">=</span> get_batch<span class=\"token punctuation\">(</span><span class=\"token string\">'train'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"247\"></td><td><pre>    logits<span class=\"token punctuation\">,</span> loss <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>xb<span class=\"token punctuation\">,</span> yb<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"248\"></td><td><pre>    optimizer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span>set_to_none<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"249\"></td><td><pre>    loss<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"250\"></td><td><pre>    optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"251\"></td><td><pre></pre></td></tr><tr><td data-num=\"252\"></td><td><pre><span class=\"token comment\"># Save the model state dictionary</span></pre></td></tr><tr><td data-num=\"253\"></td><td><pre>torch<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>state_dict<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'model-ckpt.pt'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"254\"></td><td><pre></pre></td></tr><tr><td data-num=\"255\"></td><td><pre><span class=\"token comment\"># Generate</span></pre></td></tr><tr><td data-num=\"256\"></td><td><pre>model<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"257\"></td><td><pre>start <span class=\"token operator\">=</span> <span class=\"token string\">'The salesperson'</span></pre></td></tr><tr><td data-num=\"258\"></td><td><pre>start_ids <span class=\"token operator\">=</span> encoding<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span>start<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"259\"></td><td><pre>x <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span>start_ids<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">long</span><span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"260\"></td><td><pre>y <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>generate<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> max_new_tokens<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"261\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'---------------'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"262\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>encoding<span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>tolist<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"263\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'---------------'</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure>",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/05/16/AI/LLM_finetune/",
            "url": "http://qianqiu-cell.github.io/2024/05/16/AI/LLM_finetune/",
            "title": "大模型微调",
            "date_published": "2024-05-15T16:00:00.000Z",
            "content_html": "<h1 id=\"一-为什么要对大模型进行微调\"><a class=\"markdownIt-Anchor\" href=\"#一-为什么要对大模型进行微调\">#</a> 一、为什么要对大模型进行微调</h1>\n<p>  通常，要对大模型进行微调，有以下一些原因：</p>\n<ul>\n<li>\n<p>第一个原因是，因为大模型的参数量非常大，训练成本非常高，每家公司都去从头训练一个自己的大模型，这个事情的性价比非常低；</p>\n</li>\n<li>\n<p>第二个原因是， <code>Prompt Engineering</code>  的方式是一种相对来说容易上手的使用大模型的方式，但是它的缺点也非常明显。因为通常大模型的实现原理，都会对输入序列的长度有限制， <code>Prompt Engineering</code>  的方式会把 <code>Prompt</code>  搞得很长。越长的 <code>Prompt</code> ，大模型的推理成本越高，因为推理成本是跟 <code>Prompt</code>  长度的平方正向相关的。另外， <code>Prompt</code>  太长会因超过限制而被截断，进而导致大模型的输出质量打折口，这也是一个非常严重的问题。对于个人使用者而言，如果是解决自己日常生活、工作中的一些问题，直接用 <code>Prompt Engineering</code>  的方式，通常问题不大。但对于对外提供服务的企业来说，要想在自己的服务中接入大模型的能力，推理成本是不得不要考虑的一个因素，微调相对来说就是一个更优的方案。</p>\n</li>\n<li>\n<p>第三个原因是， <code>Prompt Engineering</code>  的效果达不到要求，企业又有比较好的自有数据，能够通过自有数据，更好的提升大模型在特定领域的能力。这时候微调就非常适用。</p>\n</li>\n<li>\n<p>第四个原因是，要在个性化的服务中使用大模型的能力，这时候针对每个用户的数据，训练一个轻量级的微调模型，就是一个不错的方案。</p>\n</li>\n<li>\n<p>第五个原因是，数据安全的问题。如果数据是不能传递给第三方大模型服务的，那么搭建自己的大模型就非常必要。通常这些开源的大模型都是需要用自有数据进行微调，才能够满足业务的需求，这时候也需要对大模型进行微调。</p>\n</li>\n</ul>\n<h1 id=\"二-如何对大模型进行微调\"><a class=\"markdownIt-Anchor\" href=\"#二-如何对大模型进行微调\">#</a> 二、如何对大模型进行微调</h1>\n<p>  从参数规模的角度，大模型的微调分成两条技术路线：</p>\n<ul>\n<li>\n<p>一条是对全量的参数，进行全量的训练，这条路径叫全量微调 <code>FFT(Full Fine Tuning)</code> 。</p>\n</li>\n<li>\n<p>一条是只对部分的参数进行训练，这条路径叫 <code>PEFT(Parameter-Efficient Fine Tuning)</code> 。</p>\n</li>\n</ul>\n<p>   <code>FFT</code>  的原理，就是用特定的数据，对大模型进行训练，将 <code>W</code>  变成 <code>W'</code> ， <code>W'</code>  相比 <code>W</code>  ，最大的优点就是上述特定数据领域的表现会好很多。但 <code>FFT</code>  也会带来一些问题，影响比较大的问题，主要有以下两个：</p>\n<ul>\n<li>\n<p>一个是训练的成本会比较高，因为微调的参数量跟预训练的是一样的多的；</p>\n</li>\n<li>\n<p>一个是叫灾难性遗忘 ( <code>Catastrophic Forgetting</code> )，用特定训练数据去微调可能会把这个领域的表现变好，但也可能会把原来表现好的别的领域的能力变差。</p>\n</li>\n</ul>\n<p>   <code>PEFT</code>  主要想解决的问题，就是 <code>FFT</code>  存在的上述两个问题， <code>PEFT</code>  也是目前比较主流的微调方案。</p>\n<h1 id=\"三-实现fft的示例代码\"><a class=\"markdownIt-Anchor\" href=\"#三-实现fft的示例代码\">#</a> 三、实现 FFT 的示例代码</h1>\n<p>  以下代码参考<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWRKNG0xYjdieC8/c3BtX2lkX2Zyb209MzMzLjc4OCZhbXA7dmRfc291cmNlPWUwMTE3MmVhMjkyYzFjNjA1YjM0NjEwMWQ3MDA2YzYx\"> https://www.bilibili.com/video/BV1dJ4m1b7bx/?spm_id_from=333.788&amp;vd_source=e01172ea292c1c605b346101d7006c61</span></p>\n<p>  所需的数据文件可以参考<mark> U 盘 - project-python-LLM</mark></p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 本文件提供了 Transfrom 的解码器封装类</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> math</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">import</span> torch</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">as</span> nn</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">from</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">import</span> functional <span class=\"token keyword\">as</span> F</pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token keyword\">import</span> tiktoken</pre></td></tr><tr><td data-num=\"7\"></td><td><pre></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token comment\"># Hyperparameters</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>context_length <span class=\"token operator\">=</span> <span class=\"token number\">128</span>  <span class=\"token comment\"># Length of the token chunk each batch</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>d_model <span class=\"token operator\">=</span> <span class=\"token number\">512</span>  <span class=\"token comment\"># The size of our model token embeddings</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>num_blocks <span class=\"token operator\">=</span> <span class=\"token number\">12</span>  <span class=\"token comment\"># Number of transformer blocks</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>num_heads <span class=\"token operator\">=</span> <span class=\"token number\">8</span>  <span class=\"token comment\"># Number of heads in Multi-head attention</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>dropout <span class=\"token operator\">=</span> <span class=\"token number\">0.1</span>  <span class=\"token comment\"># Dropout rate</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>device <span class=\"token operator\">=</span> <span class=\"token string\">'cuda'</span> <span class=\"token keyword\">if</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>is_available<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">else</span> <span class=\"token string\">'cpu'</span>  <span class=\"token comment\"># Use GPU if it's available.</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>TORCH_SEED <span class=\"token operator\">=</span> <span class=\"token number\">1337</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>torch<span class=\"token punctuation\">.</span>manual_seed<span class=\"token punctuation\">(</span>TORCH_SEED<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre></pre></td></tr><tr><td data-num=\"18\"></td><td><pre><span class=\"token comment\"># Define feed forward network</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">FeedForwardNetwork</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>        self<span class=\"token punctuation\">.</span>ffn <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>            nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">,</span> d_model <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>            nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>            nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>d_model <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>            nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>dropout<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>        <span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>ffn<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre></pre></td></tr><tr><td data-num=\"32\"></td><td><pre></pre></td></tr><tr><td data-num=\"33\"></td><td><pre><span class=\"token comment\"># Define Scaled Dot Product Attention</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">Attention</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>        self<span class=\"token punctuation\">.</span>Wq <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">,</span> d_model <span class=\"token operator\">//</span> num_heads<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre>        self<span class=\"token punctuation\">.</span>Wk <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">,</span> d_model <span class=\"token operator\">//</span> num_heads<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>        self<span class=\"token punctuation\">.</span>Wv <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">,</span> d_model <span class=\"token operator\">//</span> num_heads<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>        self<span class=\"token punctuation\">.</span>register_buffer<span class=\"token punctuation\">(</span><span class=\"token string\">'mask'</span><span class=\"token punctuation\">,</span> torch<span class=\"token punctuation\">.</span>tril<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>ones<span class=\"token punctuation\">(</span>context_length<span class=\"token punctuation\">,</span> context_length<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>        self<span class=\"token punctuation\">.</span>dropout <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>dropout<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre></pre></td></tr><tr><td data-num=\"43\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre>        B<span class=\"token punctuation\">,</span> T<span class=\"token punctuation\">,</span> C <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>shape</pre></td></tr><tr><td data-num=\"45\"></td><td><pre>        q <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Wq<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"46\"></td><td><pre>        k <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Wk<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"47\"></td><td><pre>        v <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>Wv<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"48\"></td><td><pre></pre></td></tr><tr><td data-num=\"49\"></td><td><pre>        weights <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>q @ k<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> math<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>d_model <span class=\"token operator\">//</span> num_heads<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"50\"></td><td><pre>        weights <span class=\"token operator\">=</span> weights<span class=\"token punctuation\">.</span>masked_fill<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>mask<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>T<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span>T<span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span><span class=\"token string\">'-inf'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"51\"></td><td><pre>        weights <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>weights<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"52\"></td><td><pre>        weights <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>dropout<span class=\"token punctuation\">(</span>weights<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"53\"></td><td><pre></pre></td></tr><tr><td data-num=\"54\"></td><td><pre>        output <span class=\"token operator\">=</span> weights @ v</pre></td></tr><tr><td data-num=\"55\"></td><td><pre></pre></td></tr><tr><td data-num=\"56\"></td><td><pre>        <span class=\"token keyword\">return</span> output</pre></td></tr><tr><td data-num=\"57\"></td><td><pre></pre></td></tr><tr><td data-num=\"58\"></td><td><pre></pre></td></tr><tr><td data-num=\"59\"></td><td><pre><span class=\"token comment\"># Define Multi-head Attention</span></pre></td></tr><tr><td data-num=\"60\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">MultiHeadAttention</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"61\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"62\"></td><td><pre>        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"63\"></td><td><pre>        self<span class=\"token punctuation\">.</span>heads <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>ModuleList<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>Attention<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>num_heads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"64\"></td><td><pre>        self<span class=\"token punctuation\">.</span>projection_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"65\"></td><td><pre>        self<span class=\"token punctuation\">.</span>dropout <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>dropout<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"66\"></td><td><pre></pre></td></tr><tr><td data-num=\"67\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"68\"></td><td><pre>        head_outputs <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>head<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> head <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>heads<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"69\"></td><td><pre>        head_outputs <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cat<span class=\"token punctuation\">(</span>head_outputs<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"70\"></td><td><pre>        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>dropout<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>projection_layer<span class=\"token punctuation\">(</span>head_outputs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"71\"></td><td><pre>        <span class=\"token keyword\">return</span> out</pre></td></tr><tr><td data-num=\"72\"></td><td><pre></pre></td></tr><tr><td data-num=\"73\"></td><td><pre></pre></td></tr><tr><td data-num=\"74\"></td><td><pre><span class=\"token comment\"># Define Transformer Block</span></pre></td></tr><tr><td data-num=\"75\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">TransformerBlock</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"76\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"77\"></td><td><pre>        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"78\"></td><td><pre>        self<span class=\"token punctuation\">.</span>ln1 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>LayerNorm<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"79\"></td><td><pre>        self<span class=\"token punctuation\">.</span>ln2 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>LayerNorm<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"80\"></td><td><pre>        self<span class=\"token punctuation\">.</span>mha <span class=\"token operator\">=</span> MultiHeadAttention<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"81\"></td><td><pre>        self<span class=\"token punctuation\">.</span>ffn <span class=\"token operator\">=</span> FeedForwardNetwork<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"82\"></td><td><pre></pre></td></tr><tr><td data-num=\"83\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"84\"></td><td><pre>        x <span class=\"token operator\">=</span> x <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>mha<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>ln1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"85\"></td><td><pre>        x <span class=\"token operator\">=</span> x <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>ffn<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>ln2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"86\"></td><td><pre>        <span class=\"token keyword\">return</span> x</pre></td></tr><tr><td data-num=\"87\"></td><td><pre></pre></td></tr><tr><td data-num=\"88\"></td><td><pre></pre></td></tr><tr><td data-num=\"89\"></td><td><pre><span class=\"token comment\"># Define the model</span></pre></td></tr><tr><td data-num=\"90\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">Model</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"91\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> max_token_value<span class=\"token operator\">=</span><span class=\"token number\">100256</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> <span class=\"token comment\"># if not passed, force to be default tiktoken cl100k vocab size</span></pre></td></tr><tr><td data-num=\"92\"></td><td><pre>        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"93\"></td><td><pre>        self<span class=\"token punctuation\">.</span>token_embedding_lookup_table <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>max_token_value<span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"94\"></td><td><pre>        self<span class=\"token punctuation\">.</span>transformer_blocks <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span><span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"95\"></td><td><pre>                <span class=\"token punctuation\">[</span>TransformerBlock<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>num_blocks<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span></pre></td></tr><tr><td data-num=\"96\"></td><td><pre>                <span class=\"token punctuation\">[</span>nn<span class=\"token punctuation\">.</span>LayerNorm<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"97\"></td><td><pre>        <span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"98\"></td><td><pre>        self<span class=\"token punctuation\">.</span>model_out_linear_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">,</span> max_token_value<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"99\"></td><td><pre></pre></td></tr><tr><td data-num=\"100\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> idx<span class=\"token punctuation\">,</span> targets<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"101\"></td><td><pre>        B<span class=\"token punctuation\">,</span> T <span class=\"token operator\">=</span> idx<span class=\"token punctuation\">.</span>shape</pre></td></tr><tr><td data-num=\"102\"></td><td><pre>        position_encoding_lookup_table <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span>context_length<span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"103\"></td><td><pre>        position <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> context_length<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>unsqueeze<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"104\"></td><td><pre>        div_term <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">-</span>math<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span><span class=\"token number\">10000.0</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> d_model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"105\"></td><td><pre>        position_encoding_lookup_table<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>sin<span class=\"token punctuation\">(</span>position <span class=\"token operator\">*</span> div_term<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"106\"></td><td><pre>        position_encoding_lookup_table<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cos<span class=\"token punctuation\">(</span>position <span class=\"token operator\">*</span> div_term<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"107\"></td><td><pre>        <span class=\"token comment\"># change position_encoding_lookup_table from (context_length, d_model) to (T, d_model)</span></pre></td></tr><tr><td data-num=\"108\"></td><td><pre>        position_embedding <span class=\"token operator\">=</span> position_encoding_lookup_table<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>T<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"109\"></td><td><pre>        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>token_embedding_lookup_table<span class=\"token punctuation\">(</span>idx<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> position_embedding</pre></td></tr><tr><td data-num=\"110\"></td><td><pre>        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>transformer_blocks<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"111\"></td><td><pre>        <span class=\"token comment\"># get the final logits</span></pre></td></tr><tr><td data-num=\"112\"></td><td><pre>        logits <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>model_out_linear_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"113\"></td><td><pre></pre></td></tr><tr><td data-num=\"114\"></td><td><pre>        <span class=\"token keyword\">if</span> targets <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"115\"></td><td><pre>            B<span class=\"token punctuation\">,</span> T<span class=\"token punctuation\">,</span> C <span class=\"token operator\">=</span> logits<span class=\"token punctuation\">.</span>shape</pre></td></tr><tr><td data-num=\"116\"></td><td><pre>            logits_reshaped <span class=\"token operator\">=</span> logits<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>B <span class=\"token operator\">*</span> T<span class=\"token punctuation\">,</span> C<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"117\"></td><td><pre>            targets_reshaped <span class=\"token operator\">=</span> targets<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>B <span class=\"token operator\">*</span> T<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"118\"></td><td><pre>            loss <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>cross_entropy<span class=\"token punctuation\">(</span><span class=\"token builtin\">input</span><span class=\"token operator\">=</span>logits_reshaped<span class=\"token punctuation\">,</span> target<span class=\"token operator\">=</span>targets_reshaped<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"119\"></td><td><pre>        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"120\"></td><td><pre>            loss <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span></pre></td></tr><tr><td data-num=\"121\"></td><td><pre>        <span class=\"token keyword\">return</span> logits<span class=\"token punctuation\">,</span> loss</pre></td></tr><tr><td data-num=\"122\"></td><td><pre></pre></td></tr><tr><td data-num=\"123\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">generate</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> idx<span class=\"token punctuation\">,</span> max_new_tokens<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"124\"></td><td><pre>        <span class=\"token comment\"># idx is (B,T) array of indices in the current context</span></pre></td></tr><tr><td data-num=\"125\"></td><td><pre>        <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>max_new_tokens<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"126\"></td><td><pre>            <span class=\"token comment\"># Crop idx to the max size of our positional embeddings table</span></pre></td></tr><tr><td data-num=\"127\"></td><td><pre>            idx_crop <span class=\"token operator\">=</span> idx<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span>context_length<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"128\"></td><td><pre>            <span class=\"token comment\"># Get predictions</span></pre></td></tr><tr><td data-num=\"129\"></td><td><pre>            logits<span class=\"token punctuation\">,</span> loss <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>forward<span class=\"token punctuation\">(</span>idx_crop<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"130\"></td><td><pre>            <span class=\"token comment\"># Get the last time step from logits where the dimensions of the logits are (B,T,C)</span></pre></td></tr><tr><td data-num=\"131\"></td><td><pre>            logits_last_timestep <span class=\"token operator\">=</span> logits<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"132\"></td><td><pre>            <span class=\"token comment\"># Apply softmax to get probabilities</span></pre></td></tr><tr><td data-num=\"133\"></td><td><pre>            probs <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span><span class=\"token builtin\">input</span><span class=\"token operator\">=</span>logits_last_timestep<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"134\"></td><td><pre>            <span class=\"token comment\"># Sample from the probabilities' distribution.</span></pre></td></tr><tr><td data-num=\"135\"></td><td><pre>            idx_next <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>multinomial<span class=\"token punctuation\">(</span><span class=\"token builtin\">input</span><span class=\"token operator\">=</span>probs<span class=\"token punctuation\">,</span> num_samples<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"136\"></td><td><pre>            <span class=\"token comment\"># Append the sampled indexes idx_next to idx</span></pre></td></tr><tr><td data-num=\"137\"></td><td><pre>            idx <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>idx<span class=\"token punctuation\">,</span> idx_next<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"138\"></td><td><pre>        <span class=\"token keyword\">return</span> idx</pre></td></tr></table></figure><figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>Train a model</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>\"\"\"</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">import</span> os</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">import</span> sys</pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token keyword\">import</span> pickle</pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token keyword\">from</span> contextlib <span class=\"token keyword\">import</span> nullcontext</pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token keyword\">import</span> torch</pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token keyword\">import</span> tiktoken</pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\"># from aim import Run</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre><span class=\"token keyword\">from</span> model <span class=\"token keyword\">import</span> Model</pre></td></tr><tr><td data-num=\"12\"></td><td><pre></pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token comment\"># Hyperparameters</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>batch_size <span class=\"token operator\">=</span> <span class=\"token number\">12</span>  <span class=\"token comment\"># How many batches per training step</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>context_length <span class=\"token operator\">=</span> <span class=\"token number\">128</span>  <span class=\"token comment\"># Length of the token chunk each batch</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>max_iters <span class=\"token operator\">=</span> <span class=\"token number\">1000</span>  <span class=\"token comment\"># Total of training iterations &lt;- Change this to smaller number for testing</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>learning_rate <span class=\"token operator\">=</span> <span class=\"token number\">1e-3</span>  <span class=\"token comment\"># 0.001</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>eval_interval <span class=\"token operator\">=</span> <span class=\"token number\">50</span>  <span class=\"token comment\"># How often to evaluate</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>eval_iters <span class=\"token operator\">=</span> <span class=\"token number\">20</span>  <span class=\"token comment\"># Number of iterations to average for evaluation</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>device <span class=\"token operator\">=</span> <span class=\"token string\">'cuda'</span> <span class=\"token keyword\">if</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>is_available<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">else</span> <span class=\"token string\">'cpu'</span>  <span class=\"token comment\"># Use GPU if it's available.</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>TORCH_SEED <span class=\"token operator\">=</span> <span class=\"token number\">1337</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>torch<span class=\"token punctuation\">.</span>manual_seed<span class=\"token punctuation\">(</span>TORCH_SEED<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre></pre></td></tr><tr><td data-num=\"25\"></td><td><pre></pre></td></tr><tr><td data-num=\"26\"></td><td><pre><span class=\"token comment\"># AIM Logs</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre><span class=\"token comment\"># run = Run()</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre><span class=\"token comment\"># run[\"hparams\"] = &#123;</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre><span class=\"token comment\">#     \"learning_rate\": learning_rate,</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre><span class=\"token comment\">#     \"max_iters\": max_iters,</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre><span class=\"token comment\">#     \"batch_size\": batch_size,</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre><span class=\"token comment\">#     \"context_length\": context_length</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre><span class=\"token comment\"># &#125;</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre></pre></td></tr><tr><td data-num=\"35\"></td><td><pre><span class=\"token comment\"># 准备训练数据</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre><span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'data/scifi.txt'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">\"utf-8\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> <span class=\"token builtin\">file</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>    text <span class=\"token operator\">=</span> <span class=\"token builtin\">file</span><span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre></pre></td></tr><tr><td data-num=\"39\"></td><td><pre></pre></td></tr><tr><td data-num=\"40\"></td><td><pre><span class=\"token comment\"># Using TikToken (Same as GPT3) to tokenize the source text</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>encoding <span class=\"token operator\">=</span> tiktoken<span class=\"token punctuation\">.</span>get_encoding<span class=\"token punctuation\">(</span><span class=\"token string\">\"cl100k_base\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre>tokenized_text <span class=\"token operator\">=</span> encoding<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"43\"></td><td><pre><span class=\"token comment\"># max_token_value = max(tokenized_text)+1  # the maximum value of the tokenized numbers</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre>tokenized_text <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span>tokenized_text<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">long</span><span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 将 77,919 个 tokens 转换到 Pytorch 张量中</span></pre></td></tr><tr><td data-num=\"45\"></td><td><pre></pre></td></tr><tr><td data-num=\"46\"></td><td><pre>total_tokens <span class=\"token operator\">=</span> encoding<span class=\"token punctuation\">.</span>encode_ordinary<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"47\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"数据集合计有 </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>total_tokens<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">,</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\"> tokens\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"48\"></td><td><pre></pre></td></tr><tr><td data-num=\"49\"></td><td><pre></pre></td></tr><tr><td data-num=\"50\"></td><td><pre><span class=\"token comment\"># vocab = sorted(list(set(text)))</span></pre></td></tr><tr><td data-num=\"51\"></td><td><pre><span class=\"token comment\"># vocab_size = max_token_value = len(vocab)</span></pre></td></tr><tr><td data-num=\"52\"></td><td><pre></pre></td></tr><tr><td data-num=\"53\"></td><td><pre><span class=\"token comment\"># char2idx = &#123;char: idx for idx, char in enumerate(vocab)&#125;</span></pre></td></tr><tr><td data-num=\"54\"></td><td><pre><span class=\"token comment\"># idx2char = &#123;idx: char for char, idx in char2idx.items()&#125;</span></pre></td></tr><tr><td data-num=\"55\"></td><td><pre><span class=\"token comment\"># encode = lambda x: [char2idx[char] for char in x]</span></pre></td></tr><tr><td data-num=\"56\"></td><td><pre><span class=\"token comment\"># decode = lambda idxs: ''.join([idx2char[idx] for idx in idxs])</span></pre></td></tr><tr><td data-num=\"57\"></td><td><pre><span class=\"token comment\"># tokenized_text = torch.tensor(encode(text), dtype=torch.long)</span></pre></td></tr><tr><td data-num=\"58\"></td><td><pre></pre></td></tr><tr><td data-num=\"59\"></td><td><pre><span class=\"token comment\"># Split train and validation</span></pre></td></tr><tr><td data-num=\"60\"></td><td><pre>train_size <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>tokenized_text<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">0.9</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"61\"></td><td><pre>train_data <span class=\"token operator\">=</span> tokenized_text<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>train_size<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"62\"></td><td><pre>val_data <span class=\"token operator\">=</span> tokenized_text<span class=\"token punctuation\">[</span>train_size<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"63\"></td><td><pre></pre></td></tr><tr><td data-num=\"64\"></td><td><pre></pre></td></tr><tr><td data-num=\"65\"></td><td><pre><span class=\"token comment\"># Initialize the model</span></pre></td></tr><tr><td data-num=\"66\"></td><td><pre>model <span class=\"token operator\">=</span> Model<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"67\"></td><td><pre></pre></td></tr><tr><td data-num=\"68\"></td><td><pre><span class=\"token comment\"># get batch</span></pre></td></tr><tr><td data-num=\"69\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">get_batch</span><span class=\"token punctuation\">(</span>split<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"70\"></td><td><pre>    data <span class=\"token operator\">=</span> train_data <span class=\"token keyword\">if</span> split <span class=\"token operator\">==</span> <span class=\"token string\">'train'</span> <span class=\"token keyword\">else</span> val_data</pre></td></tr><tr><td data-num=\"71\"></td><td><pre>    idxs <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>randint<span class=\"token punctuation\">(</span>low<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> high<span class=\"token operator\">=</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> context_length<span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"72\"></td><td><pre>    x <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>stack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>idx<span class=\"token punctuation\">:</span>idx <span class=\"token operator\">+</span> context_length<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> idx <span class=\"token keyword\">in</span> idxs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"73\"></td><td><pre>    y <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>stack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>idx <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>idx <span class=\"token operator\">+</span> context_length <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> idx <span class=\"token keyword\">in</span> idxs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"74\"></td><td><pre>    <span class=\"token keyword\">return</span> x<span class=\"token punctuation\">,</span> y</pre></td></tr><tr><td data-num=\"75\"></td><td><pre></pre></td></tr><tr><td data-num=\"76\"></td><td><pre></pre></td></tr><tr><td data-num=\"77\"></td><td><pre><span class=\"token comment\"># calculate the loss</span></pre></td></tr><tr><td data-num=\"78\"></td><td><pre><span class=\"token decorator annotation punctuation\">@torch<span class=\"token punctuation\">.</span>no_grad</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"79\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">estimate_loss</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"80\"></td><td><pre>    out <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"81\"></td><td><pre>    model<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"82\"></td><td><pre>    <span class=\"token keyword\">for</span> split <span class=\"token keyword\">in</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'train'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'valid'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"83\"></td><td><pre>        losses <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span>eval_iters<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"84\"></td><td><pre>        <span class=\"token keyword\">for</span> k <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>eval_iters<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"85\"></td><td><pre>            x_batch<span class=\"token punctuation\">,</span> y_batch <span class=\"token operator\">=</span> get_batch<span class=\"token punctuation\">(</span>split<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"86\"></td><td><pre>            logits<span class=\"token punctuation\">,</span> loss <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>x_batch<span class=\"token punctuation\">,</span> y_batch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"87\"></td><td><pre>            losses<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> loss<span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"88\"></td><td><pre>        out<span class=\"token punctuation\">[</span>split<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> losses<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"89\"></td><td><pre>    model<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"90\"></td><td><pre>    <span class=\"token keyword\">return</span> out</pre></td></tr><tr><td data-num=\"91\"></td><td><pre></pre></td></tr><tr><td data-num=\"92\"></td><td><pre></pre></td></tr><tr><td data-num=\"93\"></td><td><pre><span class=\"token comment\"># Create the optimizer</span></pre></td></tr><tr><td data-num=\"94\"></td><td><pre>optimizer <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>optim<span class=\"token punctuation\">.</span>AdamW<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span>learning_rate<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"95\"></td><td><pre>tracked_losses <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"96\"></td><td><pre><span class=\"token keyword\">for</span> step <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>max_iters<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"97\"></td><td><pre>    <span class=\"token keyword\">if</span> step <span class=\"token operator\">%</span> eval_iters <span class=\"token operator\">==</span> <span class=\"token number\">0</span> <span class=\"token keyword\">or</span> step <span class=\"token operator\">==</span> max_iters <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"98\"></td><td><pre>        losses <span class=\"token operator\">=</span> estimate_loss<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"99\"></td><td><pre>        tracked_losses<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>losses<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"100\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Step:'</span><span class=\"token punctuation\">,</span> step<span class=\"token punctuation\">,</span> <span class=\"token string\">'Training Loss:'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>losses<span class=\"token punctuation\">[</span><span class=\"token string\">'train'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Validation Loss:'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>losses<span class=\"token punctuation\">[</span><span class=\"token string\">'valid'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"101\"></td><td><pre>        <span class=\"token comment\"># run.track(round(losses['train'].item(), 3), name='Training Loss')</span></pre></td></tr><tr><td data-num=\"102\"></td><td><pre>        <span class=\"token comment\"># run.track(round(losses['valid'].item(), 3), name='Validation Loss')</span></pre></td></tr><tr><td data-num=\"103\"></td><td><pre></pre></td></tr><tr><td data-num=\"104\"></td><td><pre>    xb<span class=\"token punctuation\">,</span> yb <span class=\"token operator\">=</span> get_batch<span class=\"token punctuation\">(</span><span class=\"token string\">'train'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"105\"></td><td><pre>    logits<span class=\"token punctuation\">,</span> loss <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>xb<span class=\"token punctuation\">,</span> yb<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"106\"></td><td><pre>    optimizer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span>set_to_none<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"107\"></td><td><pre>    loss<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"108\"></td><td><pre>    optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"109\"></td><td><pre></pre></td></tr><tr><td data-num=\"110\"></td><td><pre><span class=\"token comment\"># Save the model</span></pre></td></tr><tr><td data-num=\"111\"></td><td><pre>torch<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>state_dict<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'model/model-scifi.pt'</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>Fine-tune a model</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>\"\"\"</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">import</span> os</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">import</span> sys</pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token keyword\">import</span> pickle</pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token keyword\">from</span> contextlib <span class=\"token keyword\">import</span> nullcontext</pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token keyword\">import</span> torch</pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token keyword\">import</span> tiktoken</pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\"># from aim import Run</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre><span class=\"token keyword\">from</span> model <span class=\"token keyword\">import</span> Model</pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token keyword\">import</span> json</pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre></pre></td></tr><tr><td data-num=\"15\"></td><td><pre><span class=\"token comment\"># Hyperparameters</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>batch_size <span class=\"token operator\">=</span> <span class=\"token number\">8</span>  <span class=\"token comment\"># How many batches per training step</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>context_length <span class=\"token operator\">=</span> <span class=\"token number\">128</span>  <span class=\"token comment\"># Length of the token chunk each batch</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>max_iters <span class=\"token operator\">=</span> <span class=\"token number\">500</span>  <span class=\"token comment\"># Total of training iterations &lt;- Change this to smaller number for testing</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>learning_rate <span class=\"token operator\">=</span> <span class=\"token number\">1e-4</span>  <span class=\"token comment\"># 0.001</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>eval_interval <span class=\"token operator\">=</span> <span class=\"token number\">10</span>  <span class=\"token comment\"># How often to evaluate</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>eval_iters <span class=\"token operator\">=</span> <span class=\"token number\">10</span>  <span class=\"token comment\"># Number of iterations to average for evaluation</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>device <span class=\"token operator\">=</span> <span class=\"token string\">'cuda'</span> <span class=\"token keyword\">if</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>is_available<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">else</span> <span class=\"token string\">'cpu'</span>  <span class=\"token comment\"># Use GPU if it's available.</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>TORCH_SEED <span class=\"token operator\">=</span> <span class=\"token number\">1337</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>torch<span class=\"token punctuation\">.</span>manual_seed<span class=\"token punctuation\">(</span>TORCH_SEED<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre></pre></td></tr><tr><td data-num=\"26\"></td><td><pre></pre></td></tr><tr><td data-num=\"27\"></td><td><pre><span class=\"token comment\"># 准备训练数据</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre><span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'data/scifi-finetune.json'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> <span class=\"token builtin\">file</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>    alpaca <span class=\"token operator\">=</span> json<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>    text <span class=\"token operator\">=</span> alpaca<span class=\"token punctuation\">[</span><span class=\"token number\">1000</span><span class=\"token punctuation\">:</span><span class=\"token number\">5001</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre></pre></td></tr><tr><td data-num=\"32\"></td><td><pre><span class=\"token comment\"># print(text)</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre><span class=\"token comment\"># sys.exit(0)</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre></pre></td></tr><tr><td data-num=\"35\"></td><td><pre><span class=\"token comment\"># Using TikToken (Same as GPT3) to tokenize the source text</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>encoding <span class=\"token operator\">=</span> tiktoken<span class=\"token punctuation\">.</span>get_encoding<span class=\"token punctuation\">(</span><span class=\"token string\">\"cl100k_base\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>tokenized_text <span class=\"token operator\">=</span> encoding<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre>tokenized_text <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span>tokenized_text<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">long</span><span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 将 77,919 个 tokens 转换到 Pytorch 张量中</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>total_tokens <span class=\"token operator\">=</span> encoding<span class=\"token punctuation\">.</span>encode_ordinary<span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"数据集合计有 </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>total_tokens<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">,</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\"> tokens\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre></pre></td></tr><tr><td data-num=\"43\"></td><td><pre></pre></td></tr><tr><td data-num=\"44\"></td><td><pre><span class=\"token comment\"># Split train and validation</span></pre></td></tr><tr><td data-num=\"45\"></td><td><pre>train_size <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>tokenized_text<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">0.9</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"46\"></td><td><pre>train_data <span class=\"token operator\">=</span> tokenized_text<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>train_size<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"47\"></td><td><pre>val_data <span class=\"token operator\">=</span> tokenized_text<span class=\"token punctuation\">[</span>train_size<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"48\"></td><td><pre></pre></td></tr><tr><td data-num=\"49\"></td><td><pre></pre></td></tr><tr><td data-num=\"50\"></td><td><pre><span class=\"token comment\"># Initialize the model</span></pre></td></tr><tr><td data-num=\"51\"></td><td><pre>model <span class=\"token operator\">=</span> Model<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"52\"></td><td><pre>model<span class=\"token punctuation\">.</span>load_state_dict<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token string\">'model/model-scifi.pt'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"53\"></td><td><pre>model<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"54\"></td><td><pre></pre></td></tr><tr><td data-num=\"55\"></td><td><pre></pre></td></tr><tr><td data-num=\"56\"></td><td><pre><span class=\"token comment\"># get batch</span></pre></td></tr><tr><td data-num=\"57\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">get_batch</span><span class=\"token punctuation\">(</span>split<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"58\"></td><td><pre>    data <span class=\"token operator\">=</span> train_data <span class=\"token keyword\">if</span> split <span class=\"token operator\">==</span> <span class=\"token string\">'train'</span> <span class=\"token keyword\">else</span> val_data</pre></td></tr><tr><td data-num=\"59\"></td><td><pre>    idxs <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>randint<span class=\"token punctuation\">(</span>low<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> high<span class=\"token operator\">=</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> context_length<span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"60\"></td><td><pre>    x <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>stack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>idx<span class=\"token punctuation\">:</span>idx <span class=\"token operator\">+</span> context_length<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> idx <span class=\"token keyword\">in</span> idxs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"61\"></td><td><pre>    y <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>stack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>idx <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>idx <span class=\"token operator\">+</span> context_length <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> idx <span class=\"token keyword\">in</span> idxs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"62\"></td><td><pre>    <span class=\"token keyword\">return</span> x<span class=\"token punctuation\">,</span> y</pre></td></tr><tr><td data-num=\"63\"></td><td><pre></pre></td></tr><tr><td data-num=\"64\"></td><td><pre></pre></td></tr><tr><td data-num=\"65\"></td><td><pre><span class=\"token comment\"># calculate the loss</span></pre></td></tr><tr><td data-num=\"66\"></td><td><pre><span class=\"token decorator annotation punctuation\">@torch<span class=\"token punctuation\">.</span>no_grad</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"67\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">estimate_loss</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"68\"></td><td><pre>    out <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"69\"></td><td><pre>    model<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"70\"></td><td><pre>    <span class=\"token keyword\">for</span> split <span class=\"token keyword\">in</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'train'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'valid'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"71\"></td><td><pre>        losses <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span>eval_iters<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"72\"></td><td><pre>        <span class=\"token keyword\">for</span> k <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>eval_iters<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"73\"></td><td><pre>            x_batch<span class=\"token punctuation\">,</span> y_batch <span class=\"token operator\">=</span> get_batch<span class=\"token punctuation\">(</span>split<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"74\"></td><td><pre>            logits<span class=\"token punctuation\">,</span> loss <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>x_batch<span class=\"token punctuation\">,</span> y_batch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"75\"></td><td><pre>            losses<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> loss<span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"76\"></td><td><pre>        out<span class=\"token punctuation\">[</span>split<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> losses<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"77\"></td><td><pre>    model<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"78\"></td><td><pre>    <span class=\"token keyword\">return</span> out</pre></td></tr><tr><td data-num=\"79\"></td><td><pre></pre></td></tr><tr><td data-num=\"80\"></td><td><pre></pre></td></tr><tr><td data-num=\"81\"></td><td><pre><span class=\"token comment\"># Create the optimizer</span></pre></td></tr><tr><td data-num=\"82\"></td><td><pre>optimizer <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>optim<span class=\"token punctuation\">.</span>AdamW<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span>learning_rate<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"83\"></td><td><pre>tracked_losses <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"84\"></td><td><pre><span class=\"token keyword\">for</span> step <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>max_iters<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"85\"></td><td><pre>    <span class=\"token keyword\">if</span> step <span class=\"token operator\">%</span> eval_iters <span class=\"token operator\">==</span> <span class=\"token number\">0</span> <span class=\"token keyword\">or</span> step <span class=\"token operator\">==</span> max_iters <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"86\"></td><td><pre>        losses <span class=\"token operator\">=</span> estimate_loss<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"87\"></td><td><pre>        tracked_losses<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>losses<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"88\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Step:'</span><span class=\"token punctuation\">,</span> step<span class=\"token punctuation\">,</span> <span class=\"token string\">'Training Loss:'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>losses<span class=\"token punctuation\">[</span><span class=\"token string\">'train'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Validation Loss:'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>losses<span class=\"token punctuation\">[</span><span class=\"token string\">'valid'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"89\"></td><td><pre></pre></td></tr><tr><td data-num=\"90\"></td><td><pre>    xb<span class=\"token punctuation\">,</span> yb <span class=\"token operator\">=</span> get_batch<span class=\"token punctuation\">(</span><span class=\"token string\">'train'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"91\"></td><td><pre>    logits<span class=\"token punctuation\">,</span> loss <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>xb<span class=\"token punctuation\">,</span> yb<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"92\"></td><td><pre>    optimizer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span>set_to_none<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"93\"></td><td><pre>    loss<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"94\"></td><td><pre>    optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"95\"></td><td><pre></pre></td></tr><tr><td data-num=\"96\"></td><td><pre><span class=\"token comment\"># Save the model</span></pre></td></tr><tr><td data-num=\"97\"></td><td><pre>torch<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>state_dict<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'model/model-scifi-finetune.pt'</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># -*- coding: utf-8 -*-</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>Sample from a trained model</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>\"\"\"</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">import</span> os</pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token keyword\">import</span> pickle</pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token keyword\">from</span> contextlib <span class=\"token keyword\">import</span> nullcontext</pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token keyword\">import</span> torch</pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token keyword\">import</span> tiktoken</pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token keyword\">from</span> model <span class=\"token keyword\">import</span> Model</pre></td></tr><tr><td data-num=\"11\"></td><td><pre></pre></td></tr><tr><td data-num=\"12\"></td><td><pre></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token comment\"># Hyperparameters</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>device <span class=\"token operator\">=</span> <span class=\"token string\">'cuda'</span> <span class=\"token keyword\">if</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>is_available<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">else</span> <span class=\"token string\">'cpu'</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>TORCH_SEED <span class=\"token operator\">=</span> <span class=\"token number\">1337</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>torch<span class=\"token punctuation\">.</span>manual_seed<span class=\"token punctuation\">(</span>TORCH_SEED<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>manual_seed<span class=\"token punctuation\">(</span>TORCH_SEED<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre></pre></td></tr><tr><td data-num=\"19\"></td><td><pre></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>encoding <span class=\"token operator\">=</span> tiktoken<span class=\"token punctuation\">.</span>get_encoding<span class=\"token punctuation\">(</span><span class=\"token string\">\"cl100k_base\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre></pre></td></tr><tr><td data-num=\"22\"></td><td><pre></pre></td></tr><tr><td data-num=\"23\"></td><td><pre><span class=\"token comment\"># Initiate from trained model</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>model <span class=\"token operator\">=</span> Model<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre><span class=\"token comment\"># model.load_state_dict(torch.load('model/model-scifi-finetune.pt'))</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>model<span class=\"token punctuation\">.</span>load_state_dict<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token string\">'model/model-scifi.pt'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>model<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>model<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>start <span class=\"token operator\">=</span> <span class=\"token string\">'Write a short story about Sam Altman.'</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre><span class=\"token comment\"># start = 'Sam Altman was born in'</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>start_ids <span class=\"token operator\">=</span> encoding<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span>start<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>x <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span>start_ids<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">long</span><span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre></pre></td></tr><tr><td data-num=\"35\"></td><td><pre><span class=\"token comment\"># run generation</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre><span class=\"token keyword\">with</span> torch<span class=\"token punctuation\">.</span>no_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>    y <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>generate<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> max_new_tokens<span class=\"token operator\">=</span><span class=\"token number\">500</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'---------------'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>encoding<span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>tolist<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'---------------'</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure>",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/02/01/AI/Neural_networks_classification/",
            "url": "http://qianqiu-cell.github.io/2024/02/01/AI/Neural_networks_classification/",
            "title": "神经网络大致分类",
            "date_published": "2024-01-31T16:00:00.000Z",
            "content_html": "<p>参考文章：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8yNjg3MDk2MTg=\">https://zhuanlan.zhihu.com/p/268709618</span><br>\n<img data-src=\"/images/AI/Neural_networks_classification/0.1.png\" alt=\"\"></p>\n<h1 id=\"一-mp神经元模型\"><a class=\"markdownIt-Anchor\" href=\"#一-mp神经元模型\">#</a> 一、MP 神经元模型</h1>\n<p>  MP 模型是针对生物神经元的一些基本生理特征所提出的形式神经元的数学模型与结构，其权值被认为是不可调整的。MP 神经元模型是其他神经网络的基础。<br>\n<img data-src=\"/images/AI/Neural_networks_classification/1.1.png\" alt=\"\"></p>\n<h1 id=\"二-前馈神经网络fnn\"><a class=\"markdownIt-Anchor\" href=\"#二-前馈神经网络fnn\">#</a> 二、前馈神经网络（FNN）</h1>\n<p>  对于前馈网络，根据神经元的传递函数不同，以及学习算法和网络结构上的区别，可以细分类感知器网络、线性网络、BP 网络、径向基网络及 GMDH 网络等不同的网络模型。</p>\n<h2 id=\"21-感知器pla\"><a class=\"markdownIt-Anchor\" href=\"#21-感知器pla\">#</a> 2.1 感知器（PLA）</h2>\n<p>  感知器模型（Percetron Learning Algorithm，简称 PLA）是由美国学者 F.Rosenblatt 于 1958 年提出的。它与 MP 模型的不同之处是它假定神经元的突触权值是可变的，这样就可以进行学习。感知器是最简单形式的前馈神经网络，是一种二元线性分类器。<br>\n<img data-src=\"/images/AI/Neural_networks_classification/1.2.png\" alt=\"\"><br>\n  感知器具有如下的局限性：</p>\n<ul>\n<li>感知器神经网络的传输函数一般采用阈值函数，所以输出值只有两种；</li>\n<li>单层感知器网络只能用于解决线性可分的分类问题，而对线性不可分的分类问题无能为力；</li>\n<li>感知器学习算法只适于单层感知器网络，所以一般感知器网络都是单层的。</li>\n</ul>\n<h2 id=\"22-多层感知器mlp\"><a class=\"markdownIt-Anchor\" href=\"#22-多层感知器mlp\">#</a> 2.2 多层感知器（MLP）</h2>\n<p>  多层感知器（Multilayer Perceptron, 简称 MLP）是感知器的推广，克服了感知器不能对线性不可分数据进行识别的弱点。对于非线性函数的模拟，需要采用 MLP，即在最初的输入和输出层之间隐藏着一到多个层。<br>\n  <mark>全连接神经网络（Fully Connected Neural Network，简称 FNN），深度神经网络（ Deep Neural Networks，简称 DNN）和 MLP 的概念相似，只是侧重点不同。一个多层全连接神经网络即使 MLP，又是 FNN，同时也是 DNN。</mark><br>\n  <mark>BP 神经网络是指使用了 BP 算法（ Back Propagation，反向传播）进行训练的 MLP 模型。</mark></p>\n<h2 id=\"23-径向基神经网络rbfnn\"><a class=\"markdownIt-Anchor\" href=\"#23-径向基神经网络rbfnn\">#</a> 2.3 径向基神经网络（RBFNN）</h2>\n<p>参考链接： <span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDgwMjY3Ni9hcnRpY2xlL2RldGFpbHMvMTAwODA1NTQ1\">https://blog.csdn.net/weixin_40802676/article/details/100805545</span><br>\n  首先介绍径向基函数（ Radial Basis Function，简称 RBF）：<br>\n<img data-src=\"/images/AI/Neural_networks_classification/1.3.png\" alt=\"\"><br>\n  最常用的径向基函数是高斯函数（radbas）。<br>\n<img data-src=\"/images/AI/Neural_networks_classification/1.4.png\" alt=\"\"><br>\n  RBFNN 的神经网络节后如上图所示。三层的神经网络就可以拟合任何一个函数，RBFNN 即为三层（单隐层）且隐藏层使用径向基函数的神经网络。因此 RBFNN 完全可以拟合任何一个函数（只要隐藏层神经元足够多）。输入层到隐藏层的神经元之间的权重全部为 1。隐藏层是使用径向基函数作为激活函数的神经元。隐藏层与输出层之间就是普通的神经网络的连接关系，他们之间的权重可以训练而改变。<br>\n  RBFNN 的关键就在于径向基函数的确定，中心点在哪，径基宽度多大，多少个径向基函数，都是会影响神经网络的效果的。广义回归神经网络 (General Regression Neural Network，简称 GRNN) 和广义回归神经网络 (General Regression Neural Network，简称 GPNN) 都是 RBFNN 的变化形式。</p>\n<h2 id=\"24-卷积神经网络cnn\"><a class=\"markdownIt-Anchor\" href=\"#24-卷积神经网络cnn\">#</a> 2.4 卷积神经网络（CNN）</h2>\n<p>  卷积神经网络（Convolutional Neural Networks，简称 CNN）是一种深度学习模型或类似于人工神经网络的多层感知器，常用来分析视觉图像。<br>\n<img data-src=\"/images/AI/Neural_networks_classification/1.5.png\" alt=\"\"><br>\n  一个卷积神经网络主要由以下 5 层组成：</p>\n<ul>\n<li>数据输入层 / Input layer</li>\n<li>卷积计算层 / CONV layer</li>\n<li>ReLU 激励层 / ReLU layer</li>\n<li>池化层     / Pooling layer</li>\n<li>全连接层   / FC layer</li>\n</ul>\n<h2 id=\"25-线性神经网咯\"><a class=\"markdownIt-Anchor\" href=\"#25-线性神经网咯\">#</a> 2.5 线性神经网咯</h2>\n<p>  线性神经网络与感知器的主要区别在于感知器的激活函数只能输出两种可能值（-1 或 1），而线性神经网络的输出可以取任意值，其激活函数是线性函数。<br>\n  线性神经网络采用 Widrow-Hoff 学习规则（最小均方规则），即 LMS（Least Mean Square）算法来调整网络的权值和偏置值。结构图如下。这里使用 purelin 激活函数进行模型训练，这样可以得到一个更好的效果。输出结果的时候还是使用 sign 激活函数。<br>\n<img data-src=\"/images/AI/Neural_networks_classification/1.6.png\" alt=\"\"><br>\n<img data-src=\"/images/AI/Neural_networks_classification/1.7.png\" alt=\"\"></p>\n<h1 id=\"三-反馈神经网络\"><a class=\"markdownIt-Anchor\" href=\"#三-反馈神经网络\">#</a> 三、反馈神经网络</h1>\n<p>  所谓反馈网络是指在网络中至少含有一个反馈回路的神经网络。反馈网络可以包含一个单层神经元，其中每个神经元将自身的输出信号反馈给其他所有神经元的输入 反馈神经网络中神经元不但可以接收其他神经元的信号，而且可以接收自己的反馈信号。和前馈神经网络相比，反馈神经网络中的神经元具有记忆功能，在不同时刻具有不同的状态。反馈神经网络中的信息传播可以是单向也可以是双向传播，因此可以用一个有向循环图或者无向图来表示。</p>\n<h2 id=\"31-循环神经网络rnn\"><a class=\"markdownIt-Anchor\" href=\"#31-循环神经网络rnn\">#</a> 3.1 循环神经网络（RNN）</h2>\n<p>  循环神经网络（Recurrent Neural Network，简称 RNN）是一种深度学习模型，专门用于处理序列数据和具有时间依赖性的任务。相比于传统神经网络，RNN 具有一种递归结构，使其能够对序列信息进行处理。<br>\n  RNN 的主要特点是它能够保持对之前输入信息的记忆，这使得它在处理时间序列、自然语言处理等任务时非常有效。它的基本结构包括一个隐藏层，其中的神经元可以接收输入数据和前一个时间步的隐藏状态，并输出一个新的隐藏状态。这种递归结构使得 RNN 能够捕捉序列中的上下文信息，从而更好地理解和处理序列数据。<br>\n  然而，传统的 RNN 存在梯度消失和梯度爆炸等问题，导致难以捕捉长期依赖关系。为了解决这些问题，一些改进型的循环神经网络被提出，如长短时记忆网络（Long Short-Term Memory，简称 LSTM）和门控循环单元（Gated Recurrent Unit，简称 GRU）。这些改进模型引入了门控机制，使得网络能够更好地处理长期依赖关系，从而提高了性能。<br>\n  总的来说，循环神经网络在处理序列数据方面具有广泛的应用，包括自然语言处理、语音识别、时间序列预测等领域。</p>\n<h2 id=\"32-hopfield神经网络\"><a class=\"markdownIt-Anchor\" href=\"#32-hopfield神经网络\">#</a> 3.2 Hopfield 神经网络</h2>\n<p>  Hopfield 神经网络是一种反馈型的人工神经网络，最初由物理学家约翰・霍普菲尔德（John Hopfield）于 1982 年提出。它主要用于模拟和处理离散型动力系统，尤其在解决优化问题和模式识别方面应用广泛。根据其激活函数的不同，Hopfield 神经网络有两种：离散 Hopfield 网络（Discrete Hopfield Neural Network，简称 DHNN）和连续 Hopfield 网络（Continues Hopfield Neural Network，简称 CHNN）。</p>\n<h1 id=\"四-对抗神经网络gan\"><a class=\"markdownIt-Anchor\" href=\"#四-对抗神经网络gan\">#</a> 四、对抗神经网络（GAN）</h1>\n<p>  简介：对抗神经网络其实是两个网络的组合，可以理解为一个网络生成模拟数据，另一个网络判断生成的数据是真实的还是模拟的。生成模拟数据的网络要不断优化自己让判别的网络判断不出来，判别的网络也要不断优化自己让判断的更加精确。两者的关系形成对抗，因此叫对抗神经网络。<br>\n  结构：GAN 由 generator（生成模型）和 discriminator（判别式模型）两部分构成。二者结合之后，经过大量次数的迭代训练会使 generator 尽可能模拟出以假乱真的样本，而 discrimator 会有更精确的鉴别真伪数据的能力，最终整个 GAN 会达到所谓的纳什均衡，即 discriminator 对于 generator 的数据鉴别结果为正确率和错误率各占 50%。</p>\n<h1 id=\"五-自组织神经网络\"><a class=\"markdownIt-Anchor\" href=\"#五-自组织神经网络\">#</a> 五、自组织神经网络</h1>\n<p>  在生物神经系统中，存在着一种侧抑制现象，即一个神经细胞兴奋以后，会对周围其他神经细胞产生抑制作用。这种抑制作用会使神经细胞之间出现竞争，其结果是某些获胜，而另一些则失败。表现形式是获胜神经细胞兴奋，失败神经细胞抑制。自组织（竞争型）神经网络就是模拟上述生物神经系统功能的人工神经网络。</p>\n<h1 id=\"六-反馈神经网络\"><a class=\"markdownIt-Anchor\" href=\"#六-反馈神经网络\">#</a> 六、反馈神经网络</h1>\n<p>  一般的神经网络模型通常假定网络结构是事先固定的，训练的目的是利用训练样本来确定合适的连接权、阙值等参数。与此不同，结构自适应网络则将网络结构也当作学习的目标之一，并希望能在训练过程中找到最利合数据特点的网络结构</p>\n<h1 id=\"七-反馈神经网络\"><a class=\"markdownIt-Anchor\" href=\"#七-反馈神经网络\">#</a> 七、反馈神经网络</h1>\n<p>  随机神经网络是对神经网络引入随机机制，认为神经元是按照概率的原理进行工作的，这就是说，每个神经元的兴奋或抑制具有随机性，其概率取决于神经元的输入。</p>\n",
            "tags": [
                "AI"
            ]
        }
    ]
}