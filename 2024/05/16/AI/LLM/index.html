



<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#FFF">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">


<link rel="alternate" type="application/rss+xml" title="Keep Moving" href="http://qianqiu-cell.github.io/rss.xml" />
<link rel="alternate" type="application/atom+xml" title="Keep Moving" href="http://qianqiu-cell.github.io/atom.xml" />
<link rel="alternate" type="application/json" title="Keep Moving" href="http://qianqiu-cell.github.io/feed.json" />

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="/css/app.css?v=0.2.5">

  
  <meta name="keywords" content="AI" />


<link rel="canonical" href="http://qianqiu-cell.github.io/2024/05/16/AI/LLM/">



  <title>
å¤§æ¨¡å‹LLMå­¦ä¹  - AI |
å”¯çˆ±ãºç¬babyãƒ« = Keep Moving = å¤©å°†é™å¤§ä»»äºæ–¯äººä¹Ÿ</title>
<meta name="generator" content="Hexo 6.3.0"></head>
<body itemscope itemtype="http://schema.org/WebPage">
  <div id="loading">
    <div class="cat">
      <div class="body"></div>
      <div class="head">
        <div class="face"></div>
      </div>
      <div class="foot">
        <div class="tummy-end"></div>
        <div class="bottom"></div>
        <div class="legs left"></div>
        <div class="legs right"></div>
      </div>
      <div class="paw">
        <div class="hands left"></div>
        <div class="hands right"></div>
      </div>
    </div>
  </div>
  <div id="container">
    <header id="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="inner">
        <div id="brand">
          <div class="pjax">
          
  <h1 itemprop="name headline">å¤§æ¨¡å‹LLMå­¦ä¹ 
  </h1>
  
<div class="meta">
  <span class="item" title="åˆ›å»ºæ—¶é—´ï¼š2024-05-16 00:00:00">
    <span class="icon">
      <i class="ic i-calendar"></i>
    </span>
    <span class="text">å‘è¡¨äº</span>
    <time itemprop="dateCreated datePublished" datetime="2024-05-16T00:00:00+08:00">2024-05-16</time>
  </span>
  <span class="item" title="æœ¬æ–‡å­—æ•°">
    <span class="icon">
      <i class="ic i-pen"></i>
    </span>
    <span class="text">æœ¬æ–‡å­—æ•°</span>
    <span>15k</span>
    <span class="text">å­—</span>
  </span>
  <span class="item" title="é˜…è¯»æ—¶é•¿">
    <span class="icon">
      <i class="ic i-clock"></i>
    </span>
    <span class="text">é˜…è¯»æ—¶é•¿</span>
    <span>14 åˆ†é’Ÿ</span>
  </span>
</div>


          </div>
        </div>
        <nav id="nav">
  <div class="inner">
    <div class="toggle">
      <div class="lines" aria-label="åˆ‡æ¢å¯¼èˆªæ ">
        <span class="line"></span>
        <span class="line"></span>
        <span class="line"></span>
      </div>
    </div>
    <ul class="menu">
      <li class="item title"><a href="/" rel="start">å”¯çˆ±ãºç¬babyãƒ«</a></li>
    </ul>
    <ul class="right">
      <li class="item theme">
        <i class="ic i-sun"></i>
      </li>
      <li class="item search">
        <i class="ic i-search"></i>
      </li>
    </ul>
  </div>
</nav>

      </div>
      <div id="imgs" class="pjax">
        <ul>
          <li class="item" data-background-image="https://i.postimg.cc/0yS7gzhX/img-2000891315.jpg"></li>
          <li class="item" data-background-image="https://i.postimg.cc/tRfb1Jmz/img-2000880084.jpg"></li>
          <li class="item" data-background-image="https://i.postimg.cc/nLq3YFxg/img-2000959067.jpg"></li>
          <li class="item" data-background-image="https://i.postimg.cc/DzqTN4Lc/img-2001089444.jpg"></li>
          <li class="item" data-background-image="https://i.postimg.cc/yYQfPpZh/img-2001032858.jpg"></li>
          <li class="item" data-background-image="https://i.postimg.cc/yxJwXq8G/img-2001040529.jpg"></li>
        </ul>
      </div>
    </header>
    <div id="waves">
      <svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto">
        <defs>
          <path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z" />
        </defs>
        <g class="parallax">
          <use xlink:href="#gentle-wave" x="48" y="0" />
          <use xlink:href="#gentle-wave" x="48" y="3" />
          <use xlink:href="#gentle-wave" x="48" y="5" />
          <use xlink:href="#gentle-wave" x="48" y="7" />
        </g>
      </svg>
    </div>
    <main>
      <div class="inner">
        <div id="main" class="pjax">
          
  <div class="article wrap">
    
<div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList">
<i class="ic i-home"></i>
<span><a href="/">é¦–é¡µ</a></span><i class="ic i-angle-right"></i>
<span  class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/AI/" itemprop="item" rel="index" title="åˆ†ç±»äº AI"><span itemprop="name">AI</span></a>
<meta itemprop="position" content="1" /></span>
</div>

    <article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN">
  <link itemprop="mainEntityOfPage" href="http://qianqiu-cell.github.io/2024/05/16/AI/LLM/">

  <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="image" content="/images/avatar.jpg">
    <meta itemprop="name" content="Ember">
    <meta itemprop="description" content="å¤©å°†é™å¤§ä»»äºæ–¯äººä¹Ÿ, ğŸŒ¸å­¦ä¹ ç¬”è®°ğŸŒ¸">
  </span>

  <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Keep Moving">
  </span>

  <div class="body md" itemprop="articleBody">
    

    <p><img data-src="/images/AI/LLM/0.1.jpg" alt=""></p>
<p>å‚è€ƒé“¾æ¥ï¼š<span class="exturl" data-url="aHR0cHM6Ly93YXlsYW5kemhhbmcuZ2l0aHViLmlvL2VuL3RyYW5zZm9ybWVyLWFyY2hpdGVjdHVyZS5odG1sIzQtNy1jYWxjdWxhdGUtdi1hdHRlbnRpb24=">https://waylandzhang.github.io/en/transformer-architecture.html#4-7-calculate-v-attention</span>ã€<span class="exturl" data-url="aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vMzU0NjYxMTUyNzQ1MzE2MT9zcG1faWRfZnJvbT0zMzMuNzg4LjAuMA==">https://space.bilibili.com/3546611527453161?spm_id_from=333.788.0.0</span></p>
<p>â€ƒâ€ƒ <code>Transformer</code>  æ¨¡å‹ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼šç¼–ç å™¨å’Œè§£ç å™¨ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œä»…ç¼–ç å™¨çš„æ¶æ„ç²¾é€šäºä»æ–‡æœ¬ä¸­æå–ä¿¡æ¯ï¼Œç”¨äºåˆ†ç±»å’Œå›å½’ç­‰ä»»åŠ¡ï¼Œè€Œä»…è§£ç å™¨çš„æ¨¡å‹ä¸“é—¨ç”¨äºç”Ÿæˆæ–‡æœ¬ã€‚ä¾‹å¦‚ï¼Œ<mark>ä¸“æ³¨äºæ–‡æœ¬ç”Ÿæˆçš„ <code>GPT</code>  å±äºä»…è§£ç å™¨æ¨¡å‹çš„ç±»åˆ«</mark>ã€‚</p>
<p>â€ƒâ€ƒ <code>Transformer</code>  çš„å¤§è‡´è¿‡ç¨‹å¦‚ä¸‹ï¼š</p>
<ul>
<li>é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç³»åˆ—è¾“å…¥å­—ç¬¦ä½œä¸ºè®­ç»ƒæ•°æ®ã€‚è¿™äº›è¾“å…¥è¢«è½¬æ¢æˆçŸ¢é‡åµŒå…¥æ ¼å¼ã€‚</li>
<li>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ä½ç½®ç¼–ç æ·»åŠ åˆ°çŸ¢é‡åµŒå…¥ä¸­ï¼Œä»¥æ•è·åºåˆ—ä¸­æ¯ä¸ªå­—ç¬¦çš„ä½ç½®ã€‚</li>
<li>éšåï¼Œè¯¥æ¨¡å‹é€šè¿‡ä¸€ç³»åˆ—è®¡ç®—æ“ä½œå¤„ç†è¿™äº›è¾“å…¥åµŒå…¥ï¼Œæœ€ç»ˆä¸ºç»™å®šçš„è¾“å…¥æ–‡æœ¬ç”Ÿæˆå¯èƒ½çš„ä¸‹ä¸€ä¸ªå­—ç¬¦çš„æ¦‚ç‡åˆ†å¸ƒã€‚</li>
<li>è¯¥æ¨¡å‹æ ¹æ®è®­ç»ƒæ•°æ®é›†ä¸­çš„å®é™…åç»­ç‰¹å¾æ¥è¯„ä¼°é¢„æµ‹ç»“æœï¼Œå¹¶ç›¸åº”åœ°è°ƒæ•´æ¦‚ç‡æˆ– â€œæƒé‡â€ã€‚</li>
<li>æœ€åï¼Œè¯¥æ¨¡å‹è¿­ä»£åœ°ç»†åŒ–è¿™ä¸ªè¿‡ç¨‹ï¼Œä¸æ–­æ›´æ–°å…¶å‚æ•°ï¼Œä»¥æé«˜æœªæ¥é¢„æµ‹çš„ç²¾åº¦ã€‚</li>
</ul>
<h1 id="ä¸€-tokenizer"><a class="markdownIt-Anchor" href="#ä¸€-tokenizer">#</a> ä¸€ã€Tokenizer</h1>
<p>â€ƒâ€ƒ <code>Tokenizer</code>  åˆ†è¯ç®—æ³•æ˜¯ <code>NLP</code>  å¤§æ¨¡å‹æœ€åŸºç¡€çš„ç»„ä»¶ï¼ŒåŸºäº <code>Tokenizer</code>  å¯ä»¥<mark>å°†æ–‡æœ¬è½¬æ¢æˆç‹¬ç«‹çš„ <code>token</code>  åˆ—è¡¨ï¼Œè¿›è€Œè½¬æ¢æˆè¾“å…¥çš„å‘é‡æˆä¸ºè®¡ç®—æœºå¯ä»¥ç†è§£çš„è¾“å…¥å½¢å¼</mark>ã€‚</p>
<p>â€ƒâ€ƒ <code>tiktoken</code>  æ˜¯ä¸€ç§å¿«é€Ÿ  <code>BPE</code>  æ ‡è®°å™¨ï¼Œå¯ä¸ <code>OpenAI</code>  æ¨¡å‹ä¸€èµ·ä½¿ç”¨ã€‚</p>
<p>â€ƒâ€ƒ <code>tiktoken</code>  ä½¿ç”¨æ–¹æ³•ä¸ºï¼š</p>
<figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> tiktoken</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment"># Using TikToken (Same as GPT3) to tokenize the source text</span></pre></td></tr><tr><td data-num="3"></td><td><pre>encoding <span class="token operator">=</span> tiktoken<span class="token punctuation">.</span>get_encoding<span class="token punctuation">(</span><span class="token string">"cl100k_base"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># text ä¿å­˜äº† str å˜é‡ç±»å‹çš„æ–‡æœ¬å†…å®¹ --> è¾“å‡ºä¸ºä»¥å•è¯ä¸ºå•ä½çš„ int åˆ—è¡¨</span></pre></td></tr><tr><td data-num="5"></td><td><pre>tokenized_text <span class="token operator">=</span> encoding<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment"># å°† tokenized_text è½¬æ¢ä¸º Tensor.int64 ç±»å‹çš„å¼ é‡</span></pre></td></tr><tr><td data-num="7"></td><td><pre>tokenized_text <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>tokenized_text<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span></pre></td></tr></table></figure><p>â€ƒâ€ƒä¸Šè¿°çš„ä»£ç æä¾›äº† <code>encoding</code>  çš„ç¼–ç è¿‡ç¨‹ï¼ŒåŒæ—¶è¿˜å¯ä»¥æ ¹æ® <code>tokenized</code>  çš„ç¼–ç ç»“æœè¿›è¡Œè§£ç ï¼Œåªéœ€è¦é€šè¿‡ <code>decode</code>  å‡½æ•°è¾“å…¥ <code>int</code>  ç±»å‹çš„åˆ—è¡¨é›†åˆè¿”å›åŸå§‹çš„ str ç±»å‹æ–‡æœ¬</p>
<figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># è¾“å‡ºå•ä¸ªç¼–ç å¯¹åº”çš„ str æ–‡æœ¬</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>encoding<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>tokenized_text<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># è¾“å‡ºå¤šä¸ªç¼–ç å¯¹åº”çš„ str æ–‡æœ¬</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>encoding<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>tokenized_text<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h1 id="äºŒ-embedding"><a class="markdownIt-Anchor" href="#äºŒ-embedding">#</a> äºŒã€Embedding</h1>
<p>â€ƒâ€ƒ <code>Tokenize</code>  å®Œçš„ä¸‹ä¸€æ­¥å°±æ˜¯å°† <code>token</code>  çš„ <code>one-hot</code>  ç¼–ç è½¬æ¢æˆæ›´ <code>dense</code>  çš„ <code>embedding</code>  ç¼–ç ã€‚</p>
<p>â€ƒâ€ƒ <code>Embedding</code>  çŸ©é˜µçš„æœ¬è´¨å°±æ˜¯ä¸€ä¸ªæŸ¥æ‰¾è¡¨ã€‚ç”±äºè¾“å…¥å‘é‡æ˜¯ <code>one-hot</code>  çš„ï¼Œ <code>embedding</code>  çŸ©é˜µä¸­æœ‰ä¸”ä»…æœ‰ä¸€è¡Œè¢«æ¿€æ´»ã€‚è¡Œé—´äº’ä¸å¹²æ‰°ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå‡è®¾è¯æ±‡è¡¨ä¸€å…±æœ‰ <code>6</code>  ä¸ªè¯ï¼Œåˆ™ <code>one-hot</code>  è¡¨ç¤ºçš„é•¿åº¦ä¸º <code>6</code> ã€‚ç°åœ¨æˆ‘ä»¬æœ‰ä¸‰ä¸ªå•è¯ç»„æˆä¸€ä¸ªå¥å­ï¼Œåˆ™è¾“å…¥çŸ©é˜µçš„å½¢çŠ¶ä¸º <code>(3,6)</code>  ã€‚ç„¶åæˆ‘ä»¬å­¦å‡ºæ¥ä¸€ä¸ª <code>embedding</code>  çŸ©é˜µï¼Œæ ¹æ®ä¸Šé¢çš„æ¨å¯¼ï¼Œå¦‚æœæˆ‘ä»¬çš„ <code>embedding size</code> ï¼ˆç¼–ç å‘é‡çš„é•¿åº¦ï¼‰ä¸º <code>4</code> ï¼Œåˆ™ <code>embedding</code>  çŸ©é˜µçš„å½¢çŠ¶åº”è¯¥ä¸º <code>(6,4)</code> ã€‚è¿™æ ·ä¹˜å‡ºæ¥çš„è¾“å‡ºçŸ©é˜µçš„å½¢çŠ¶åº”ä¸º <code>(3,4)</code> ã€‚</p>
<p><img data-src="/images/AI/LLM/2.1.jpg" alt=""></p>
<p>â€ƒâ€ƒå¯¹äºç¬¬ä¸€ä¸ªå•è¯ <code>I</code> ï¼Œå‡è®¾å…¶ <code>one-hot</code>  ç¼–ç ä¸º <code>[0,0,1,0,0,0]</code> ï¼Œå°†å…¶ä¸ <code>embedding</code>  çŸ©é˜µç›¸ä¹˜ï¼Œç›¸å½“äºå–å‡º <code>embedding</code>  çŸ©é˜µçš„ç¬¬ <code>3</code>  è¡Œï¼ˆ <code>index</code>  ä¸º <code>2</code> ï¼‰ã€‚åŒç†ï¼Œå¯¹äºå•è¯ <code>love</code> ï¼Œç›¸å½“äºå–å‡º <code>embedding</code>  çŸ©é˜µçš„ç¬¬äºŒè¡Œï¼ˆ <code>index</code>  ä¸º <code>1</code> ï¼‰ã€‚å› æ­¤ <code>embedding</code>  çŸ©é˜µçš„æœ¬è´¨æ˜¯ä¸€ä¸ªæŸ¥æ‰¾è¡¨ï¼Œæ¯ä¸ªå•è¯ä¼šå®šä½è¿™ä¸ªè¡¨ä¸­çš„æŸä¸€è¡Œï¼Œè€Œè¿™ä¸€è¡Œå°±æ˜¯è¿™ä¸ªå•è¯å­¦ä¹ åˆ°çš„åœ¨åµŒå…¥ç©ºé—´çš„è¯­ä¹‰ã€‚</p>
<p>â€ƒâ€ƒé¦–å…ˆå‡†å¤‡æ‰€éœ€è¦çš„æ•°æ®ï¼Œåœ¨ transformer çš„è§£ç å™¨ä¸­ï¼Œéœ€è¦è¾“å…¥ <code>n_batch * context_length * d_model</code>  ç»´åº¦çš„ <code>Tensor</code>  æ•°æ®ï¼Œå…¶ä¸­ <code>n_batch</code>  è¡¨ç¤ºæ‰¹æ¬¡å¤§å°ï¼Œ <code>contex_length</code>  è¡¨ç¤ºä¸€æ¬¡è¾“å…¥çš„å•æ¬¡æ•°é‡ï¼Œ <code>d_model</code>  è¡¨ç¤ºç¼–ç å‘é‡çš„é•¿åº¦ã€‚å°† <code>Tokenizer</code>  ä¸­è·å¾—çš„ <code>tokenized_text</code>  è¿›è¡Œæ•°æ®é¢„å¤„ç†ï¼š</p>
<figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># Split train and validation</span></pre></td></tr><tr><td data-num="2"></td><td><pre>split_idx <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>tokenized_text<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.9</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>train_data <span class="token operator">=</span> tokenized_text<span class="token punctuation">[</span><span class="token punctuation">:</span>split_idx<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="4"></td><td><pre>val_data <span class="token operator">=</span> tokenized_text<span class="token punctuation">[</span>split_idx<span class="token punctuation">:</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment"># Get input embedding batch</span></pre></td></tr><tr><td data-num="7"></td><td><pre>data <span class="token operator">=</span> train_data</pre></td></tr><tr><td data-num="8"></td><td><pre>idxs <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>low<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> high<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token operator">-</span> context_length<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>x_batch <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>data<span class="token punctuation">[</span>idx<span class="token punctuation">:</span>idx <span class="token operator">+</span> context_length<span class="token punctuation">]</span> <span class="token keyword">for</span> idx <span class="token keyword">in</span> idxs<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>y_batch <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>data<span class="token punctuation">[</span>idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span>idx <span class="token operator">+</span> context_length <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> idx <span class="token keyword">in</span> idxs<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr></table></figure><p>â€ƒâ€ƒä¹‹åä¾¿å¯ä»¥åˆ©ç”¨ <code>torch</code>  ä¸­çš„ <code>nn.Embedding</code>  å‡½æ•°æ„é€  <code>Embedding</code>  å±‚ã€‚å…¶ä¸­ <code>Embedding.weight.data</code>  æ˜¯ä¸€ä¸ª <code>max_token_value * d_model</code>  ç»´åº¦çš„ <code>Tensor</code>  å˜é‡ï¼Œæ˜¯æ¨¡å‹éœ€è¦è®­ç»ƒçš„å‚æ•°ï¼ŒåŒæ—¶ä¹Ÿæ˜¯ä¸Šå›¾ä¸­å¯¹åº”çš„ <code>Embedding</code>  æŸ¥æ‰¾è¡¨ã€‚</p>
<figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># define input embedding table</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment"># è·å– tokenized_text ä¸­çš„æœ€å¤§å€¼ + 1ï¼Œç”¨äºæ„é€  Embedding çš„è¡Œ</span></pre></td></tr><tr><td data-num="3"></td><td><pre>max_token_value <span class="token operator">=</span> tokenized_text<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># ä½¿ç”¨ nn.Embedding å‡½æ•°æ„é€  Embedding å±‚</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment"># `Embedding.weight.data` æ˜¯ä¸€ä¸ª `max_token_value * d_model` ç»´åº¦çš„ `Tensor` å˜é‡</span></pre></td></tr><tr><td data-num="6"></td><td><pre>token_embedding_lookup_table <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>num_embeddings<span class="token operator">=</span>max_token_value<span class="token punctuation">,</span> embedding_dim<span class="token operator">=</span>d_model<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token comment"># é€šè¿‡è¾“å…¥ x_batch æˆ– y_batch å³å¯è·å¾—å¯¹åº”çš„ Embedding ç¼–ç ç»“æœ</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token comment"># x_batch_embedding å’Œ y_batch_embedding æ˜¯ `n_batch * context_length * d_model` ç»´åº¦çš„ `Tensor` æ•°æ®</span></pre></td></tr><tr><td data-num="9"></td><td><pre>x_batch_embedding <span class="token operator">=</span> token_embedding_lookup_table<span class="token punctuation">(</span>x_batch<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>y_batch_embedding <span class="token operator">=</span> token_embedding_lookup_table<span class="token punctuation">(</span>y_batch<span class="token punctuation">)</span></pre></td></tr></table></figure><h1 id="ä¸‰-position-encoding"><a class="markdownIt-Anchor" href="#ä¸‰-position-encoding">#</a> ä¸‰ã€Position Encoding</h1>
<p>â€ƒâ€ƒåœ¨ <code>transformer</code>  çš„ <code>encoder</code>  å’Œ <code>decoder</code>  çš„è¾“å…¥å±‚ä¸­ï¼Œå‡ä½¿ç”¨äº† <code>Positional Encoding</code> ï¼Œä½¿å¾—æœ€ç»ˆçš„è¾“å…¥æ»¡è¶³ï¼š <code>input = input_embedding + positional_encoding</code> ã€‚</p>
<p>â€ƒâ€ƒ <code>Transformer</code>  ä½ç½®ç¼–ç çš„å®šä¹‰ä¸ºï¼š</p>
<p><img data-src="/images/AI/LLM/3.1.png" alt=""></p>
<p>â€ƒâ€ƒå®ç°ä½ç½®ç¼–ç çš„ä»£ç ä¸ºï¼š</p>
<figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># get positional encoding</span></pre></td></tr><tr><td data-num="2"></td><td><pre>position_encoding_lookup_table <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>context_length<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># unsqueeze ç”¨æ¥æ‰©å……ä¸€ä¸ªç»´åº¦ï¼Œä¸ºäº†åé¢çš„é€å…ƒç´ è®¡ç®—æ—¶çš„å¹¿æ’­æœºåˆ¶</span></pre></td></tr><tr><td data-num="4"></td><td><pre>position <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> context_length<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment"># æ ¹æ®å…¬å¼è®¡ç®—ä½ç½®ç¼–ç </span></pre></td></tr><tr><td data-num="6"></td><td><pre>div_term <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token operator">-</span>math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">10000.0</span><span class="token punctuation">)</span> <span class="token operator">/</span> d_model<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>position_encoding_lookup_table<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>position <span class="token operator">*</span> div_term<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>position_encoding_lookup_table<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>position <span class="token operator">*</span> div_term<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token comment"># å°† context_length*d_model çš„çŸ©é˜µå¤åˆ¶ n_epoch æ¬¡ï¼Œå½¢æˆ n_epoch*context_length*d_model çš„çŸ©é˜µ</span></pre></td></tr><tr><td data-num="10"></td><td><pre>position_encoding_lookup_table <span class="token operator">=</span> position_encoding_lookup_table<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>â€ƒâ€ƒåœ¨è·å¾—ä½ç½®ç¼–ç ä¹‹åå³å¯å°†ä½ç½®ç¼–ç ä¸ <code>Embedding</code>  è¿›è¡Œç›¸åŠ ï¼Œè·å¾—æœ€ç»ˆè¾“å…¥è‡³ç½‘ç»œçš„è¾“å…¥ï¼š</p>
<figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># add positional encoding to the input_embedding</span></pre></td></tr><tr><td data-num="2"></td><td><pre>x <span class="token operator">=</span> x_batch_embedding <span class="token operator">+</span> position_encoding_lookup_table</pre></td></tr><tr><td data-num="3"></td><td><pre>y <span class="token operator">=</span> y_batch_embedding <span class="token operator">+</span> position_encoding_lookup_table</pre></td></tr></table></figure><h1 id="å››-transformer-block"><a class="markdownIt-Anchor" href="#å››-transformer-block">#</a> å››ã€Transformer Block</h1>
<p><img data-src="/images/AI/LLM/4.1.png" alt=""></p>
<p>â€ƒâ€ƒé€šè¿‡ç¬¬ä¸‰æ­¥ï¼Œæˆ‘ä»¬è·å¾—äº†è¾“å…¥ <code>x</code> ï¼Œä¸‹ä¸€æ­¥æ˜¯å¼€å§‹å®ç°å¤šå¤´æ³¨æ„åŠ›å—ï¼ˆ <code>Muti-head Attention block</code> ï¼‰ã€‚</p>
<p>â€ƒâ€ƒ <code>Transformer</code>  æ¨¡å‹çš„å¼ºå¤§æ¥æºäº <code>self-attention</code> ï¼Œé€šè¿‡ <code>self-attention</code> ï¼Œ <code>Transformer</code>  æ¨¡å‹å¯ä»¥å…³æ³¨åˆ° <code>input</code>  æ›´åŠ é‡è¦çš„éƒ¨åˆ†ã€‚</p>
<p>â€ƒâ€ƒ <code>Multi-head attention</code>  ç”±å‡ ä¸ªå•ç‹¬çš„ <code>heads</code>  å †å åœ¨ä¸€èµ·ç»„æˆã€‚æ‰€æœ‰ heads éƒ½æ¥æ”¶åˆ°å®Œå…¨ç›¸åŒçš„è¾“å…¥ï¼Œå°½ç®¡å®ƒä»¬åœ¨è®¡ç®—è¿‡ç¨‹ä¸­ä½¿ç”¨äº†è‡ªå·±çš„ç‰¹å®šæƒé‡é›†ã€‚åœ¨å¤„ç†è¾“å…¥ä¹‹åï¼Œæ¥è‡ªæ‰€æœ‰ <code>heads</code>  çš„è¾“å‡ºè¢«çº§è”ï¼Œç„¶åé€šè¿‡çº¿æ€§å±‚ã€‚</p>
<p>â€ƒâ€ƒ <code>heads</code>  çš„å·¥ä½œæ–¹å¼æ˜¯é€šè¿‡ä¸‰ä¸ªç‹¬ç‰¹çš„å±‚å¤„ç†ï¼Œå³æŸ¥è¯¢ï¼ˆ <code>Q</code> ï¼‰ã€é”®ï¼ˆ <code>K</code> ï¼‰å’Œå€¼ï¼ˆ <code>V</code> ï¼‰ã€‚ <code>Attention</code>  çš„è®¡ç®—å…¬å¼å¯ä»¥ä»è®ºæ–‡ã€Š <code>Attention is all you need</code> ã€‹ä¸­å¾—åˆ°ï¼š</p>
<p><img data-src="/images/AI/LLM/4.2.png" alt=""></p>
<figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># get Q, K, V</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment"># æ‰€è°“çš„å¤šå¤´å°±æ˜¯æŠŠ d_model åˆ‡æˆå¤šä»½ï¼Œæ¯ä¸€ä¸ªå¤´é‡Œé¢æœ‰ä¸€éƒ¨åˆ†ç»´åº¦ï¼Œç„¶åå»åšè¿™ä¸€éƒ¨åˆ†çš„è®¡ç®—ï¼Œæœ€åå†æŠŠæ‰€æœ‰çš„è®¡ç®—åˆå¹¶åœ¨ä¸€èµ·</span></pre></td></tr><tr><td data-num="3"></td><td><pre>head_size <span class="token operator">=</span> d_model <span class="token operator">//</span> num_heads  <span class="token comment"># head size should be divisible by d_model</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># (1) è®¡ç®— Q,K,V çŸ©é˜µ</span></pre></td></tr><tr><td data-num="5"></td><td><pre>key_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>d_model<span class="token punctuation">,</span> out_features<span class="token operator">=</span>d_model<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>query_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>d_model<span class="token punctuation">,</span> out_features<span class="token operator">=</span>d_model<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>value_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>d_model<span class="token punctuation">,</span> out_features<span class="token operator">=</span>d_model<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token comment"># [batch_size, context_length, d_model]</span></pre></td></tr><tr><td data-num="9"></td><td><pre>q <span class="token operator">=</span> query_layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>k <span class="token operator">=</span> key_layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>v <span class="token operator">=</span> value_layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token comment"># [batch_size, context_length, num_heads, head_size]</span></pre></td></tr><tr><td data-num="13"></td><td><pre>q <span class="token operator">=</span> q<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> head_size<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>k <span class="token operator">=</span> k<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> head_size<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>v <span class="token operator">=</span> v<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> head_size<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token comment"># [batch_size, num_heads, context_length, head_size]</span></pre></td></tr><tr><td data-num="17"></td><td><pre>q <span class="token operator">=</span> q<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre>k <span class="token operator">=</span> k<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>v <span class="token operator">=</span> v<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre><span class="token comment"># (2) é€šè¿‡ Q @ K^T /sqrt (d_k) è®¡ç®— Attention</span></pre></td></tr><tr><td data-num="21"></td><td><pre>attention_score <span class="token operator">=</span> <span class="token punctuation">(</span>q @ k<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">/</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>head_size<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre><span class="token comment"># (3) è®¡ç®— Mask</span></pre></td></tr><tr><td data-num="23"></td><td><pre>mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>triu<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>context_length<span class="token punctuation">,</span> context_length<span class="token punctuation">)</span><span class="token punctuation">,</span> diagonal<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">bool</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre>attention_score <span class="token operator">=</span> attention_score<span class="token punctuation">.</span>masked_fill<span class="token punctuation">(</span>mask<span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token string">'-inf'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="25"></td><td><pre><span class="token comment"># (4) è®¡ç®— Softmax</span></pre></td></tr><tr><td data-num="26"></td><td><pre><span class="token comment"># [batch_size, num_heads, context_length, context_length]</span></pre></td></tr><tr><td data-num="27"></td><td><pre>attention_score <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>attention_score<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre><span class="token comment"># (5) é€šè¿‡ $V è®¡ç®— A</span></pre></td></tr><tr><td data-num="29"></td><td><pre><span class="token comment"># [batch_size, num_heads, context_length, head_size]</span></pre></td></tr><tr><td data-num="30"></td><td><pre>A <span class="token operator">=</span> attention_score @ v</pre></td></tr><tr><td data-num="31"></td><td><pre><span class="token comment"># (6) è®¡ç®— Concatenate</span></pre></td></tr><tr><td data-num="32"></td><td><pre><span class="token comment"># [batch_size, context_length, num_heads, head_size]</span></pre></td></tr><tr><td data-num="33"></td><td><pre>A <span class="token operator">=</span> A<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="34"></td><td><pre><span class="token comment"># [batch_size, context_length, d_model]</span></pre></td></tr><tr><td data-num="35"></td><td><pre>A <span class="token operator">=</span> A<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> d_model<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="36"></td><td><pre><span class="token comment"># (7) é€šè¿‡ Wo è®¡ç®— Output</span></pre></td></tr><tr><td data-num="37"></td><td><pre><span class="token comment"># Define the output weight matrix</span></pre></td></tr><tr><td data-num="38"></td><td><pre>Wo <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="39"></td><td><pre><span class="token comment"># [batch_size, context_length, d_model]</span></pre></td></tr><tr><td data-num="40"></td><td><pre>output <span class="token operator">=</span> Wo<span class="token punctuation">(</span>A<span class="token punctuation">)</span></pre></td></tr></table></figure><h1 id="äº”-residual-connection-and-layer-normalization"><a class="markdownIt-Anchor" href="#äº”-residual-connection-and-layer-normalization">#</a> äº”ã€Residual Connection and Layer Normalization</h1>
<p>â€ƒâ€ƒæ®‹å·®è¿æ¥ï¼Œæœ‰æ—¶è¢«ç§°ä¸º <code>skip connection</code> ï¼Œæ˜¯è®©åŸå§‹è¾“å…¥ <code>X</code>  ç»•è¿‡ä¸€ä¸ªæˆ–å¤šä¸ªå±‚çš„è¿æ¥ã€‚é€šè¿‡å°†åŸå§‹è¾“å…¥ <code>x</code>  ä¸æ­¥éª¤å››å¤šå¤´æ³¨æ„åŠ›å±‚çš„è¾“å‡º <code>output</code>  ç›¸åŠ å³å¯å®Œæˆæ“ä½œã€‚</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo>=</mo><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo>+</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">output = output + x
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span></span></span></span></span></p>
<p>â€ƒâ€ƒåœ¨æ®‹å·®è¿æ¥ä¹‹åï¼Œè¿‡ç¨‹è¿›å…¥å±‚å½’ä¸€åŒ–ã€‚å±‚å½’ä¸€åŒ–ï¼ˆ <code>LayerNorm</code> ï¼‰æ˜¯ä¸€ç§ç”¨äºå¯¹ç½‘ç»œä¸­æ¯ä¸€å±‚çš„è¾“å‡ºè¿›è¡Œå½’ä¸€åŒ–çš„æŠ€æœ¯ã€‚å…¶æ–¹æ³•æ˜¯å‡å»è¾“å‡ºçš„å‡å€¼ï¼Œå¹¶é™¤ä»¥è¾“å‡ºçš„æ ‡å‡†å·®ã€‚ä½¿ç”¨è¿™ç§æŠ€æœ¯æ˜¯ä¸ºäº†é˜²æ­¢æŸä¸€å±‚çš„è¾“å‡ºå˜å¾—è¿‡å¤§æˆ–è¿‡å°ï¼Œä»è€Œé¿å…ç½‘ç»œçš„ä¸ç¨³å®šæ€§ã€‚</p>
<figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># Add residual connection</span></pre></td></tr><tr><td data-num="2"></td><td><pre>output <span class="token operator">=</span> output <span class="token operator">+</span> X</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># Add Layer Normalization</span></pre></td></tr><tr><td data-num="5"></td><td><pre>layer_norm <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>d_model<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>output <span class="token operator">=</span> layer_norm<span class="token punctuation">(</span>output<span class="token punctuation">)</span></pre></td></tr></table></figure><h1 id="å…­-feed-forward-network"><a class="markdownIt-Anchor" href="#å…­-feed-forward-network">#</a> å…­ã€Feed-Forward Network</h1>
<p>â€ƒâ€ƒä¸€æ—¦æˆ‘ä»¬è·å¾—äº†å½’ä¸€åŒ–çš„æ³¨æ„åŠ›æƒé‡ï¼ˆæ¦‚ç‡åˆ†æ•°ï¼‰ï¼Œå®ƒå°†è¢«ä¼ é€’åˆ°ä¸€ä¸ªä½ç½®çº§å‰é¦ˆç½‘ç»œä¸­è¿›è¡Œå¤„ç†ã€‚å‰é¦ˆç¥ç»ç½‘ç»œï¼ˆ <code>FFN</code> ï¼‰ç”±ä¸¤ä¸ªçº¿æ€§å±‚å’Œå®ƒä»¬ä¹‹é—´çš„ ReLU æ¿€æ´»å‡½æ•°ç»„æˆã€‚</p>
<figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># update x</span></pre></td></tr><tr><td data-num="2"></td><td><pre>x <span class="token operator">=</span> output</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># Define Feed Forward Network</span></pre></td></tr><tr><td data-num="5"></td><td><pre>output <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_model <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>output <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>output <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> d_model<span class="token punctuation">)</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>output <span class="token operator">=</span> torch<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>output<span class="token punctuation">,</span> p<span class="token operator">=</span>dropout<span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token comment"># Add residual connection</span></pre></td></tr><tr><td data-num="11"></td><td><pre>output <span class="token operator">=</span> output <span class="token operator">+</span> x</pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token comment"># Add Layer Normalization</span></pre></td></tr><tr><td data-num="13"></td><td><pre>layer_norm <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>d_model<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>output <span class="token operator">=</span> layer_norm<span class="token punctuation">(</span>output<span class="token punctuation">)</span></pre></td></tr></table></figure><h1 id="ä¸ƒ-repeat-step-4-to-6"><a class="markdownIt-Anchor" href="#ä¸ƒ-repeat-step-4-to-6">#</a> ä¸ƒã€Repeat step 4 to 6</h1>
<p>â€ƒâ€ƒä»¥ä¸Šæˆ‘ä»¬å®Œæˆçš„åªæ˜¯ä¸€ä¸ª <code>transformer</code>  å—ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬ä¼šå°†å¤šä¸ª <code>transformer</code>  å—å †å åœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ª <code>transformer</code>  è§£ç å™¨ã€‚</p>
<p>â€ƒâ€ƒå®é™…ä¸Šï¼Œæˆ‘ä»¬åº”è¯¥å°†ä»£ç å°è£…åˆ°ç±»ä¸­ï¼Œå¹¶ä½¿ç”¨ <code>PyTorch</code>  çš„ <code>nn.Module</code>  æ¥æ„å»ºæˆ‘ä»¬çš„ <code>transformer</code>  è§£ç å™¨ã€‚ä½†ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬åªä½¿ç”¨ä¸€ä¸ªå—ã€‚</p>
<h1 id="å…«-output-probabilities"><a class="markdownIt-Anchor" href="#å…«-output-probabilities">#</a> å…«ã€Output Probabilities</h1>
<p>â€ƒâ€ƒåº”ç”¨æœ€åä¸€ä¸ªçº¿æ€§å±‚æ¥è·å¾—æˆ‘ä»¬çš„ <code>logits</code> ï¼š</p>
<figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre>logits <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> max_token_value<span class="token punctuation">)</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span></pre></td></tr></table></figure><p>â€ƒâ€ƒæœ€åä¸€æ­¥æ˜¯å¯¹é€»è¾‘å›å½’è¾“å‡ºè¿›è¡Œ <code>softmax</code>  æ“ä½œï¼Œä»¥è·å¾—æ¯ä¸ª <code>token</code>  çš„æ¦‚ç‡ï¼š</p>
<figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># torch.softmax usually used during inference, during training we use torch.nn.CrossEntropyLoss</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment"># but for illustration purpose, we'll use torch.softmax here</span></pre></td></tr><tr><td data-num="3"></td><td><pre>probabilities <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h1 id="full-working-code"><a class="markdownIt-Anchor" href="#full-working-code">#</a> Full Working Code</h1>
<p>â€ƒâ€ƒå®Œæ•´çš„ä»£ç å¯ä»¥å‚è€ƒ <code>github</code> : <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3dheWxhbmR6aGFuZy9UcmFuc2Zvcm1lci1mcm9tLXNjcmF0Y2g=">https://github.com/waylandzhang/Transformer-from-scratch</span></p>
<figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> os</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> requests</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">import</span> math</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">import</span> tiktoken</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn</pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> functional <span class="token keyword">as</span> F</pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token comment"># Hyperparameters</span></pre></td></tr><tr><td data-num="10"></td><td><pre>batch_size <span class="token operator">=</span> <span class="token number">4</span>  <span class="token comment"># How many batches per training step</span></pre></td></tr><tr><td data-num="11"></td><td><pre>context_length <span class="token operator">=</span> <span class="token number">16</span>  <span class="token comment"># Length of the token chunk each batch</span></pre></td></tr><tr><td data-num="12"></td><td><pre>d_model <span class="token operator">=</span> <span class="token number">64</span>  <span class="token comment"># The size of our model token embeddings</span></pre></td></tr><tr><td data-num="13"></td><td><pre>num_blocks <span class="token operator">=</span> <span class="token number">8</span>  <span class="token comment"># Number of transformer blocks</span></pre></td></tr><tr><td data-num="14"></td><td><pre>num_heads <span class="token operator">=</span> <span class="token number">4</span>  <span class="token comment"># Number of heads in Multi-head attention</span></pre></td></tr><tr><td data-num="15"></td><td><pre>learning_rate <span class="token operator">=</span> <span class="token number">1e-3</span>  <span class="token comment"># 0.001</span></pre></td></tr><tr><td data-num="16"></td><td><pre>dropout <span class="token operator">=</span> <span class="token number">0.1</span>  <span class="token comment"># Dropout rate</span></pre></td></tr><tr><td data-num="17"></td><td><pre>max_iters <span class="token operator">=</span> <span class="token number">5000</span>  <span class="token comment"># Total of training iterations &lt;- Change this to smaller number for testing</span></pre></td></tr><tr><td data-num="18"></td><td><pre>eval_interval <span class="token operator">=</span> <span class="token number">50</span>  <span class="token comment"># How often to evaluate</span></pre></td></tr><tr><td data-num="19"></td><td><pre>eval_iters <span class="token operator">=</span> <span class="token number">20</span>  <span class="token comment"># Number of iterations to average for evaluation</span></pre></td></tr><tr><td data-num="20"></td><td><pre>device <span class="token operator">=</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span>  <span class="token comment"># Use GPU if it's available.</span></pre></td></tr><tr><td data-num="21"></td><td><pre>TORCH_SEED <span class="token operator">=</span> <span class="token number">1337</span></pre></td></tr><tr><td data-num="22"></td><td><pre>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>TORCH_SEED<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre></pre></td></tr><tr><td data-num="24"></td><td><pre><span class="token comment"># Load training data</span></pre></td></tr><tr><td data-num="25"></td><td><pre><span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span><span class="token string">'data/sales_textbook.txt'</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    url <span class="token operator">=</span> <span class="token string">'https://huggingface.co/datasets/goendalf666/sales-textbook_for_convincing_and_selling/raw/main/sales_textbook.txt'</span></pre></td></tr><tr><td data-num="27"></td><td><pre>    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'data/sales_textbook.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="28"></td><td><pre>        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token punctuation">.</span>text<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre></pre></td></tr><tr><td data-num="30"></td><td><pre><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'data/sales_textbook.txt'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="31"></td><td><pre>    text <span class="token operator">=</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="32"></td><td><pre></pre></td></tr><tr><td data-num="33"></td><td><pre><span class="token comment"># Using TikToken (Same as GPT3) to tokenize the source text</span></pre></td></tr><tr><td data-num="34"></td><td><pre>encoding <span class="token operator">=</span> tiktoken<span class="token punctuation">.</span>get_encoding<span class="token punctuation">(</span><span class="token string">"cl100k_base"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre>tokenized_text <span class="token operator">=</span> encoding<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="36"></td><td><pre>max_token_value <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>tokenized_text<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>  <span class="token comment"># the maximum value of the tokenized numbers</span></pre></td></tr><tr><td data-num="37"></td><td><pre>tokenized_text <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>tokenized_text<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>  <span class="token comment"># put tokenized text into tensor</span></pre></td></tr><tr><td data-num="38"></td><td><pre></pre></td></tr><tr><td data-num="39"></td><td><pre><span class="token comment"># Split train and validation</span></pre></td></tr><tr><td data-num="40"></td><td><pre>split_idx <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>tokenized_text<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.9</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="41"></td><td><pre>train_data <span class="token operator">=</span> tokenized_text<span class="token punctuation">[</span><span class="token punctuation">:</span>split_idx<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="42"></td><td><pre>val_data <span class="token operator">=</span> tokenized_text<span class="token punctuation">[</span>split_idx<span class="token punctuation">:</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="43"></td><td><pre></pre></td></tr><tr><td data-num="44"></td><td><pre></pre></td></tr><tr><td data-num="45"></td><td><pre><span class="token comment"># Define Feed Forward Network</span></pre></td></tr><tr><td data-num="46"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">FeedForward</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="47"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="48"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="49"></td><td><pre>        self<span class="token punctuation">.</span>d_model <span class="token operator">=</span> d_model</pre></td></tr><tr><td data-num="50"></td><td><pre>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> dropout</pre></td></tr><tr><td data-num="51"></td><td><pre>        self<span class="token punctuation">.</span>ffn <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="52"></td><td><pre>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>self<span class="token punctuation">.</span>d_model<span class="token punctuation">,</span> out_features<span class="token operator">=</span>self<span class="token punctuation">.</span>d_model <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="53"></td><td><pre>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="54"></td><td><pre>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>self<span class="token punctuation">.</span>d_model <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span>self<span class="token punctuation">.</span>d_model<span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="55"></td><td><pre>            nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="56"></td><td><pre>        <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="57"></td><td><pre></pre></td></tr><tr><td data-num="58"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="59"></td><td><pre>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>ffn<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="60"></td><td><pre></pre></td></tr><tr><td data-num="61"></td><td><pre></pre></td></tr><tr><td data-num="62"></td><td><pre><span class="token comment"># Define Scaled Dot Product Attention</span></pre></td></tr><tr><td data-num="63"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">Attention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="64"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> head_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="65"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="66"></td><td><pre>        self<span class="token punctuation">.</span>d_model <span class="token operator">=</span> d_model</pre></td></tr><tr><td data-num="67"></td><td><pre>        self<span class="token punctuation">.</span>head_size <span class="token operator">=</span> head_size</pre></td></tr><tr><td data-num="68"></td><td><pre>        self<span class="token punctuation">.</span>context_length <span class="token operator">=</span> context_length</pre></td></tr><tr><td data-num="69"></td><td><pre>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> dropout</pre></td></tr><tr><td data-num="70"></td><td><pre></pre></td></tr><tr><td data-num="71"></td><td><pre>        self<span class="token punctuation">.</span>key_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>self<span class="token punctuation">.</span>d_model<span class="token punctuation">,</span> out_features<span class="token operator">=</span>self<span class="token punctuation">.</span>head_size<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="72"></td><td><pre>        self<span class="token punctuation">.</span>query_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>self<span class="token punctuation">.</span>d_model<span class="token punctuation">,</span> out_features<span class="token operator">=</span>self<span class="token punctuation">.</span>head_size<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="73"></td><td><pre>        self<span class="token punctuation">.</span>value_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>self<span class="token punctuation">.</span>d_model<span class="token punctuation">,</span> out_features<span class="token operator">=</span>self<span class="token punctuation">.</span>head_size<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="74"></td><td><pre>        self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span><span class="token string">'tril'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tril<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="75"></td><td><pre>            torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>context_length<span class="token punctuation">,</span> self<span class="token punctuation">.</span>context_length<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># Lower triangular mask</span></pre></td></tr><tr><td data-num="76"></td><td><pre>        self<span class="token punctuation">.</span>dropout_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="77"></td><td><pre></pre></td></tr><tr><td data-num="78"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="79"></td><td><pre>        B<span class="token punctuation">,</span> T<span class="token punctuation">,</span> C <span class="token operator">=</span> x<span class="token punctuation">.</span>shape  <span class="token comment"># Batch size, Time steps(current context_length), Channels(dimensions)</span></pre></td></tr><tr><td data-num="80"></td><td><pre>        <span class="token keyword">assert</span> T <span class="token operator">&lt;=</span> self<span class="token punctuation">.</span>context_length</pre></td></tr><tr><td data-num="81"></td><td><pre>        <span class="token keyword">assert</span> C <span class="token operator">==</span> self<span class="token punctuation">.</span>d_model</pre></td></tr><tr><td data-num="82"></td><td><pre>        q <span class="token operator">=</span> self<span class="token punctuation">.</span>query_layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="83"></td><td><pre>        k <span class="token operator">=</span> self<span class="token punctuation">.</span>key_layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="84"></td><td><pre>        v <span class="token operator">=</span> self<span class="token punctuation">.</span>value_layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="85"></td><td><pre></pre></td></tr><tr><td data-num="86"></td><td><pre>        <span class="token comment"># Scaled dot product attention: Q @ K^T / sqrt(d_k)</span></pre></td></tr><tr><td data-num="87"></td><td><pre>        weights <span class="token operator">=</span> <span class="token punctuation">(</span>q @ k<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">/</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>k<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="88"></td><td><pre>        <span class="token comment"># Apply masked attention</span></pre></td></tr><tr><td data-num="89"></td><td><pre>        weights <span class="token operator">=</span> weights<span class="token punctuation">.</span>masked_fill<span class="token punctuation">(</span>self<span class="token punctuation">.</span>tril<span class="token punctuation">[</span><span class="token punctuation">:</span>T<span class="token punctuation">,</span> <span class="token punctuation">:</span>T<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token string">'-inf'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="90"></td><td><pre>        weights <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>weights<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="91"></td><td><pre>        weights <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout_layer<span class="token punctuation">(</span>weights<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="92"></td><td><pre></pre></td></tr><tr><td data-num="93"></td><td><pre>        <span class="token comment"># Apply dot product attention: weights @ V</span></pre></td></tr><tr><td data-num="94"></td><td><pre>        out <span class="token operator">=</span> weights @ v</pre></td></tr><tr><td data-num="95"></td><td><pre>        <span class="token keyword">return</span> out</pre></td></tr><tr><td data-num="96"></td><td><pre></pre></td></tr><tr><td data-num="97"></td><td><pre></pre></td></tr><tr><td data-num="98"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">MultiHeadAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="99"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> head_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="100"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="101"></td><td><pre>        self<span class="token punctuation">.</span>num_heads <span class="token operator">=</span> num_heads</pre></td></tr><tr><td data-num="102"></td><td><pre>        self<span class="token punctuation">.</span>head_size <span class="token operator">=</span> head_size</pre></td></tr><tr><td data-num="103"></td><td><pre>        self<span class="token punctuation">.</span>d_model <span class="token operator">=</span> d_model</pre></td></tr><tr><td data-num="104"></td><td><pre>        self<span class="token punctuation">.</span>context_length <span class="token operator">=</span> context_length</pre></td></tr><tr><td data-num="105"></td><td><pre>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> dropout</pre></td></tr><tr><td data-num="106"></td><td><pre></pre></td></tr><tr><td data-num="107"></td><td><pre>        self<span class="token punctuation">.</span>heads <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>Attention<span class="token punctuation">(</span>head_size<span class="token operator">=</span>self<span class="token punctuation">.</span>head_size<span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_heads<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="108"></td><td><pre>        self<span class="token punctuation">.</span>projection_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>self<span class="token punctuation">.</span>d_model<span class="token punctuation">,</span> out_features<span class="token operator">=</span>self<span class="token punctuation">.</span>d_model<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="109"></td><td><pre>        self<span class="token punctuation">.</span>dropout_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="110"></td><td><pre></pre></td></tr><tr><td data-num="111"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="112"></td><td><pre>        out <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>h<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> h <span class="token keyword">in</span> self<span class="token punctuation">.</span>heads<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="113"></td><td><pre>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>projection_layer<span class="token punctuation">(</span>out<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="114"></td><td><pre>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout_layer<span class="token punctuation">(</span>out<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="115"></td><td><pre>        <span class="token keyword">return</span> out</pre></td></tr><tr><td data-num="116"></td><td><pre></pre></td></tr><tr><td data-num="117"></td><td><pre></pre></td></tr><tr><td data-num="118"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">TransformerBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="119"></td><td><pre></pre></td></tr><tr><td data-num="120"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_heads<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="121"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="122"></td><td><pre>        self<span class="token punctuation">.</span>d_model <span class="token operator">=</span> d_model</pre></td></tr><tr><td data-num="123"></td><td><pre>        self<span class="token punctuation">.</span>context_length <span class="token operator">=</span> context_length</pre></td></tr><tr><td data-num="124"></td><td><pre>        self<span class="token punctuation">.</span>head_size <span class="token operator">=</span> d_model <span class="token operator">//</span> num_heads  <span class="token comment"># head size should be divisible by d_model</span></pre></td></tr><tr><td data-num="125"></td><td><pre>        self<span class="token punctuation">.</span>num_heads <span class="token operator">=</span> num_heads</pre></td></tr><tr><td data-num="126"></td><td><pre>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> dropout</pre></td></tr><tr><td data-num="127"></td><td><pre></pre></td></tr><tr><td data-num="128"></td><td><pre>        self<span class="token punctuation">.</span>multi_head_attention_layer <span class="token operator">=</span> MultiHeadAttention<span class="token punctuation">(</span>head_size<span class="token operator">=</span>self<span class="token punctuation">.</span>head_size<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="129"></td><td><pre>        self<span class="token punctuation">.</span>feed_forward_layer <span class="token operator">=</span> FeedForward<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="130"></td><td><pre>        self<span class="token punctuation">.</span>layer_norm_1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>normalized_shape<span class="token operator">=</span>self<span class="token punctuation">.</span>d_model<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="131"></td><td><pre>        self<span class="token punctuation">.</span>layer_norm_2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>normalized_shape<span class="token operator">=</span>self<span class="token punctuation">.</span>d_model<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="132"></td><td><pre></pre></td></tr><tr><td data-num="133"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="134"></td><td><pre>        <span class="token comment"># Note: The order of the operations is different from the original Transformer paper</span></pre></td></tr><tr><td data-num="135"></td><td><pre>        <span class="token comment"># The order here is: LayerNorm -> Multi-head attention -> LayerNorm -> Feed forward</span></pre></td></tr><tr><td data-num="136"></td><td><pre>        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>multi_head_attention_layer<span class="token punctuation">(</span>self<span class="token punctuation">.</span>layer_norm_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># Residual connection</span></pre></td></tr><tr><td data-num="137"></td><td><pre>        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>feed_forward_layer<span class="token punctuation">(</span>self<span class="token punctuation">.</span>layer_norm_2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># Residual connection</span></pre></td></tr><tr><td data-num="138"></td><td><pre>        <span class="token keyword">return</span> x</pre></td></tr><tr><td data-num="139"></td><td><pre></pre></td></tr><tr><td data-num="140"></td><td><pre></pre></td></tr><tr><td data-num="141"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">TransformerLanguageModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="142"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="143"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="144"></td><td><pre>        self<span class="token punctuation">.</span>d_model <span class="token operator">=</span> d_model</pre></td></tr><tr><td data-num="145"></td><td><pre>        self<span class="token punctuation">.</span>context_length <span class="token operator">=</span> context_length</pre></td></tr><tr><td data-num="146"></td><td><pre>        self<span class="token punctuation">.</span>num_heads <span class="token operator">=</span> num_heads</pre></td></tr><tr><td data-num="147"></td><td><pre>        self<span class="token punctuation">.</span>num_blocks <span class="token operator">=</span> num_blocks</pre></td></tr><tr><td data-num="148"></td><td><pre>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> dropout</pre></td></tr><tr><td data-num="149"></td><td><pre>        self<span class="token punctuation">.</span>max_token_value <span class="token operator">=</span> max_token_value</pre></td></tr><tr><td data-num="150"></td><td><pre>        <span class="token comment"># Set up token embedding look-up table</span></pre></td></tr><tr><td data-num="151"></td><td><pre>        self<span class="token punctuation">.</span>token_embedding_lookup_table <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>num_embeddings<span class="token operator">=</span>self<span class="token punctuation">.</span>max_token_value <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> embedding_dim<span class="token operator">=</span>self<span class="token punctuation">.</span>d_model<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="152"></td><td><pre></pre></td></tr><tr><td data-num="153"></td><td><pre>        <span class="token comment"># Run all the transformer blocks</span></pre></td></tr><tr><td data-num="154"></td><td><pre>        <span class="token comment"># Different from original paper, here we add a final layer norm after all the blocks</span></pre></td></tr><tr><td data-num="155"></td><td><pre>        self<span class="token punctuation">.</span>transformer_blocks <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">(</span></pre></td></tr><tr><td data-num="156"></td><td><pre>                <span class="token punctuation">[</span>TransformerBlock<span class="token punctuation">(</span>num_heads<span class="token operator">=</span>self<span class="token punctuation">.</span>num_heads<span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_blocks<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">+</span></pre></td></tr><tr><td data-num="157"></td><td><pre>                <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>self<span class="token punctuation">.</span>d_model<span class="token punctuation">)</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="158"></td><td><pre>        <span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="159"></td><td><pre>        self<span class="token punctuation">.</span>language_model_out_linear_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>self<span class="token punctuation">.</span>d_model<span class="token punctuation">,</span> out_features<span class="token operator">=</span>self<span class="token punctuation">.</span>max_token_value<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="160"></td><td><pre></pre></td></tr><tr><td data-num="161"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">,</span> targets<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="162"></td><td><pre>        B<span class="token punctuation">,</span> T <span class="token operator">=</span> idx<span class="token punctuation">.</span>shape</pre></td></tr><tr><td data-num="163"></td><td><pre>        <span class="token triple-quoted-string string">"""</pre></td></tr><tr><td data-num="164"></td><td><pre>        # Set up position embedding look-up table</pre></td></tr><tr><td data-num="165"></td><td><pre>        # following the same approach as the original Transformer paper (Sine and Cosine functions)</pre></td></tr><tr><td data-num="166"></td><td><pre>        """</span></pre></td></tr><tr><td data-num="167"></td><td><pre>        position_encoding_lookup_table <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>context_length<span class="token punctuation">,</span> self<span class="token punctuation">.</span>d_model<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="168"></td><td><pre>        position <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>context_length<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="169"></td><td><pre>        div_term <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>d_model<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token operator">-</span>math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">10000.0</span><span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>d_model<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="170"></td><td><pre>        position_encoding_lookup_table<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>position <span class="token operator">*</span> div_term<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="171"></td><td><pre>        position_encoding_lookup_table<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>position <span class="token operator">*</span> div_term<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="172"></td><td><pre>        <span class="token comment"># change position_encoding_lookup_table from (context_length, d_model) to (T, d_model)</span></pre></td></tr><tr><td data-num="173"></td><td><pre>        position_embedding <span class="token operator">=</span> position_encoding_lookup_table<span class="token punctuation">[</span><span class="token punctuation">:</span>T<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="174"></td><td><pre>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>token_embedding_lookup_table<span class="token punctuation">(</span>idx<span class="token punctuation">)</span> <span class="token operator">+</span> position_embedding</pre></td></tr><tr><td data-num="175"></td><td><pre>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>transformer_blocks<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="176"></td><td><pre>        <span class="token comment"># The "logits" are the output values of our model before applying softmax</span></pre></td></tr><tr><td data-num="177"></td><td><pre>        logits <span class="token operator">=</span> self<span class="token punctuation">.</span>language_model_out_linear_layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="178"></td><td><pre></pre></td></tr><tr><td data-num="179"></td><td><pre>        <span class="token keyword">if</span> targets <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="180"></td><td><pre>            B<span class="token punctuation">,</span> T<span class="token punctuation">,</span> C <span class="token operator">=</span> logits<span class="token punctuation">.</span>shape</pre></td></tr><tr><td data-num="181"></td><td><pre>            logits_reshaped <span class="token operator">=</span> logits<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B <span class="token operator">*</span> T<span class="token punctuation">,</span> C<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="182"></td><td><pre>            targets_reshaped <span class="token operator">=</span> targets<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B <span class="token operator">*</span> T<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="183"></td><td><pre>            loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>logits_reshaped<span class="token punctuation">,</span> target<span class="token operator">=</span>targets_reshaped<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="184"></td><td><pre>        <span class="token keyword">else</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="185"></td><td><pre>            loss <span class="token operator">=</span> <span class="token boolean">None</span></pre></td></tr><tr><td data-num="186"></td><td><pre>        <span class="token keyword">return</span> logits<span class="token punctuation">,</span> loss</pre></td></tr><tr><td data-num="187"></td><td><pre></pre></td></tr><tr><td data-num="188"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">generate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">,</span> max_new_tokens<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="189"></td><td><pre>        <span class="token comment"># idx is (B,T) array of indices in the current context</span></pre></td></tr><tr><td data-num="190"></td><td><pre>        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>max_new_tokens<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="191"></td><td><pre>            <span class="token comment"># Crop idx to the max size of our positional embeddings table</span></pre></td></tr><tr><td data-num="192"></td><td><pre>            idx_crop <span class="token operator">=</span> idx<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>context_length<span class="token punctuation">:</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="193"></td><td><pre>            <span class="token comment"># Get predictions</span></pre></td></tr><tr><td data-num="194"></td><td><pre>            logits<span class="token punctuation">,</span> loss <span class="token operator">=</span> self<span class="token punctuation">(</span>idx_crop<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="195"></td><td><pre>            <span class="token comment"># Get the last time step from logits where the dimensions of the logits are (B,T,C)</span></pre></td></tr><tr><td data-num="196"></td><td><pre>            logits_last_timestep <span class="token operator">=</span> logits<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="197"></td><td><pre>            <span class="token comment"># Apply softmax to get probabilities</span></pre></td></tr><tr><td data-num="198"></td><td><pre>            probs <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>logits_last_timestep<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="199"></td><td><pre>            <span class="token comment"># Sample from the probabilities' distribution.</span></pre></td></tr><tr><td data-num="200"></td><td><pre>            idx_next <span class="token operator">=</span> torch<span class="token punctuation">.</span>multinomial<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>probs<span class="token punctuation">,</span> num_samples<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="201"></td><td><pre>            <span class="token comment"># Append the sampled indexes idx_next to idx</span></pre></td></tr><tr><td data-num="202"></td><td><pre>            idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>idx<span class="token punctuation">,</span> idx_next<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="203"></td><td><pre>        <span class="token keyword">return</span> idx</pre></td></tr><tr><td data-num="204"></td><td><pre></pre></td></tr><tr><td data-num="205"></td><td><pre></pre></td></tr><tr><td data-num="206"></td><td><pre><span class="token comment"># Initialize the model</span></pre></td></tr><tr><td data-num="207"></td><td><pre>model <span class="token operator">=</span> TransformerLanguageModel<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="208"></td><td><pre>model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="209"></td><td><pre></pre></td></tr><tr><td data-num="210"></td><td><pre></pre></td></tr><tr><td data-num="211"></td><td><pre><span class="token comment"># Get input embedding batch</span></pre></td></tr><tr><td data-num="212"></td><td><pre><span class="token keyword">def</span> <span class="token function">get_batch</span><span class="token punctuation">(</span>split<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="213"></td><td><pre>    data <span class="token operator">=</span> train_data <span class="token keyword">if</span> split <span class="token operator">==</span> <span class="token string">'train'</span> <span class="token keyword">else</span> val_data</pre></td></tr><tr><td data-num="214"></td><td><pre>    idxs <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>low<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> high<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token operator">-</span> context_length<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="215"></td><td><pre>    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>data<span class="token punctuation">[</span>idx<span class="token punctuation">:</span>idx <span class="token operator">+</span> context_length<span class="token punctuation">]</span> <span class="token keyword">for</span> idx <span class="token keyword">in</span> idxs<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="216"></td><td><pre>    y <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>data<span class="token punctuation">[</span>idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span>idx <span class="token operator">+</span> context_length <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> idx <span class="token keyword">in</span> idxs<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="217"></td><td><pre>    <span class="token keyword">return</span> x<span class="token punctuation">,</span> y</pre></td></tr><tr><td data-num="218"></td><td><pre></pre></td></tr><tr><td data-num="219"></td><td><pre></pre></td></tr><tr><td data-num="220"></td><td><pre><span class="token comment"># Calculate loss</span></pre></td></tr><tr><td data-num="221"></td><td><pre><span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="222"></td><td><pre><span class="token keyword">def</span> <span class="token function">estimate_loss</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="223"></td><td><pre>    out <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="224"></td><td><pre>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="225"></td><td><pre>    <span class="token keyword">for</span> split <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'valid'</span><span class="token punctuation">]</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="226"></td><td><pre>        losses <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>eval_iters<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="227"></td><td><pre>        <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>eval_iters<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="228"></td><td><pre>            x_batch<span class="token punctuation">,</span> y_batch <span class="token operator">=</span> get_batch<span class="token punctuation">(</span>split<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="229"></td><td><pre>            logits<span class="token punctuation">,</span> loss <span class="token operator">=</span> model<span class="token punctuation">(</span>x_batch<span class="token punctuation">,</span> y_batch<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="230"></td><td><pre>            losses<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="231"></td><td><pre>        out<span class="token punctuation">[</span>split<span class="token punctuation">]</span> <span class="token operator">=</span> losses<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="232"></td><td><pre>    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="233"></td><td><pre>    <span class="token keyword">return</span> out</pre></td></tr><tr><td data-num="234"></td><td><pre></pre></td></tr><tr><td data-num="235"></td><td><pre></pre></td></tr><tr><td data-num="236"></td><td><pre><span class="token comment"># Use AdamW optimizer</span></pre></td></tr><tr><td data-num="237"></td><td><pre>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>AdamW<span class="token punctuation">(</span>params<span class="token operator">=</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="238"></td><td><pre>tracked_losses <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="239"></td><td><pre><span class="token keyword">for</span> step <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>max_iters<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="240"></td><td><pre>    <span class="token keyword">if</span> step <span class="token operator">%</span> eval_iters <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">or</span> step <span class="token operator">==</span> max_iters <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="241"></td><td><pre>        losses <span class="token operator">=</span> estimate_loss<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="242"></td><td><pre>        tracked_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>losses<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="243"></td><td><pre>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Step:'</span><span class="token punctuation">,</span> step<span class="token punctuation">,</span> <span class="token string">'Training Loss:'</span><span class="token punctuation">,</span> <span class="token builtin">round</span><span class="token punctuation">(</span>losses<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'Validation Loss:'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="244"></td><td><pre>              <span class="token builtin">round</span><span class="token punctuation">(</span>losses<span class="token punctuation">[</span><span class="token string">'valid'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="245"></td><td><pre></pre></td></tr><tr><td data-num="246"></td><td><pre>    xb<span class="token punctuation">,</span> yb <span class="token operator">=</span> get_batch<span class="token punctuation">(</span><span class="token string">'train'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="247"></td><td><pre>    logits<span class="token punctuation">,</span> loss <span class="token operator">=</span> model<span class="token punctuation">(</span>xb<span class="token punctuation">,</span> yb<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="248"></td><td><pre>    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span>set_to_none<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="249"></td><td><pre>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="250"></td><td><pre>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="251"></td><td><pre></pre></td></tr><tr><td data-num="252"></td><td><pre><span class="token comment"># Save the model state dictionary</span></pre></td></tr><tr><td data-num="253"></td><td><pre>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'model-ckpt.pt'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="254"></td><td><pre></pre></td></tr><tr><td data-num="255"></td><td><pre><span class="token comment"># Generate</span></pre></td></tr><tr><td data-num="256"></td><td><pre>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="257"></td><td><pre>start <span class="token operator">=</span> <span class="token string">'The salesperson'</span></pre></td></tr><tr><td data-num="258"></td><td><pre>start_ids <span class="token operator">=</span> encoding<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>start<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="259"></td><td><pre>x <span class="token operator">=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>start_ids<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="260"></td><td><pre>y <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>x<span class="token punctuation">,</span> max_new_tokens<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="261"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'---------------'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="262"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>encoding<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="263"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'---------------'</span><span class="token punctuation">)</span></pre></td></tr></table></figure>
      <div class="tags">
          <a href="/tags/AI/" rel="tag"><i class="ic i-tag"></i> AI</a>
      </div>
  </div>

   <footer>

    <div class="meta">
  <span class="item">
    <span class="icon">
      <i class="ic i-calendar-check"></i>
    </span>
    <span class="text">æ›´æ–°äº</span>
    <time title="ä¿®æ”¹æ—¶é—´ï¼š2024-05-27 21:10:21" itemprop="dateModified" datetime="2024-05-27T21:10:21+08:00">2024-05-27</time>
  </span>
  <span id="2024/05/16/AI/LLM/" class="item leancloud_visitors" data-flag-title="å¤§æ¨¡å‹LLMå­¦ä¹ " title="é˜…è¯»æ¬¡æ•°">
      <span class="icon">
        <i class="ic i-eye"></i>
      </span>
      <span class="text">é˜…è¯»æ¬¡æ•°</span>
      <span class="leancloud-visitors-count"></span>
      <span class="text">æ¬¡</span>
  </span>
</div>

  </footer>

</article>

  </div>
  

<div class="post-nav">
    <div class="item left">
      

  <a href="/2024/05/16/AI/LLM_finetune/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;i.postimg.cc&#x2F;13fT61f1&#x2F;img-2000933420.jpg" title="å¤§æ¨¡å‹å¾®è°ƒ">
  <span class="type">ä¸Šä¸€ç¯‡</span>
  <span class="category"><i class="ic i-flag"></i> AI</span>
  <h3>å¤§æ¨¡å‹å¾®è°ƒ</h3>
  </a>

    </div>
    <div class="item right">
      

  <a href="/2024/07/23/math/least_square_method/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;i.postimg.cc&#x2F;hG40x9Cz&#x2F;img-2000982503.jpg" title="æœ€å°äºŒä¹˜æ³•">
  <span class="type">ä¸‹ä¸€ç¯‡</span>
  <span class="category"><i class="ic i-flag"></i> æ•°å­¦åŸºç¡€</span>
  <h3>æœ€å°äºŒä¹˜æ³•</h3>
  </a>

    </div>
</div>

  
  <div class="wrap" id="comments"></div>


        </div>
        <div id="sidebar">
          

<div class="inner">

  <div class="panels">
    <div class="inner">
      <div class="contents panel pjax" data-title="æ–‡ç« ç›®å½•">
          <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80-tokenizer"><span class="toc-number">1.</span> <span class="toc-text"> ä¸€ã€Tokenizer</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C-embedding"><span class="toc-number">2.</span> <span class="toc-text"> äºŒã€Embedding</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89-position-encoding"><span class="toc-number">3.</span> <span class="toc-text"> ä¸‰ã€Position Encoding</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B-transformer-block"><span class="toc-number">4.</span> <span class="toc-text"> å››ã€Transformer Block</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94-residual-connection-and-layer-normalization"><span class="toc-number">5.</span> <span class="toc-text"> äº”ã€Residual Connection and Layer Normalization</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AD-feed-forward-network"><span class="toc-number">6.</span> <span class="toc-text"> å…­ã€Feed-Forward Network</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%83-repeat-step-4-to-6"><span class="toc-number">7.</span> <span class="toc-text"> ä¸ƒã€Repeat step 4 to 6</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AB-output-probabilities"><span class="toc-number">8.</span> <span class="toc-text"> å…«ã€Output Probabilities</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#full-working-code"><span class="toc-number">9.</span> <span class="toc-text"> Full Working Code</span></a></li></ol>
      </div>
      <div class="related panel pjax" data-title="ç³»åˆ—æ–‡ç« ">
        <ul>
          <li><a href="/2024/02/01/AI/Neural_networks_classification/" rel="bookmark" title="ç¥ç»ç½‘ç»œå¤§è‡´åˆ†ç±»">ç¥ç»ç½‘ç»œå¤§è‡´åˆ†ç±»</a></li><li class="active"><a href="/2024/05/16/AI/LLM/" rel="bookmark" title="å¤§æ¨¡å‹LLMå­¦ä¹ ">å¤§æ¨¡å‹LLMå­¦ä¹ </a></li><li><a href="/2024/05/16/AI/LLM_finetune/" rel="bookmark" title="å¤§æ¨¡å‹å¾®è°ƒ">å¤§æ¨¡å‹å¾®è°ƒ</a></li><li><a href="/2024/07/23/AI/Prompt_engineering/" rel="bookmark" title="å¤§æ¨¡å‹æç¤ºè¯å·¥ç¨‹ï¼ˆPrompt Engineeringï¼‰">å¤§æ¨¡å‹æç¤ºè¯å·¥ç¨‹ï¼ˆPrompt Engineeringï¼‰</a></li>
        </ul>
      </div>
      <div class="overview panel" data-title="ç«™ç‚¹æ¦‚è§ˆ">
        <div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="image" itemprop="image" alt="Ember"
      data-src="/images/avatar.jpg">
  <p class="name" itemprop="name">Ember</p>
  <div class="description" itemprop="description">ğŸŒ¸å­¦ä¹ ç¬”è®°ğŸŒ¸</div>
</div>

<nav class="state">
    <div class="item posts">
      <a href="/archives/">
        <span class="count">77</span>
        <span class="name">æ–‡ç« </span>
      </a>
    </div>
    <div class="item categories">
      <a href="/categories/">
        <span class="count">14</span>
        <span class="name">åˆ†ç±»</span>
      </a>
    </div>
    <div class="item tags">
      <a href="/tags/">
        <span class="count">23</span>
        <span class="name">æ ‡ç­¾</span>
      </a>
    </div>
</nav>

<div class="social">
      <span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL3FpYW5xaXUtY2VsbA==" title="https:&#x2F;&#x2F;github.com&#x2F;qianqiu-cell"><i class="ic i-github"></i></span>
      <span class="exturl item email" data-url="bWFpbHRvOjI4MzI1Njc4NTFAcXEuY29t" title="mailto:2832567851@qq.com"><i class="ic i-envelope"></i></span>
</div>

<ul class="menu">
  
    
  <li class="item">
    <a href="/" rel="section"><i class="ic i-home"></i>é¦–é¡µ</a>
  </li>

    
  <li class="item">
    <a href="/about/" rel="section"><i class="ic i-user"></i>å…³äº</a>
  </li>

        
  <li class="item dropdown">
      <a href="javascript:void(0);"><i class="ic i-feather"></i>æ–‡ç« </a>
    <ul class="submenu">

        
  <li class="item">
    <a href="/archives/" rel="section"><i class="ic i-list-alt"></i>å½’æ¡£</a>
  </li>

        
  <li class="item">
    <a href="/categories/" rel="section"><i class="ic i-th"></i>åˆ†ç±»</a>
  </li>

        
  <li class="item">
    <a href="/tags/" rel="section"><i class="ic i-tags"></i>æ ‡ç­¾</a>
  </li>

  </ul>
    
  <li class="item">
    <a href="/friends/" rel="section"><i class="ic i-heart"></i>friends</a>
  </li>

    
  <li class="item">
    <a href="/links/" rel="section"><i class="ic i-magic"></i>links</a>
  </li>


</ul>

      </div>
    </div>
  </div>

  <ul id="quick">
    <li class="prev pjax">
        <a href="/2024/05/16/AI/LLM_finetune/" rel="prev" title="ä¸Šä¸€ç¯‡"><i class="ic i-chevron-left"></i></a>
    </li>
    <li class="up"><i class="ic i-arrow-up"></i></li>
    <li class="down"><i class="ic i-arrow-down"></i></li>
    <li class="next pjax">
        <a href="/2024/07/23/math/least_square_method/" rel="next" title="ä¸‹ä¸€ç¯‡"><i class="ic i-chevron-right"></i></a>
    </li>
    <li class="percent"></li>
  </ul>
</div>


        </div>
        <div class="dimmer"></div>
      </div>
    </main>
    <footer id="footer">
      <div class="inner">
        <div class="widgets">
          
<div class="rpost pjax">
  <h2>éšæœºæ–‡ç« </h2>
  <ul>
      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="åˆ†ç±»äº python">python</a>
</div>

    <span><a href="/2023/03/01/code/python/python_test/" title="Python test in xxxé—®é¢˜">Python test in xxxé—®é¢˜</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/blog/" title="åˆ†ç±»äº åšå®¢æ­å»º">åšå®¢æ­å»º</a>
</div>

    <span><a href="/2023/01/02/blog/hexo_image/" title="Hexoå›¾ç‰‡æ˜¾ç¤ºå¼‚å¸¸é—®é¢˜">Hexoå›¾ç‰‡æ˜¾ç¤ºå¼‚å¸¸é—®é¢˜</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/latex/" title="åˆ†ç±»äº latex">latex</a>
</div>

    <span><a href="/2024/03/01/latex/visio_eps/" title="Visioå›¾ç‰‡å¯¼å‡ºPDFè½¬EPSæ ¼å¼">Visioå›¾ç‰‡å¯¼å‡ºPDFè½¬EPSæ ¼å¼</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="åˆ†ç±»äº python">python</a>
</div>

    <span><a href="/2023/03/02/code/python/python_numba/" title="ä½¿ç”¨numbaå¯¹pythonè¿›è¡ŒåŠ é€Ÿ">ä½¿ç”¨numbaå¯¹pythonè¿›è¡ŒåŠ é€Ÿ</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="åˆ†ç±»äº python">python</a>
</div>

    <span><a href="/2024/02/20/code/python/python_pytorch_transforms/" title="Pytorchæ•°æ®é¢„å¤„ç†ï¼štransformsçš„ä½¿ç”¨">Pytorchæ•°æ®é¢„å¤„ç†ï¼štransformsçš„ä½¿ç”¨</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="åˆ†ç±»äº python">python</a>
</div>

    <span><a href="/2023/02/06/code/python/python_note/" title="Pycharmä¸­çš„ç‰¹æ®Šæ³¨é‡Š">Pycharmä¸­çš„ç‰¹æ®Šæ³¨é‡Š</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/blog/" title="åˆ†ç±»äº åšå®¢æ­å»º">åšå®¢æ­å»º</a>
</div>

    <span><a href="/2022/12/24/blog/hexo_change/" title="Hexoæ–‡ä»¶è¿ç§»">Hexoæ–‡ä»¶è¿ç§»</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="åˆ†ç±»äº python">python</a>
</div>

    <span><a href="/2023/02/06/code/python/python_bitwise_operators/" title="PythonæŒ‰ä½è¿ç®—ç¬¦">PythonæŒ‰ä½è¿ç®—ç¬¦</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/math/" title="åˆ†ç±»äº æ•°å­¦åŸºç¡€">æ•°å­¦åŸºç¡€</a>
</div>

    <span><a href="/2024/07/23/math/least_square_method/" title="æœ€å°äºŒä¹˜æ³•">æœ€å°äºŒä¹˜æ³•</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="åˆ†ç±»äº python">python</a>
</div>

    <span><a href="/2023/03/12/code/python/python_class_inherit/" title="pythonç±»çš„ç»§æ‰¿">pythonç±»çš„ç»§æ‰¿</a></span>
  </li>

  </ul>
</div>
<div>
  <h2>æœ€æ–°è¯„è®º</h2>
  <ul class="leancloud-recent-comment"></ul>
</div>

        </div>
        <div class="status">
  <div class="copyright">
    
    &copy; 2022 â€“ 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="ic i-sakura rotate"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Ember @ å”¯çˆ±ãºç¬babyãƒ«</span>
  </div>
  <div class="count">
    <span class="post-meta-item-icon">
      <i class="ic i-chart-area"></i>
    </span>
    <span title="ç«™ç‚¹æ€»å­—æ•°">244k å­—</span>

    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="ic i-coffee"></i>
    </span>
    <span title="ç«™ç‚¹é˜…è¯»æ—¶é•¿">3:41</span>
  </div>
  <div class="powered-by">
    åŸºäº <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span>
  </div>
</div>

      </div>
    </footer>
  </div>
<script data-config type="text/javascript">
  var LOCAL = {
    path: '2024/05/16/AI/LLM/',
    favicon: {
      show: "ï¼ˆâ—Â´3ï½€â—ï¼‰ã‚„ã‚Œã‚„ã‚Œã ãœ",
      hide: "(Â´Ğ”ï½€)å¤§å¤‰ã ï¼"
    },
    search : {
      placeholder: "æ–‡ç« æœç´¢",
      empty: "å…³äº ã€Œ ${query} ã€ï¼Œä»€ä¹ˆä¹Ÿæ²¡æœåˆ°",
      stats: "${time} ms å†…æ‰¾åˆ° ${hits} æ¡ç»“æœ"
    },
    valine: true,fancybox: true,
    copyright: 'å¤åˆ¶æˆåŠŸï¼Œè½¬è½½è¯·éµå®ˆ <i class="ic i-creative-commons"></i> åè®®ã€‚',
    ignores : [
      function(uri) {
        return uri.includes('#');
      },
      function(uri) {
        return new RegExp(LOCAL.path+"$").test(uri);
      }
    ]
  };
</script>

<script src="https://cdn.polyfill.io/v2/polyfill.js"></script>

<script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script>

<script src="/js/app.js?v=0.2.5"></script>




</body>
</html>
