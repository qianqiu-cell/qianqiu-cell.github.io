



<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#FFF">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">


<link rel="alternate" type="application/rss+xml" title="Keep Moving" href="http://qianqiu-cell.github.io/rss.xml" />
<link rel="alternate" type="application/atom+xml" title="Keep Moving" href="http://qianqiu-cell.github.io/atom.xml" />
<link rel="alternate" type="application/json" title="Keep Moving" href="http://qianqiu-cell.github.io/feed.json" />

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="/css/app.css?v=0.2.5">

  
  <meta name="keywords" content="AI" />


<link rel="canonical" href="http://qianqiu-cell.github.io/2024/07/29/AI/LLM_finetune/">



  <title>
大模型微调 - AI |
唯爱ぺ灬babyル = Keep Moving = 天将降大任于斯人也</title>
<meta name="generator" content="Hexo 6.3.0"></head>
<body itemscope itemtype="http://schema.org/WebPage">
  <div id="loading">
    <div class="cat">
      <div class="body"></div>
      <div class="head">
        <div class="face"></div>
      </div>
      <div class="foot">
        <div class="tummy-end"></div>
        <div class="bottom"></div>
        <div class="legs left"></div>
        <div class="legs right"></div>
      </div>
      <div class="paw">
        <div class="hands left"></div>
        <div class="hands right"></div>
      </div>
    </div>
  </div>
  <div id="container">
    <header id="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="inner">
        <div id="brand">
          <div class="pjax">
          
  <h1 itemprop="name headline">大模型微调
  </h1>
  
<div class="meta">
  <span class="item" title="创建时间：2024-07-29 00:00:00">
    <span class="icon">
      <i class="ic i-calendar"></i>
    </span>
    <span class="text">发表于</span>
    <time itemprop="dateCreated datePublished" datetime="2024-07-29T00:00:00+08:00">2024-07-29</time>
  </span>
  <span class="item" title="本文字数">
    <span class="icon">
      <i class="ic i-pen"></i>
    </span>
    <span class="text">本文字数</span>
    <span>5.7k</span>
    <span class="text">字</span>
  </span>
  <span class="item" title="阅读时长">
    <span class="icon">
      <i class="ic i-clock"></i>
    </span>
    <span class="text">阅读时长</span>
    <span>5 分钟</span>
  </span>
</div>


          </div>
        </div>
        <nav id="nav">
  <div class="inner">
    <div class="toggle">
      <div class="lines" aria-label="切换导航栏">
        <span class="line"></span>
        <span class="line"></span>
        <span class="line"></span>
      </div>
    </div>
    <ul class="menu">
      <li class="item title"><a href="/" rel="start">唯爱ぺ灬babyル</a></li>
    </ul>
    <ul class="right">
      <li class="item theme">
        <i class="ic i-sun"></i>
      </li>
      <li class="item search">
        <i class="ic i-search"></i>
      </li>
    </ul>
  </div>
</nav>

      </div>
      <div id="imgs" class="pjax">
        <ul>
          <li class="item" data-background-image="https://i.postimg.cc/Rh5wZfyD/img-2000906221.jpg"></li>
          <li class="item" data-background-image="https://i.postimg.cc/fy7Gyc22/img-2001024813.jpg"></li>
          <li class="item" data-background-image="https://i.postimg.cc/9X4k4p9D/img-2000907359.jpg"></li>
          <li class="item" data-background-image="https://i.postimg.cc/RFsVPzQQ/img-2000937871.jpg"></li>
          <li class="item" data-background-image="https://i.postimg.cc/G2gjLZKX/img-2000899915.jpg"></li>
          <li class="item" data-background-image="https://i.postimg.cc/HxVV1xLP/img-2000957688.jpg"></li>
        </ul>
      </div>
    </header>
    <div id="waves">
      <svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto">
        <defs>
          <path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z" />
        </defs>
        <g class="parallax">
          <use xlink:href="#gentle-wave" x="48" y="0" />
          <use xlink:href="#gentle-wave" x="48" y="3" />
          <use xlink:href="#gentle-wave" x="48" y="5" />
          <use xlink:href="#gentle-wave" x="48" y="7" />
        </g>
      </svg>
    </div>
    <main>
      <div class="inner">
        <div id="main" class="pjax">
          
  <div class="article wrap">
    
<div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList">
<i class="ic i-home"></i>
<span><a href="/">首页</a></span><i class="ic i-angle-right"></i>
<span  class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/AI/" itemprop="item" rel="index" title="分类于 AI"><span itemprop="name">AI</span></a>
<meta itemprop="position" content="1" /></span>
</div>

    <article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN">
  <link itemprop="mainEntityOfPage" href="http://qianqiu-cell.github.io/2024/07/29/AI/LLM_finetune/">

  <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="image" content="/images/avatar.jpg">
    <meta itemprop="name" content="Ember">
    <meta itemprop="description" content="天将降大任于斯人也, 🌸学习笔记🌸">
  </span>

  <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Keep Moving">
  </span>

  <div class="body md" itemprop="articleBody">
    

    <p>参考链接：<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzU2NTkxODE0L2FydGljbGUvZGV0YWlscy8xMzEyOTM5NDA=">https://blog.csdn.net/qq_56591814/article/details/131293940</span>、<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVdrYnplVUVWRC8/c3BtX2lkX2Zyb209MzMzLjg4MC5teV9oaXN0b3J5LnBhZ2UuY2xpY2smYW1wO3ZkX3NvdXJjZT1lMDExNzJlYTI5MmMxYzYwNWIzNDYxMDFkNzAwNmM2MQ==">https://www.bilibili.com/video/BV1WkbzeUEVD/?spm_id_from=333.880.my_history.page.click&amp;vd_source=e01172ea292c1c605b346101d7006c61</span></p>
<h1 id="一-为什么要对大模型进行微调"><a class="markdownIt-Anchor" href="#一-为什么要对大模型进行微调">#</a> 一、为什么要对大模型进行微调</h1>
<p>  通常，要对大模型进行微调，有以下一些原因：</p>
<ul>
<li>
<p>第一个原因是，因为大模型的参数量非常大，训练成本非常高，每家公司都去从头训练一个自己的大模型，这个事情的性价比非常低；</p>
</li>
<li>
<p>第二个原因是， <code>Prompt Engineering</code>  的方式是一种相对来说容易上手的使用大模型的方式，但是它的缺点也非常明显。因为通常大模型的实现原理，都会对输入序列的长度有限制， <code>Prompt Engineering</code>  的方式会把 <code>Prompt</code>  搞得很长。越长的 <code>Prompt</code> ，大模型的推理成本越高，因为推理成本是跟 <code>Prompt</code>  长度的平方正向相关的。另外， <code>Prompt</code>  太长会因超过限制而被截断，进而导致大模型的输出质量打折口，这也是一个非常严重的问题。对于个人使用者而言，如果是解决自己日常生活、工作中的一些问题，直接用 <code>Prompt Engineering</code>  的方式，通常问题不大。但对于对外提供服务的企业来说，要想在自己的服务中接入大模型的能力，推理成本是不得不要考虑的一个因素，微调相对来说就是一个更优的方案。</p>
</li>
<li>
<p>第三个原因是， <code>Prompt Engineering</code>  的效果达不到要求，企业又有比较好的自有数据，能够通过自有数据，更好的提升大模型在特定领域的能力。这时候微调就非常适用。</p>
</li>
<li>
<p>第四个原因是，要在个性化的服务中使用大模型的能力，这时候针对每个用户的数据，训练一个轻量级的微调模型，就是一个不错的方案。</p>
</li>
<li>
<p>第五个原因是，数据安全的问题。如果数据是不能传递给第三方大模型服务的，那么搭建自己的大模型就非常必要。通常这些开源的大模型都是需要用自有数据进行微调，才能够满足业务的需求，这时候也需要对大模型进行微调。</p>
</li>
</ul>
<h1 id="二-大模型微调的技术手段"><a class="markdownIt-Anchor" href="#二-大模型微调的技术手段">#</a> 二、大模型微调的技术手段</h1>
<p>  根据微调对整个预训练模型的调整程度，微调可以分为全微调和部分微调两个方法：</p>
<ul>
<li>
<p>全微调（ <code>Full Fine-tuning, FFT</code> ）： <code>FFT</code>  是指对整个预训练模型进行微调，包括所有的模型参数。在这种方法中，预训练模型的所有层和参数都会被更新和优化，以适应目标任务的需求。这种微调方法通常适用于任务和预训练模型之间存在较大差异的情况，或者任务需要模型具有高度灵活性和自适应能力的情况。 <code>FFT</code>  需要较大的计算资源和时间，但可以获得更好的性能。</p>
</li>
<li>
<p>参数高效微调（ <code>Parameter-Efficient Fine-Tuning, PEFT</code> ）： <code>PEFT</code>  旨在通过最小化微调参数数量和计算复杂度，提升预训练模型在新任务上的表现，从而减轻大型预训练模型的训练负担。 <code>PEFT</code>  方法可以通过多种方式进行分类，比如根据其基本方法或结构进行区分 —— 是否向模型引入新的参数，还是仅微调不分现有的参数；根据微调目的进行分类 —— 是否旨在最小化内存占用或仅追求存储效率。我们首先基于基本方法 &amp; 结构进行分类，下图展示了这个分类体系的 <code>30</code>  种 <code>PEFT</code>  方法。接下来对 <code>PEFT</code>  的分类进行详细介绍。</p>
</li>
</ul>
<p><img data-src="/images/AI/LLM_finetune/2.1.png" alt=""></p>
<h2 id="21-additive-methods"><a class="markdownIt-Anchor" href="#21-additive-methods">#</a> 2.1 Additive methods</h2>
<p>  主要思想是通过<mark>添加额外的参数或层来扩充现有的预训练模型，并仅训练新添加的参数</mark>。到目前为止，这是参数高效微调方法中最大且广泛探索的类别。这种方法又分为：</p>
<ul>
<li><code>Adapters</code> ：即在 <code>Transformer</code>  子层后引入小型全连接网络，这种方法被广泛采用。 <code>Adapters</code>  有多种变体，例如修改适配器的位置、剪枝以及使用重参数化来减少可训练参数的数量。</li>
<li><code>Soft Prompts</code> ： <code>GPT-2</code>  旨在通过修改输入文本来控制语言模型的行为。然而，这些方法很难进行优化，且存在模型输入长度、训练示例的数量等限制，由此引入了 <code>soft</code>  概念。 <code>Soft Prompts</code> <mark> 将模型的一部分输入嵌入通过梯度下降进行微调</mark>，将在离散空间中寻找提示的问题转化为连续优化问题。 <code>Soft Prompts</code>  可以仅对输入层进行训练（<span class="exturl" data-url="aHR0cHM6Ly9wYXBlcnN3aXRoY29kZS5jb20vcGFwZXIvZ3B0LXVuZGVyc3RhbmRzLXRvbw==">《GPT Understands, Too》</span>、<span class="exturl" data-url="aHR0cHM6Ly9wYXBlcnN3aXRoY29kZS5jb20vcGFwZXIvdGhlLXBvd2VyLW9mLXNjYWxlLWZvci1wYXJhbWV0ZXItZWZmaWNpZW50">Prompt Tuning</span>），也可以对所有层进行训练（<span class="exturl" data-url="aHR0cHM6Ly9wYXBlcnN3aXRoY29kZS5jb20vcGFwZXIvcHJlZml4LXR1bmluZy1vcHRpbWl6aW5nLWNvbnRpbnVvdXMtcHJvbXB0cw==">Prefix-Tuning</span>）。</li>
<li><code>others</code> ：例如 <code>LeTS</code> ,  <code>LST</code>  和 <code>(IA)^3</code></li>
</ul>
<p>  尽管这些方法引入了额外的参数到网络中，但它们通过减少梯度和优化器状态的大小，减少了训练时间，提升了内存效率。此外可以对冻结的模型参数进行量化（<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzU2NTkxODE0L2FydGljbGUvZGV0YWlscy8xMzEyOTM5NDA=">参考论文</span>）， <code>additive PEFT</code>  方法能够微调更大的网络或使用更大的批次大小，这提高了在 <code>GPU</code>  上的训练吞吐量。此外，在分布式设置中优化较少的参数大大减少了通信量。</p>
<h2 id="22-selective-methods"><a class="markdownIt-Anchor" href="#22-selective-methods">#</a> 2.2 Selective methods</h2>
<p>  最早的 <code>selective PEFT</code>  方法是仅微调网络的几个顶层（冻结前层），现代方法通常基于层的类型（<span class="exturl" data-url="aHR0cHM6Ly9wYXBlcnN3aXRoY29kZS5jb20vcGFwZXIvb24tdGhlLXN0cmVuZ3Rocy1vZi1jcm9zcy1hdHRlbnRpb24taW4=">Cross-Attention is All You Need</span>）或内部结构，例如仅微调模型的偏置（<span class="exturl" data-url="aHR0cHM6Ly9wYXBlcnN3aXRoY29kZS5jb20vcGFwZXIvYml0Zml0LXNpbXBsZS1wYXJhbWV0ZXItZWZmaWNpZW50LWZpbmUtdHVuaW5n">BitFit</span>）或仅特定的行（<span class="exturl" data-url="aHR0cHM6Ly9wYXBlcnN3aXRoY29kZS5jb20vcGFwZXIvZWZmaWNpZW50LWZpbmUtdHVuaW5nLW9mLWJlcnQtbW9kZWxzLW9uLXRoZQ==">Efficient Fine-Tuning of BERT Models on the Edge</span>）。</p>
<h2 id="23-reparametrization-based-peft重参数化"><a class="markdownIt-Anchor" href="#23-reparametrization-based-peft重参数化">#</a> 2.3 Reparametrization-based PEFT（重参数化）</h2>
<p>  利用低秩表示来最小化可训练参数的数量。Aghajanyan 等人（2020）证明了在低秩子空间中可以有效地进行微调，对于更大的模型或经过更长时间预训练的模型，需要进行调整的子空间更小。最知名的基于重参数化的方法 <code>LoRa</code> ，它将参数矩阵进行简单的低秩分解来更新权重。最近的研究（Karimi Mahabadi 等，2021；Edalati 等，2022）还探索了 <code>Kronecker product reparametrization</code>  的使用，它在秩和参数数量之间取得了更有利的权衡。</p>
<p>   <code>LoRA</code>  背后有一个假设：我们现在看到的这些大语言模型，它们都是被过度参数化的。而过度参数化的大模型背后，都有一个低维的本质模型。</p>
<p>  大白话说：大模型参数很多，但并不是所有的参数都是发挥同样作用的；大模型中有其中一部分参数，是非常重要的，是影响大模型生成结果的关键参数，这部分关键参数就是上面提到的低维的本质模型。</p>
<p>   <code>LoRA</code>  的基本思路，包括以下几步：</p>
<ul>
<li>
<p>首先，要适配特定的下游任务，要训练一个特定的模型，将 <code>Y=WX</code>  变成 <code>Y=(W+∆W)X</code> ，这里面 <code>∆W</code>  主是我们要微调得到的结果；</p>
</li>
<li>
<p>其次，将 <code>∆W</code>  进行低维分解 <code>∆W=AB</code>  ( <code>∆W</code>  为 <code>m*n</code>  维， <code>A</code>  为 <code>m*r</code>  维， <code>B</code>  为 <code>r*n</code>  维， <code>r</code>  就是上述假设中的低维)；</p>
</li>
<li>
<p>接下来，用特定的训练数据，训练出 <code>A</code>  和 <code>B</code>  即可得到 <code>∆W</code> ，在推理的过程中直接将 <code>∆W</code>  加到 <code>W</code>  上去，再没有额外的成本。</p>
</li>
<li>
<p>另外，如果要用 <code>LoRA</code>  适配不同的场景，切换也非常方便，做简单的矩阵加法即可： <code>(W+∆W)-∆W+∆W'</code> 。</p>
</li>
</ul>
<p>  该方法认为模型权重矩阵在特定微调后具有较低的本征秩，故基于秩分解的概念，将预训练模型的现有权重矩阵分成两个较小的矩阵。</p>
<p><img data-src="/images/AI/LLM_finetune/2.2.png" alt=""></p>
<h2 id="24-hybrid-methods"><a class="markdownIt-Anchor" href="#24-hybrid-methods">#</a> 2.4 Hybrid methods</h2>
<p>  混合多种 <code>PEFT</code>  方法，例如， <code>MAM Adapter</code>  结合了 <code>Adapters</code>  和 <code>Prompt tuning</code> ； <code>UniPELT</code>  加入了 <code>LoRa</code> ,  <code>Compacter</code>  和 <code>KronAB</code>  对适配器进行了重参数化以减少其参数数量；最后， <code>S4</code>  是一个自动化算法搜索的结果，它结合了所有的 <code>PEFT</code>  类别，额外参数数量增加 0.5% 的情况下最大化准确性。</p>
<h1 id="三-使用llama-factory微调qwen2模型"><a class="markdownIt-Anchor" href="#三-使用llama-factory微调qwen2模型">#</a> 三、使用 LLaMA-Factory 微调 Qwen2 模型</h1>
<h2 id="31-运行qwen2模型"><a class="markdownIt-Anchor" href="#31-运行qwen2模型">#</a> 3.1 运行 Qwen2 模型</h2>
<p>  首先进入下载 Qwen2 的<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1F3ZW5MTS9Rd2VuMg=="> github 网页</span>的运行文件。运行 <code>Qwen2/examples/demo/web_demo.py</code>  即可在网页端运行 <code>Qwen2</code>  模型。</p>
<p>  若本地没有大模型参数文件，则会下载 <code>hugging face</code>  中的参数文件。但是 <code>hugging face</code>  由于网络原因会导致模型下载失败。因此选择国内的<span class="exturl" data-url="aHR0cHM6Ly93d3cubW9kZWxzY29wZS5jbi9teS9vdmVydmlldw=="> ModelScope</span> 网站下载所需要的 <code>Qwen2</code>  大模型参数文件。找到对应的模型参数文件，依次点击模型文件 - 下载模型 - SDK 下载，即可获得模型参数文件的下载方式，一个示例下载的 <code>python</code>  程序如下所示：</p>
<figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">#模型下载</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> modelscope <span class="token keyword">import</span> snapshot_download</pre></td></tr><tr><td data-num="3"></td><td><pre>model_dir <span class="token operator">=</span> snapshot_download<span class="token punctuation">(</span><span class="token string">'qwen/Qwen2-1.5B-Instruct'</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>  待下载完成模型文件后，更改 <code>web_demo.py</code>  文件的 <code>DEFAULT_CKPT_PATH</code>  参数为所下载模型参数文件的路径，一个示例的路径为： <code>DEFAULT_CKPT_PATH = 'E:/python/9_LLM/2_FineTuning/4_Qwen/qwen/Qwen2-1___5B-Instruct'</code></p>
<p>  之后即可成功运行 <code>web_demo.py</code> ，并与所下载的大模型参数文件对应的大模型进行对话。</p>
<p><img data-src="/images/AI/LLM_finetune/3.1.png" alt=""></p>
<h2 id="32-下载并运行llama-factory"><a class="markdownIt-Anchor" href="#32-下载并运行llama-factory">#</a> 3.2 下载并运行 LLaMA-Factory</h2>
<p>  首先进入 <code>github</code>  的<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2hpeW91Z2EvTExhTUEtRmFjdG9yeQ=="> LLaMA-Factory 网页</span>，下载 <code>LLaMA-Factory</code>  工具箱。运行 <code>LLaMA-Factory-main/src/webui.py</code>  即可运行 <code>LLaMA-Factory</code>  的网页可视化界面。可视化界面如下所示：</p>
<p><img data-src="/images/AI/LLM_finetune/3.2.png" alt=""></p>
<h2 id="33-准备数据集"><a class="markdownIt-Anchor" href="#33-准备数据集">#</a> 3.3 准备数据集</h2>
<p>  在 <code>LLaMA-Factory-main/data</code>  文件夹下保存了几组示例数据集的 <code>json</code>  文件。其中 <code>dataset_info.json</code>  包含了所有可用的数据集。参考<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2hpeW91Z2EvTExhTUEtRmFjdG9yeS9ibG9iL21haW4vZGF0YS9SRUFETUVfemgubWQ="> LLaMA-Factory 的说明文件</span>，如果希望使用自定义数据集，需要在 <code>dataset_info.json</code>  文件中添加数据集描述，目前 <code>LLaMA-Factory</code>  仅支持 <code>alpaca</code>  格式和 <code>sharegpt</code>  格式的数据集。完整的数据集描述如下，具体的示例可以参考初始 <code>dataset_info.json</code>  文件：</p>
<figure class="highlight markdown"><figcaption data-lang="markdown"></figcaption><table><tr><td data-num="1"></td><td><pre>"数据集名称": &#123;</pre></td></tr><tr><td data-num="2"></td><td><pre>  "hf_hub_url": "Hugging Face 的数据集仓库地址（若指定，则忽略 script_url 和 file_name）",</pre></td></tr><tr><td data-num="3"></td><td><pre>  "ms_hub_url": "ModelScope 的数据集仓库地址（若指定，则忽略 script_url 和 file_name）",</pre></td></tr><tr><td data-num="4"></td><td><pre>  "script_url": "包含数据加载脚本的本地文件夹名称（若指定，则忽略 file_name）",</pre></td></tr><tr><td data-num="5"></td><td><pre>  "file_name": "该目录下数据集文件夹或文件的名称（若上述参数未指定，则此项必需）",</pre></td></tr><tr><td data-num="6"></td><td><pre>  "formatting": "数据集格式（可选，默认：alpaca，可以为 alpaca 或 sharegpt）",</pre></td></tr><tr><td data-num="7"></td><td><pre>  "ranking": "是否为偏好数据集（可选，默认：False）",</pre></td></tr><tr><td data-num="8"></td><td><pre>  "subset": "数据集子集的名称（可选，默认：None）",</pre></td></tr><tr><td data-num="9"></td><td><pre>  "split": "所使用的数据集切分（可选，默认：train）",</pre></td></tr><tr><td data-num="10"></td><td><pre>  "folder": "Hugging Face 仓库的文件夹名称（可选，默认：None）",</pre></td></tr><tr><td data-num="11"></td><td><pre>  "num_samples": "该数据集所使用的样本数量。（可选，默认：None）",</pre></td></tr><tr><td data-num="12"></td><td><pre>  "columns（可选）": &#123;</pre></td></tr><tr><td data-num="13"></td><td><pre>    "prompt": "数据集代表提示词的表头名称（默认：instruction）",</pre></td></tr><tr><td data-num="14"></td><td><pre>    "query": "数据集代表请求的表头名称（默认：input）",</pre></td></tr><tr><td data-num="15"></td><td><pre>    "response": "数据集代表回答的表头名称（默认：output）",</pre></td></tr><tr><td data-num="16"></td><td><pre>    "history": "数据集代表历史对话的表头名称（默认：None）",</pre></td></tr><tr><td data-num="17"></td><td><pre>    "messages": "数据集代表消息列表的表头名称（默认：conversations）",</pre></td></tr><tr><td data-num="18"></td><td><pre>    "system": "数据集代表系统提示的表头名称（默认：None）",</pre></td></tr><tr><td data-num="19"></td><td><pre>    "tools": "数据集代表工具描述的表头名称（默认：None）",</pre></td></tr><tr><td data-num="20"></td><td><pre>    "images": "数据集代表图像输入的表头名称（默认：None）",</pre></td></tr><tr><td data-num="21"></td><td><pre>    "chosen": "数据集代表更优回答的表头名称（默认：None）",</pre></td></tr><tr><td data-num="22"></td><td><pre>    "rejected": "数据集代表更差回答的表头名称（默认：None）",</pre></td></tr><tr><td data-num="23"></td><td><pre>    "kto_tag": "数据集代表 KTO 标签的表头名称（默认：None）"</pre></td></tr><tr><td data-num="24"></td><td><pre>  &#125;,</pre></td></tr><tr><td data-num="25"></td><td><pre>  "tags（可选，用于 sharegpt 格式）": &#123;</pre></td></tr><tr><td data-num="26"></td><td><pre>    "role_tag": "消息中代表发送者身份的键名（默认：from）",</pre></td></tr><tr><td data-num="27"></td><td><pre>    "content_tag": "消息中代表文本内容的键名（默认：value）",</pre></td></tr><tr><td data-num="28"></td><td><pre>    "user_tag": "消息中代表用户的 role_tag（默认：human）",</pre></td></tr><tr><td data-num="29"></td><td><pre>    "assistant_tag": "消息中代表助手的 role_tag（默认：gpt）",</pre></td></tr><tr><td data-num="30"></td><td><pre>    "observation_tag": "消息中代表工具返回结果的 role_tag（默认：observation）",</pre></td></tr><tr><td data-num="31"></td><td><pre>    "function_tag": "消息中代表工具调用的 role_tag（默认：function_call）",</pre></td></tr><tr><td data-num="32"></td><td><pre>    "system_tag": "消息中代表系统提示的 role_tag（默认：system，会覆盖 system column）"</pre></td></tr><tr><td data-num="33"></td><td><pre>  &#125;</pre></td></tr><tr><td data-num="34"></td><td><pre>&#125;</pre></td></tr></table></figure><p>  添加完成数据集描述后，即可在在 <code>LLaMA-Factory-main/data</code>  文件夹内创建对应数据集名称的 <code>json</code>  文件，即可完成自定义数据集的添加。数据集的格式需要和数据集描述一致，详细的示例可以参考初始在 <code>LLaMA-Factory-main/data</code>  文件夹下的其他 <code>json</code>  数据集文件。</p>
<h2 id="34-使用llama-factory进行大模型微调"><a class="markdownIt-Anchor" href="#34-使用llama-factory进行大模型微调">#</a> 3.4 使用 LLaMA-Factory 进行大模型微调</h2>
<p>  在准备好微调的数据集之后，即可再次运行 <code>LLaMA-Factory-main/src/webui.py</code> ，启动 LLaMA-Factory 的可视化界面，其中的部分参数定义如下，需要注意的是数据路径应该指定为本地计算机 <code>LLaMA-Factory-main/data</code>  文件夹的绝对路径：</p>
<p><img data-src="/images/AI/LLM_finetune/3.2.png" alt=""></p>
<p>  定义完成训练参数后即可点击 “开始” 按钮，开始模型的微调训练。模型训练完毕后，点击 <code>Chat</code>  选项卡，检查点路径选择训练好的大模型，即可开始与微调完成的大模型进行在线对话。点击 <code>Export</code>  选项卡，指定导出目录以及其他设置，点击 “开始导出”，即可导出训练完毕的大模型。至此，已经完成使用 <code>LLaMA-Factory</code>  进行大模型微调的全部过程。</p>

      <div class="tags">
          <a href="/tags/AI/" rel="tag"><i class="ic i-tag"></i> AI</a>
      </div>
  </div>

   <footer>

    <div class="meta">
  <span class="item">
    <span class="icon">
      <i class="ic i-calendar-check"></i>
    </span>
    <span class="text">更新于</span>
    <time title="修改时间：2024-07-29 13:06:49" itemprop="dateModified" datetime="2024-07-29T13:06:49+08:00">2024-07-29</time>
  </span>
  <span id="2024/07/29/AI/LLM_finetune/" class="item leancloud_visitors" data-flag-title="大模型微调" title="阅读次数">
      <span class="icon">
        <i class="ic i-eye"></i>
      </span>
      <span class="text">阅读次数</span>
      <span class="leancloud-visitors-count"></span>
      <span class="text">次</span>
  </span>
</div>

  </footer>

</article>

  </div>
  

<div class="post-nav">
    <div class="item left">
      

  <a href="/2024/07/25/control/MOESP/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;i.postimg.cc&#x2F;7Pg1hs9P&#x2F;img-2001035236.jpg" title="MOESP系统辨识方法">
  <span class="type">上一篇</span>
  <span class="category"><i class="ic i-flag"></i> 控制工程</span>
  <h3>MOESP系统辨识方法</h3>
  </a>

    </div>
    <div class="item right">
      

  <a href="/2024/08/27/code/python/python_ipdb/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;i.postimg.cc&#x2F;MTxd9CKT&#x2F;img-2000889855.jpg" title="IPython Debugger (ipdb)">
  <span class="type">下一篇</span>
  <span class="category"><i class="ic i-flag"></i> python</span>
  <h3>IPython Debugger (ipdb)</h3>
  </a>

    </div>
</div>

  
  <div class="wrap" id="comments"></div>


        </div>
        <div id="sidebar">
          

<div class="inner">

  <div class="panels">
    <div class="inner">
      <div class="contents panel pjax" data-title="文章目录">
          <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AF%B9%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E5%BE%AE%E8%B0%83"><span class="toc-number">1.</span> <span class="toc-text"> 一、为什么要对大模型进行微调</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E7%9A%84%E6%8A%80%E6%9C%AF%E6%89%8B%E6%AE%B5"><span class="toc-number">2.</span> <span class="toc-text"> 二、大模型微调的技术手段</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#21-additive-methods"><span class="toc-number">2.1.</span> <span class="toc-text"> 2.1 Additive methods</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#22-selective-methods"><span class="toc-number">2.2.</span> <span class="toc-text"> 2.2 Selective methods</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#23-reparametrization-based-peft%E9%87%8D%E5%8F%82%E6%95%B0%E5%8C%96"><span class="toc-number">2.3.</span> <span class="toc-text"> 2.3 Reparametrization-based PEFT（重参数化）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#24-hybrid-methods"><span class="toc-number">2.4.</span> <span class="toc-text"> 2.4 Hybrid methods</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89-%E4%BD%BF%E7%94%A8llama-factory%E5%BE%AE%E8%B0%83qwen2%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.</span> <span class="toc-text"> 三、使用 LLaMA-Factory 微调 Qwen2 模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#31-%E8%BF%90%E8%A1%8Cqwen2%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.1.</span> <span class="toc-text"> 3.1 运行 Qwen2 模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#32-%E4%B8%8B%E8%BD%BD%E5%B9%B6%E8%BF%90%E8%A1%8Cllama-factory"><span class="toc-number">3.2.</span> <span class="toc-text"> 3.2 下载并运行 LLaMA-Factory</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#33-%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.3.</span> <span class="toc-text"> 3.3 准备数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#34-%E4%BD%BF%E7%94%A8llama-factory%E8%BF%9B%E8%A1%8C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83"><span class="toc-number">3.4.</span> <span class="toc-text"> 3.4 使用 LLaMA-Factory 进行大模型微调</span></a></li></ol></li></ol>
      </div>
      <div class="related panel pjax" data-title="系列文章">
        <ul>
          <li><a href="/2024/02/01/AI/Neural_networks_classification/" rel="bookmark" title="神经网络大致分类">神经网络大致分类</a></li><li><a href="/2024/05/16/AI/Transformer/" rel="bookmark" title="Transformer模型">Transformer模型</a></li><li><a href="/2024/07/23/AI/Prompt_engineering/" rel="bookmark" title="大模型提示词工程（Prompt Engineering）">大模型提示词工程（Prompt Engineering）</a></li><li class="active"><a href="/2024/07/29/AI/LLM_finetune/" rel="bookmark" title="大模型微调">大模型微调</a></li><li><a href="/2024/09/12/AI/CLIP/" rel="bookmark" title="CLIP">CLIP</a></li><li><a href="/2024/09/14/AI/BERT/" rel="bookmark" title="BERT">BERT</a></li><li><a href="/2024/09/14/AI/BLIP/" rel="bookmark" title="BLIP">BLIP</a></li><li><a href="/2024/09/19/AI/SimCLR/" rel="bookmark" title="SimCLR">SimCLR</a></li><li><a href="/2024/09/21/AI/ViT/" rel="bookmark" title="ViT">ViT</a></li>
        </ul>
      </div>
      <div class="overview panel" data-title="站点概览">
        <div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="image" itemprop="image" alt="Ember"
      data-src="/images/avatar.jpg">
  <p class="name" itemprop="name">Ember</p>
  <div class="description" itemprop="description">🌸学习笔记🌸</div>
</div>

<nav class="state">
    <div class="item posts">
      <a href="/archives/">
        <span class="count">87</span>
        <span class="name">文章</span>
      </a>
    </div>
    <div class="item categories">
      <a href="/categories/">
        <span class="count">15</span>
        <span class="name">分类</span>
      </a>
    </div>
    <div class="item tags">
      <a href="/tags/">
        <span class="count">24</span>
        <span class="name">标签</span>
      </a>
    </div>
</nav>

<div class="social">
      <span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL3FpYW5xaXUtY2VsbA==" title="https:&#x2F;&#x2F;github.com&#x2F;qianqiu-cell"><i class="ic i-github"></i></span>
      <span class="exturl item email" data-url="bWFpbHRvOjI4MzI1Njc4NTFAcXEuY29t" title="mailto:2832567851@qq.com"><i class="ic i-envelope"></i></span>
</div>

<ul class="menu">
  
    
  <li class="item">
    <a href="/" rel="section"><i class="ic i-home"></i>首页</a>
  </li>

    
  <li class="item">
    <a href="/about/" rel="section"><i class="ic i-user"></i>关于</a>
  </li>

        
  <li class="item dropdown">
      <a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a>
    <ul class="submenu">

        
  <li class="item">
    <a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a>
  </li>

        
  <li class="item">
    <a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a>
  </li>

        
  <li class="item">
    <a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a>
  </li>

  </ul>
    
  <li class="item">
    <a href="/friends/" rel="section"><i class="ic i-heart"></i>friends</a>
  </li>

    
  <li class="item">
    <a href="/links/" rel="section"><i class="ic i-magic"></i>links</a>
  </li>


</ul>

      </div>
    </div>
  </div>

  <ul id="quick">
    <li class="prev pjax">
        <a href="/2024/07/25/control/MOESP/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a>
    </li>
    <li class="up"><i class="ic i-arrow-up"></i></li>
    <li class="down"><i class="ic i-arrow-down"></i></li>
    <li class="next pjax">
        <a href="/2024/08/27/code/python/python_ipdb/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a>
    </li>
    <li class="percent"></li>
  </ul>
</div>


        </div>
        <div class="dimmer"></div>
      </div>
    </main>
    <footer id="footer">
      <div class="inner">
        <div class="widgets">
          
<div class="rpost pjax">
  <h2>随机文章</h2>
  <ul>
      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="分类于 python">python</a>
</div>

    <span><a href="/2023/04/02/code/python/python_thread/" title="Python多线程">Python多线程</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="分类于 python">python</a>
</div>

    <span><a href="/2023/03/02/code/python/python_try_except/" title="python下的try-except处理异常">python下的try-except处理异常</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/leetcode/" title="分类于 leetcode">leetcode</a>
</div>

    <span><a href="/2023/10/31/code/leetcode/Binary_Search/" title="二分查找的正确编写方法">二分查找的正确编写方法</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="分类于 python">python</a>
</div>

    <span><a href="/2023/03/12/code/python/python_enumerate/" title="python使用enumerate()给列表添加序号">python使用enumerate()给列表添加序号</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="分类于 python">python</a>
</div>

    <span><a href="/2023/03/02/code/python/python_gurobi/" title="python+gurobi应用">python+gurobi应用</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="分类于 python">python</a>
</div>

    <span><a href="/2023/02/06/code/python/python_special_func/" title="特定功能函数">特定功能函数</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/search/" title="分类于 search">search</a>
</div>

    <span><a href="/2024/08/28/search/Search_for_a_Stationary_Target/" title="搜索一个静止的目标">搜索一个静止的目标</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="分类于 python">python</a>
</div>

    <span><a href="/2023/02/06/code/python/python_multiply/" title="python字符串、列表、元组乘法">python字符串、列表、元组乘法</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="分类于 python">python</a>
</div>

    <span><a href="/2023/03/12/code/python/python_class_inherit/" title="python类的继承">python类的继承</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/optimal/" title="分类于 最优化">最优化</a>
</div>

    <span><a href="/2022/12/23/optimal/signal_objective_optimization/" title="单目标搜索算法汇总">单目标搜索算法汇总</a></span>
  </li>

  </ul>
</div>
<div>
  <h2>最新评论</h2>
  <ul class="leancloud-recent-comment"></ul>
</div>

        </div>
        <div class="status">
  <div class="copyright">
    
    &copy; 2022 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="ic i-sakura rotate"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Ember @ 唯爱ぺ灬babyル</span>
  </div>
  <div class="count">
    <span class="post-meta-item-icon">
      <i class="ic i-chart-area"></i>
    </span>
    <span title="站点总字数">295k 字</span>

    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="ic i-coffee"></i>
    </span>
    <span title="站点阅读时长">4:28</span>
  </div>
  <div class="powered-by">
    基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span>
  </div>
</div>

      </div>
    </footer>
  </div>
<script data-config type="text/javascript">
  var LOCAL = {
    path: '2024/07/29/AI/LLM_finetune/',
    favicon: {
      show: "（●´3｀●）やれやれだぜ",
      hide: "(´Д｀)大変だ！"
    },
    search : {
      placeholder: "文章搜索",
      empty: "关于 「 ${query} 」，什么也没搜到",
      stats: "${time} ms 内找到 ${hits} 条结果"
    },
    valine: true,fancybox: true,
    copyright: '复制成功，转载请遵守 <i class="ic i-creative-commons"></i> 协议。',
    ignores : [
      function(uri) {
        return uri.includes('#');
      },
      function(uri) {
        return new RegExp(LOCAL.path+"$").test(uri);
      }
    ]
  };
</script>

<script src="https://cdn.polyfill.io/v2/polyfill.js"></script>

<script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script>

<script src="/js/app.js?v=0.2.5"></script>




</body>
</html>
