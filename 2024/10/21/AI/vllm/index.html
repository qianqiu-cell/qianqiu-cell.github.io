



<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#FFF">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">


<link rel="alternate" type="application/rss+xml" title="Keep Moving" href="http://qianqiu-cell.github.io/rss.xml" />
<link rel="alternate" type="application/atom+xml" title="Keep Moving" href="http://qianqiu-cell.github.io/atom.xml" />
<link rel="alternate" type="application/json" title="Keep Moving" href="http://qianqiu-cell.github.io/feed.json" />

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="/css/app.css?v=0.2.5">

  
  <meta name="keywords" content="AI" />


<link rel="canonical" href="http://qianqiu-cell.github.io/2024/10/21/AI/vllm/">



  <title>
vLLM - AI |
唯爱ぺ灬babyル = Keep Moving = 天将降大任于斯人也</title>
<meta name="generator" content="Hexo 6.3.0"></head>
<body itemscope itemtype="http://schema.org/WebPage">
  <div id="loading">
    <div class="cat">
      <div class="body"></div>
      <div class="head">
        <div class="face"></div>
      </div>
      <div class="foot">
        <div class="tummy-end"></div>
        <div class="bottom"></div>
        <div class="legs left"></div>
        <div class="legs right"></div>
      </div>
      <div class="paw">
        <div class="hands left"></div>
        <div class="hands right"></div>
      </div>
    </div>
  </div>
  <div id="container">
    <header id="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="inner">
        <div id="brand">
          <div class="pjax">
          
  <h1 itemprop="name headline">vLLM
  </h1>
  
<div class="meta">
  <span class="item" title="创建时间：2024-10-21 00:00:00">
    <span class="icon">
      <i class="ic i-calendar"></i>
    </span>
    <span class="text">发表于</span>
    <time itemprop="dateCreated datePublished" datetime="2024-10-21T00:00:00+08:00">2024-10-21</time>
  </span>
  <span class="item" title="本文字数">
    <span class="icon">
      <i class="ic i-pen"></i>
    </span>
    <span class="text">本文字数</span>
    <span>5.6k</span>
    <span class="text">字</span>
  </span>
  <span class="item" title="阅读时长">
    <span class="icon">
      <i class="ic i-clock"></i>
    </span>
    <span class="text">阅读时长</span>
    <span>5 分钟</span>
  </span>
</div>


          </div>
        </div>
        <nav id="nav">
  <div class="inner">
    <div class="toggle">
      <div class="lines" aria-label="切换导航栏">
        <span class="line"></span>
        <span class="line"></span>
        <span class="line"></span>
      </div>
    </div>
    <ul class="menu">
      <li class="item title"><a href="/" rel="start">唯爱ぺ灬babyル</a></li>
    </ul>
    <ul class="right">
      <li class="item theme">
        <i class="ic i-sun"></i>
      </li>
      <li class="item search">
        <i class="ic i-search"></i>
      </li>
    </ul>
  </div>
</nav>

      </div>
      <div id="imgs" class="pjax">
        <ul>
          <li class="item" data-background-image="https://i.postimg.cc/PrZvqPQg/img-2000943305.jpg"></li>
          <li class="item" data-background-image="https://i.postimg.cc/ZRZTY5jL/img-2000927098.jpg"></li>
          <li class="item" data-background-image="https://i.postimg.cc/6psDn5GJ/img-2001095299.jpg"></li>
          <li class="item" data-background-image="https://i.postimg.cc/SRLXDPRy/img-2000995033.jpg"></li>
          <li class="item" data-background-image="https://i.postimg.cc/kXLft68q/img-2001096907.jpg"></li>
          <li class="item" data-background-image="https://i.postimg.cc/cJ7vBjbX/img-2000933840.jpg"></li>
        </ul>
      </div>
    </header>
    <div id="waves">
      <svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto">
        <defs>
          <path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z" />
        </defs>
        <g class="parallax">
          <use xlink:href="#gentle-wave" x="48" y="0" />
          <use xlink:href="#gentle-wave" x="48" y="3" />
          <use xlink:href="#gentle-wave" x="48" y="5" />
          <use xlink:href="#gentle-wave" x="48" y="7" />
        </g>
      </svg>
    </div>
    <main>
      <div class="inner">
        <div id="main" class="pjax">
          
  <div class="article wrap">
    
<div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList">
<i class="ic i-home"></i>
<span><a href="/">首页</a></span><i class="ic i-angle-right"></i>
<span  class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/AI/" itemprop="item" rel="index" title="分类于 AI"><span itemprop="name">AI</span></a>
<meta itemprop="position" content="1" /></span>
</div>

    <article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN">
  <link itemprop="mainEntityOfPage" href="http://qianqiu-cell.github.io/2024/10/21/AI/vllm/">

  <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="image" content="/images/avatar.jpg">
    <meta itemprop="name" content="Ember">
    <meta itemprop="description" content="天将降大任于斯人也, 🌸学习笔记🌸">
  </span>

  <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Keep Moving">
  </span>

  <div class="body md" itemprop="articleBody">
    

    <p>参考连接：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3ZsbG0tcHJvamVjdC92bGxt">https://github.com/vllm-project/vllm</span></p>
<h1 id="一-vllm介绍"><a class="markdownIt-Anchor" href="#一-vllm介绍">#</a> 一、vLLM 介绍</h1>
<p>  大型语言模型（LLMs）承诺将彻底改变我们在所有行业中使用人工智能的方式。然而，实际上部署这些模型是具有挑战性的，并且即使在昂贵的硬件上也可能出人意料地慢。</p>
<p>  <strong>vLLM</strong> 是一个用于快速大型语言<strong>模型推理</strong>和服务的开源库。vLLM 利用了新注意力算法<strong> PagedAttention</strong>，它有效地管理注意力键和值（KV cache）。</p>
<p>  配备 PagedAttention 的 vLLM 重新定义了大型语言模型服务的新标准：它提供的吞吐量比 HuggingFace Transformers 高出多达 24 倍，而无需对模型架构进行任何更改。</p>
<h1 id="二-pagedattention原理"><a class="markdownIt-Anchor" href="#二-pagedattention原理">#</a> 二、PagedAttention 原理</h1>
<p>  在 vLLM 中，LLM 的性能受到内存的限制。在自回归解码过程中，所有输入到 LLM 的 token 都会生成它们的<strong>注意力键 (attention key)<strong> 和</strong>值张量 (value tensors)</strong>，而这些张量被保存在 GPU 内存中以生成下一个 token。这些缓存的键和值张量通常被称为<strong> KV cache</strong>。KV cache 的特点为：</p>
<ul>
<li><strong>大型</strong>：在 LLaMA-13B 中，单个序列可能占用高达 1.7GB。</li>
<li><strong>动态</strong>：其大小取决于序列长度，这是高度可变且不可预测的。因此，有效管理 KV 缓存是一个重大挑战。由于碎片化和过度预留，现有系统浪费了 60% 至 80% 的内存。</li>
</ul>
<p>  为了解决这个问题，vLLM 引入了一种名为<strong> PagedAttention</strong> 的注意力算法，它受到了操作系统中虚拟内存和分页这一经典思想的启发。与传统的注意力算法不同，PagedAttention<strong> 允许在非连续的内存空间中存储连续的键和值</strong>。具体来说，PagedAttention<strong> 将每个序列的键值（KV）缓存划分为多个块，每个块包含固定数量的 token 的 keys 和 values</strong>。在注意力计算过程中，PagedAttention 内核能够高效地识别并获取这些块。</p>
<p><img data-src="/images/AI/vLLM/2.1.gif" alt="" title="PagedAttention：KV cache 被划分成多个块。这些块在内存空间中不需要是连续的"></p>
<p>  因为块在内存中不需要是连续的，可以像操作系统的虚拟内存那样以更灵活的方式管理 keys 和 values：可以将块看作是分页，tokens 看作是字节，sequences 看作是进程。sequence 的连续逻辑块通过块表映射到不连续的物理块。随着新 token 的生成，物理块按需分配。</p>
<p><img data-src="/images/AI/vLLM/2.2.gif" alt="" title="PagedAttention对一条request的生成过程示例"></p>
<p>  在 PagedAttention 中，<strong>内存浪费仅发生在序列的最后一个区块中</strong>。在实践中，这导致接近最优的内存使用，仅有不到 4% 的微小浪费。这种内存效率的提升被证明是非常有益的：它允许系统将更多的序列一起批处理，提高 GPU 利用率，从而显著提高吞吐量。</p>
<p>  PagedAttention 还有另一个关键优势：高效的内存共享。例如，在<strong>并行采样</strong>中，可以从同一个 prompt 生成多个输出序列。在这种情况下，对该 prompt 的计算和内存可以在输出序列之间共享。</p>
<p><img data-src="/images/AI/vLLM/2.3.gif" alt="" title="并行计算示例"></p>
<p>  PagedAttention 通过其块表自然地实现了内存共享。类似于进程共享物理页面的方式，不同序列在 PagedAttention 中可以通过将它们的逻辑块映射到同一个物理块来共享块。为了确保安全的共享，PagedAttention 会跟踪物理块的引用计数，并实现了写时复制（Copy-on-Write）机制。</p>
<p><img data-src="/images/AI/vLLM/2.4.gif" alt="" title="对一条request生成多条输出的示例"></p>
<p>  PageAttention 的内存共享大大减少了复杂采样算法的内存开销，如并行采样和束搜索，将它们的内存使用量减少了高达 55%。这可以转化为吞吐量高达 2.2 倍的提升。这使得这些采样方法在 LLM 服务中变得实用。</p>
<p>  PagedAttention 是 vLLM 背后的核心技术，vLLM 是我们的大型语言模型（LLM）推理和服务引擎，它支持多种模型，具有高性能和易于使用的界面。</p>
<h1 id="三-开始使用vllm"><a class="markdownIt-Anchor" href="#三-开始使用vllm">#</a> 三、开始使用 vLLM</h1>
<p>  使用如下命令安装 vLLM：</p>
<figure class="highlight sh"><figcaption data-lang="sh"></figcaption><table><tr><td data-num="1"></td><td><pre>pip <span class="token function">install</span> vllm</pre></td></tr></table></figure><p>  vLLM 可以用于离线推理和在线服务。要使用 vLLM 进行离线推理，可以在 Python 脚本中导入 vLLM 并使用 LLM 类：</p>
<figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> vllm <span class="token keyword">import</span> LLM<span class="token punctuation">,</span> SamplingParams</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>prompts <span class="token operator">=</span> <span class="token punctuation">[</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token string">"Hello, my name is"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token string">"The president of the United States is"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    <span class="token string">"The capital of France is"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    <span class="token string">"The future of AI is"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="10"></td><td><pre>sampling_params <span class="token operator">=</span> SamplingParams<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">,</span> top_p<span class="token operator">=</span><span class="token number">0.95</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>llm <span class="token operator">=</span> LLM<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"facebook/opt-125m"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>outputs <span class="token operator">=</span> llm<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>prompts<span class="token punctuation">,</span> sampling_params<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token keyword">for</span> output <span class="token keyword">in</span> outputs<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="17"></td><td><pre>    prompt <span class="token operator">=</span> output<span class="token punctuation">.</span>prompt</pre></td></tr><tr><td data-num="18"></td><td><pre>    generated_text <span class="token operator">=</span> output<span class="token punctuation">.</span>outputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>text</pre></td></tr><tr><td data-num="19"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Prompt: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>prompt<span class="token conversion-option punctuation">!r</span><span class="token punctuation">&#125;</span></span><span class="token string">, Generated text: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>generated_text<span class="token conversion-option punctuation">!r</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>  运行结果如下：</p>
<figure class="highlight sh"><figcaption data-lang="sh"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token punctuation">(</span>vllm<span class="token punctuation">)</span> ember@ember-Victus-by-HP-Laptop:~/project/python/1_vllm$ python main.py </pre></td></tr><tr><td data-num="2"></td><td><pre>INFO <span class="token number">10</span>-30 <span class="token number">17</span>:14:44 llm_engine.py:237<span class="token punctuation">]</span> Initializing an LLM engine <span class="token punctuation">(</span>v0.6.3.post1<span class="token punctuation">)</span> with config: <span class="token assign-left variable">model</span><span class="token operator">=</span><span class="token string">'facebook/opt-125m'</span>, <span class="token assign-left variable">speculative_config</span><span class="token operator">=</span>None, <span class="token assign-left variable">tokenizer</span><span class="token operator">=</span><span class="token string">'facebook/opt-125m'</span>, <span class="token assign-left variable">skip_tokenizer_init</span><span class="token operator">=</span>False, <span class="token assign-left variable">tokenizer_mode</span><span class="token operator">=</span>auto, <span class="token assign-left variable">revision</span><span class="token operator">=</span>None, <span class="token assign-left variable">override_neuron_config</span><span class="token operator">=</span>None, <span class="token assign-left variable">rope_scaling</span><span class="token operator">=</span>None, <span class="token assign-left variable">rope_theta</span><span class="token operator">=</span>None, <span class="token assign-left variable">tokenizer_revision</span><span class="token operator">=</span>None, <span class="token assign-left variable">trust_remote_code</span><span class="token operator">=</span>False, <span class="token assign-left variable">dtype</span><span class="token operator">=</span>torch.float16, <span class="token assign-left variable">max_seq_len</span><span class="token operator">=</span><span class="token number">2048</span>, <span class="token assign-left variable">download_dir</span><span class="token operator">=</span>None, <span class="token assign-left variable">load_format</span><span class="token operator">=</span>LoadFormat.AUTO, <span class="token assign-left variable">tensor_parallel_size</span><span class="token operator">=</span><span class="token number">1</span>, <span class="token assign-left variable">pipeline_parallel_size</span><span class="token operator">=</span><span class="token number">1</span>, <span class="token assign-left variable">disable_custom_all_reduce</span><span class="token operator">=</span>False, <span class="token assign-left variable">quantization</span><span class="token operator">=</span>None, <span class="token assign-left variable">enforce_eager</span><span class="token operator">=</span>False, <span class="token assign-left variable">kv_cache_dtype</span><span class="token operator">=</span>auto, <span class="token assign-left variable">quantization_param_path</span><span class="token operator">=</span>None, <span class="token assign-left variable">device_config</span><span class="token operator">=</span>cuda, <span class="token assign-left variable">decoding_config</span><span class="token operator">=</span>DecodingConfig<span class="token punctuation">(</span>guided_decoding_backend<span class="token operator">=</span><span class="token string">'outlines'</span><span class="token punctuation">)</span>, <span class="token assign-left variable">observability_config</span><span class="token operator">=</span>ObservabilityConfig<span class="token punctuation">(</span>otlp_traces_endpoint<span class="token operator">=</span>None, <span class="token assign-left variable">collect_model_forward_time</span><span class="token operator">=</span>False, <span class="token assign-left variable">collect_model_execute_time</span><span class="token operator">=</span>False<span class="token punctuation">)</span>, <span class="token assign-left variable">seed</span><span class="token operator">=</span><span class="token number">0</span>, <span class="token assign-left variable">served_model_name</span><span class="token operator">=</span>facebook/opt-125m, <span class="token assign-left variable">num_scheduler_steps</span><span class="token operator">=</span><span class="token number">1</span>, <span class="token assign-left variable">chunked_prefill_enabled</span><span class="token operator">=</span>False <span class="token assign-left variable">multi_step_stream_outputs</span><span class="token operator">=</span>True, <span class="token assign-left variable">enable_prefix_caching</span><span class="token operator">=</span>False, <span class="token assign-left variable">use_async_output_proc</span><span class="token operator">=</span>True, <span class="token assign-left variable">use_cached_outputs</span><span class="token operator">=</span>False, <span class="token assign-left variable">mm_processor_kwargs</span><span class="token operator">=</span>None<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>INFO <span class="token number">10</span>-30 <span class="token number">17</span>:14:45 model_runner.py:1056<span class="token punctuation">]</span> Starting to load model facebook/opt-125m<span class="token punctuation">..</span>.</pre></td></tr><tr><td data-num="4"></td><td><pre>INFO <span class="token number">10</span>-30 <span class="token number">17</span>:14:45 weight_utils.py:243<span class="token punctuation">]</span> Using model weights <span class="token function">format</span> <span class="token punctuation">[</span><span class="token string">'*.bin'</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="5"></td><td><pre>Loading pt checkpoint shards:   <span class="token number">0</span>% Completed <span class="token operator">|</span> <span class="token number">0</span>/1 <span class="token punctuation">[</span>00:0<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>?, ?it/s<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="6"></td><td><pre>/home/ember/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/model_executor/model_loader/weight_utils.py:425: FutureWarning: You are using <span class="token variable"><span class="token variable">`</span>torch.load<span class="token variable">`</span></span> with <span class="token variable"><span class="token variable">`</span><span class="token assign-left variable">weights_only</span><span class="token operator">=</span>False<span class="token variable">`</span></span> <span class="token punctuation">(</span>the current default value<span class="token punctuation">)</span>, <span class="token function">which</span> uses the default pickle module implicitly. It is possible to construct malicious pickle data <span class="token function">which</span> will execute arbitrary code during unpickling <span class="token punctuation">(</span>See https://github.com/pytorch/pytorch/blob/main/SECURITY.md<span class="token comment">#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.</span></pre></td></tr><tr><td data-num="7"></td><td><pre>  state <span class="token operator">=</span> torch.load<span class="token punctuation">(</span>bin_file, <span class="token assign-left variable">map_location</span><span class="token operator">=</span><span class="token string">"cpu"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>Loading pt checkpoint shards: <span class="token number">100</span>% Completed <span class="token operator">|</span> <span class="token number">1</span>/1 <span class="token punctuation">[</span>00:0<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>00:00,  <span class="token number">2</span>.61it/s<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="9"></td><td><pre>Loading pt checkpoint shards: <span class="token number">100</span>% Completed <span class="token operator">|</span> <span class="token number">1</span>/1 <span class="token punctuation">[</span>00:0<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>00:00,  <span class="token number">2</span>.61it/s<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>INFO <span class="token number">10</span>-30 <span class="token number">17</span>:14:46 model_runner.py:1067<span class="token punctuation">]</span> Loading model weights took <span class="token number">0.2389</span> GB</pre></td></tr><tr><td data-num="12"></td><td><pre>INFO <span class="token number">10</span>-30 <span class="token number">17</span>:14:46 gpu_executor.py:122<span class="token punctuation">]</span> <span class="token comment"># GPU blocks: 4774, # CPU blocks: 7281</span></pre></td></tr><tr><td data-num="13"></td><td><pre>INFO <span class="token number">10</span>-30 <span class="token number">17</span>:14:46 gpu_executor.py:126<span class="token punctuation">]</span> Maximum concurrency <span class="token keyword">for</span> <span class="token number">2048</span> tokens per request: <span class="token number">37</span>.30x</pre></td></tr><tr><td data-num="14"></td><td><pre>INFO <span class="token number">10</span>-30 <span class="token number">17</span>:14:48 model_runner.py:1395<span class="token punctuation">]</span> Capturing the model <span class="token keyword">for</span> CUDA graphs. This may lead to unexpected consequences <span class="token keyword">if</span> the model is not static. To run the model <span class="token keyword">in</span> eager mode, <span class="token builtin class-name">set</span> <span class="token string">'enforce_eager=True'</span> or use <span class="token string">'--enforce-eager'</span> <span class="token keyword">in</span> the CLI.</pre></td></tr><tr><td data-num="15"></td><td><pre>INFO <span class="token number">10</span>-30 <span class="token number">17</span>:14:48 model_runner.py:1399<span class="token punctuation">]</span> CUDA graphs can take additional <span class="token number">1</span>~3 GiB memory per GPU. If you are running out of memory, consider decreasing <span class="token variable"><span class="token variable">`</span>gpu_memory_utilization<span class="token variable">`</span></span> or enforcing eager mode. You can also reduce the <span class="token variable"><span class="token variable">`</span>max_num_seqs<span class="token variable">`</span></span> as needed to decrease memory usage.</pre></td></tr><tr><td data-num="16"></td><td><pre>INFO <span class="token number">10</span>-30 <span class="token number">17</span>:14:58 model_runner.py:1523<span class="token punctuation">]</span> Graph capturing finished <span class="token keyword">in</span> <span class="token number">10</span> secs.</pre></td></tr><tr><td data-num="17"></td><td><pre>Processed prompts: <span class="token number">100</span>%<span class="token operator">|</span>████<span class="token operator">|</span> <span class="token number">4</span>/4 <span class="token punctuation">[</span>00:0<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>00:00, <span class="token number">29</span>.75it/s, est. speed input: <span class="token number">193.42</span> toks/s, output: <span class="token number">476.10</span> toks/s<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="18"></td><td><pre>Prompt: <span class="token string">'Hello, my name is'</span>, Generated text: <span class="token string">" Joel. I'm a 24 year old software developer and I'm looking for a"</span></pre></td></tr><tr><td data-num="19"></td><td><pre>Prompt: <span class="token string">'The president of the United States is'</span>, Generated text: <span class="token string">', in my opinion, the worst person ever to be president.\n> In'</span></pre></td></tr><tr><td data-num="20"></td><td><pre>Prompt: <span class="token string">'The capital of France is'</span>, Generated text: <span class="token string">' wrong because a country is full of self-doubts about its own future'</span></pre></td></tr><tr><td data-num="21"></td><td><pre>Prompt: <span class="token string">'The future of AI is'</span>, Generated text: <span class="token string">' in AI and a lot of it is just making sure everyone has an AI that'</span></pre></td></tr></table></figure>
      <div class="tags">
          <a href="/tags/AI/" rel="tag"><i class="ic i-tag"></i> AI</a>
      </div>
  </div>

   <footer>

    <div class="meta">
  <span class="item">
    <span class="icon">
      <i class="ic i-calendar-check"></i>
    </span>
    <span class="text">更新于</span>
    <time title="修改时间：2024-10-30 17:39:09" itemprop="dateModified" datetime="2024-10-30T17:39:09+08:00">2024-10-30</time>
  </span>
  <span id="2024/10/21/AI/vllm/" class="item leancloud_visitors" data-flag-title="vLLM" title="阅读次数">
      <span class="icon">
        <i class="ic i-eye"></i>
      </span>
      <span class="text">阅读次数</span>
      <span class="leancloud-visitors-count"></span>
      <span class="text">次</span>
  </span>
</div>

  </footer>

</article>

  </div>
  

<div class="post-nav">
    <div class="item left">
      

  <a href="/2024/10/20/linux/docker/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;i.postimg.cc&#x2F;5tZ5YwLV&#x2F;img-2000879955.jpg" title="docker">
  <span class="type">上一篇</span>
  <span class="category"><i class="ic i-flag"></i> linux</span>
  <h3>docker</h3>
  </a>

    </div>
    <div class="item right">
      

  <a href="/2024/10/22/linux/linux_nvidia/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;i.postimg.cc&#x2F;xCK3Htv2&#x2F;img-2000933428.jpg" title="Ubuntu 20.04 Nvidia驱动安装">
  <span class="type">下一篇</span>
  <span class="category"><i class="ic i-flag"></i> linux</span>
  <h3>Ubuntu 20.04 Nvidia驱动安装</h3>
  </a>

    </div>
</div>

  
  <div class="wrap" id="comments"></div>


        </div>
        <div id="sidebar">
          

<div class="inner">

  <div class="panels">
    <div class="inner">
      <div class="contents panel pjax" data-title="文章目录">
          <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80-vllm%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text"> 一、vLLM 介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C-pagedattention%E5%8E%9F%E7%90%86"><span class="toc-number">2.</span> <span class="toc-text"> 二、PagedAttention 原理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8vllm"><span class="toc-number">3.</span> <span class="toc-text"> 三、开始使用 vLLM</span></a></li></ol>
      </div>
      <div class="related panel pjax" data-title="系列文章">
        <ul>
          <li><a href="/2024/02/01/AI/Neural_networks_classification/" rel="bookmark" title="神经网络大致分类">神经网络大致分类</a></li><li><a href="/2024/05/16/AI/Transformer/" rel="bookmark" title="Transformer模型">Transformer模型</a></li><li><a href="/2024/07/23/AI/Prompt_engineering/" rel="bookmark" title="大模型提示词工程（Prompt Engineering）">大模型提示词工程（Prompt Engineering）</a></li><li><a href="/2024/07/29/AI/LLM_finetune/" rel="bookmark" title="大模型微调">大模型微调</a></li><li><a href="/2024/08/26/AI/DiffusionModel/" rel="bookmark" title="扩散模型">扩散模型</a></li><li><a href="/2024/09/12/AI/CLIP/" rel="bookmark" title="CLIP">CLIP</a></li><li><a href="/2024/09/14/AI/BERT/" rel="bookmark" title="BERT">BERT</a></li><li><a href="/2024/09/14/AI/BLIP/" rel="bookmark" title="BLIP">BLIP</a></li><li><a href="/2024/09/19/AI/SimCLR/" rel="bookmark" title="SimCLR">SimCLR</a></li><li><a href="/2024/09/21/AI/ViT/" rel="bookmark" title="ViT">ViT</a></li><li><a href="/2024/10/05/AI/MAE/" rel="bookmark" title="MAE">MAE</a></li><li class="active"><a href="/2024/10/21/AI/vllm/" rel="bookmark" title="vLLM">vLLM</a></li><li><a href="/2024/11/01/AI/Qwen2.5-math/" rel="bookmark" title="Qwen2.5-Math">Qwen2.5-Math</a></li><li><a href="/2024/12/11/AI/deepspeed/" rel="bookmark" title="Deepspeed">Deepspeed</a></li><li><a href="/2024/12/11/AI/else/" rel="bookmark" title="其他未学习的可用工具">其他未学习的可用工具</a></li><li><a href="/2024/12/29/AI/PrecisionRecall/" rel="bookmark" title="准确率、精确率、召回率等指标定义">准确率、精确率、召回率等指标定义</a></li><li><a href="/2024/12/30/AI/RFT/" rel="bookmark" title="RFT（拒绝采样）">RFT（拒绝采样）</a></li><li><a href="/2024/12/31/AI/Top_k/" rel="bookmark" title="Top_k, Top_p, Temperature 参数">Top_k, Top_p, Temperature 参数</a></li><li><a href="/2024/12/31/AI/attention/" rel="bookmark" title="注意力机制综述">注意力机制综述</a></li><li><a href="/2025/01/02/AI/MinHash/" rel="bookmark" title="使用 MinHash 进行文本去重">使用 MinHash 进行文本去重</a></li><li><a href="/2025/01/02/AI/N-gram/" rel="bookmark" title="N-gram 模型">N-gram 模型</a></li><li><a href="/2025/01/02/AI/TIR/" rel="bookmark" title="TIR(ToRE) 集成工具推理">TIR(ToRE) 集成工具推理</a></li><li><a href="/2025/02/03/AI/LLM_base/" rel="bookmark" title="大模型基础课程（浙江大学）">大模型基础课程（浙江大学）</a></li>
        </ul>
      </div>
      <div class="overview panel" data-title="站点概览">
        <div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="image" itemprop="image" alt="Ember"
      data-src="/images/avatar.jpg">
  <p class="name" itemprop="name">Ember</p>
  <div class="description" itemprop="description">🌸学习笔记🌸</div>
</div>

<nav class="state">
    <div class="item posts">
      <a href="/archives/">
        <span class="count">107</span>
        <span class="name">文章</span>
      </a>
    </div>
    <div class="item categories">
      <a href="/categories/">
        <span class="count">15</span>
        <span class="name">分类</span>
      </a>
    </div>
    <div class="item tags">
      <a href="/tags/">
        <span class="count">24</span>
        <span class="name">标签</span>
      </a>
    </div>
</nav>

<div class="social">
      <span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL3FpYW5xaXUtY2VsbA==" title="https:&#x2F;&#x2F;github.com&#x2F;qianqiu-cell"><i class="ic i-github"></i></span>
      <span class="exturl item email" data-url="bWFpbHRvOjI4MzI1Njc4NTFAcXEuY29t" title="mailto:2832567851@qq.com"><i class="ic i-envelope"></i></span>
</div>

<ul class="menu">
  
    
  <li class="item">
    <a href="/" rel="section"><i class="ic i-home"></i>首页</a>
  </li>

    
  <li class="item">
    <a href="/about/" rel="section"><i class="ic i-user"></i>关于</a>
  </li>

        
  <li class="item dropdown">
      <a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a>
    <ul class="submenu">

        
  <li class="item">
    <a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a>
  </li>

        
  <li class="item">
    <a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a>
  </li>

        
  <li class="item">
    <a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a>
  </li>

  </ul>
    
  <li class="item">
    <a href="/friends/" rel="section"><i class="ic i-heart"></i>friends</a>
  </li>

    
  <li class="item">
    <a href="/links/" rel="section"><i class="ic i-magic"></i>links</a>
  </li>


</ul>

      </div>
    </div>
  </div>

  <ul id="quick">
    <li class="prev pjax">
        <a href="/2024/10/20/linux/docker/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a>
    </li>
    <li class="up"><i class="ic i-arrow-up"></i></li>
    <li class="down"><i class="ic i-arrow-down"></i></li>
    <li class="next pjax">
        <a href="/2024/10/22/linux/linux_nvidia/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a>
    </li>
    <li class="percent"></li>
  </ul>
</div>


        </div>
        <div class="dimmer"></div>
      </div>
    </main>
    <footer id="footer">
      <div class="inner">
        <div class="widgets">
          
<div class="rpost pjax">
  <h2>随机文章</h2>
  <ul>
      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="分类于 python">python</a>
</div>

    <span><a href="/2024/03/19/code/python/python_private_property/" title="Python——类的私有属性、公有属性、私有方法、公有方法">Python——类的私有属性、公有属性、私有方法、公有方法</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/optimal/" title="分类于 最优化">最优化</a>
</div>

    <span><a href="/2023/03/15/optimal/MOEA_D/" title="MODE&#x2F;D算法">MODE/D算法</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/blog/" title="分类于 博客搭建">博客搭建</a>
</div>

    <span><a href="/2022/11/06/blog/hexo/" title="Github+Hexo+shoka主题搭建个人博客">Github+Hexo+shoka主题搭建个人博客</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/math/" title="分类于 数学基础">数学基础</a>
</div>

    <span><a href="/2023/09/17/math/Interval_by_Dimensional/" title="区间逐维分析方法">区间逐维分析方法</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="分类于 python">python</a>
</div>

    <span><a href="/2024/03/19/code/python/python_Iterators_and_Generators/" title="Python迭代器和生成器">Python迭代器和生成器</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="分类于 python">python</a>
</div>

    <span><a href="/2023/03/01/code/python/python_test/" title="Python test in xxx问题">Python test in xxx问题</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/AI/" title="分类于 AI">AI</a>
</div>

    <span><a href="/2024/10/21/AI/vllm/" title="vLLM">vLLM</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/optimal/" title="分类于 最优化">最优化</a>
</div>

    <span><a href="/2022/12/23/optimal/signal_objective_optimization/" title="单目标搜索算法汇总">单目标搜索算法汇总</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="分类于 python">python</a>
</div>

    <span><a href="/2023/02/06/code/python/python_float/" title="Python浮点数运算不精确问题">Python浮点数运算不精确问题</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/python/" title="分类于 python">python</a>
</div>

    <span><a href="/2025/01/19/code/python/init_file/" title="__init.py__文件的作用">__init.py__文件的作用</a></span>
  </li>

  </ul>
</div>
<div>
  <h2>最新评论</h2>
  <ul class="leancloud-recent-comment"></ul>
</div>

        </div>
        <div class="status">
  <div class="copyright">
    
    &copy; 2022 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="ic i-sakura rotate"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Ember @ 唯爱ぺ灬babyル</span>
  </div>
  <div class="count">
    <span class="post-meta-item-icon">
      <i class="ic i-chart-area"></i>
    </span>
    <span title="站点总字数">378k 字</span>

    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="ic i-coffee"></i>
    </span>
    <span title="站点阅读时长">5:44</span>
  </div>
  <div class="powered-by">
    基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span>
  </div>
</div>

      </div>
    </footer>
  </div>
<script data-config type="text/javascript">
  var LOCAL = {
    path: '2024/10/21/AI/vllm/',
    favicon: {
      show: "（●´3｀●）やれやれだぜ",
      hide: "(´Д｀)大変だ！"
    },
    search : {
      placeholder: "文章搜索",
      empty: "关于 「 ${query} 」，什么也没搜到",
      stats: "${time} ms 内找到 ${hits} 条结果"
    },
    valine: true,copy_tex: true,
    katex: true,fancybox: true,
    copyright: '复制成功，转载请遵守 <i class="ic i-creative-commons"></i> 协议。',
    ignores : [
      function(uri) {
        return uri.includes('#');
      },
      function(uri) {
        return new RegExp(LOCAL.path+"$").test(uri);
      }
    ]
  };
</script>

<script src="https://cdn.polyfill.io/v2/polyfill.js"></script>

<script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script>

<script src="/js/app.js?v=0.2.5"></script>




</body>
</html>
