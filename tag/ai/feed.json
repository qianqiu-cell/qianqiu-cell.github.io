{
    "version": "https://jsonfeed.org/version/1",
    "title": "Keep Moving • All posts by \"ai\" tag",
    "description": "🌸学习笔记🌸",
    "home_page_url": "http://qianqiu-cell.github.io",
    "items": [
        {
            "id": "http://qianqiu-cell.github.io/2025/02/03/AI/LLM_base/",
            "url": "http://qianqiu-cell.github.io/2025/02/03/AI/LLM_base/",
            "title": "大模型基础课程（浙江大学）",
            "date_published": "2025-02-02T16:00:00.000Z",
            "content_html": "<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVBCNlhZRkVUMj9zcG1faWRfZnJvbT0zMzMuNzg4LnZpZGVvcG9kLnNlY3Rpb25zJmFtcDt2ZF9zb3VyY2U9ZTAxMTcyZWEyOTJjMWM2MDViMzQ2MTAxZDcwMDZjNjE=\">https://www.bilibili.com/video/BV1PB6XYFET2?spm_id_from=333.788.videopod.sections&amp;vd_source=e01172ea292c1c605b346101d7006c61</span>、<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL1pKVS1MTE1zL0ZvdW5kYXRpb25zLW9mLUxMTXMvdHJlZS9tYWlu\">https://github.com/ZJU-LLMs/Foundations-of-LLMs/tree/main</span></p>\n<h1 id=\"一-语言模型基础\"><a class=\"markdownIt-Anchor\" href=\"#一-语言模型基础\">#</a> 一、语言模型基础</h1>\n<p>  语言是概率的，并且语言的概率性与认知的概率性也存在着密不可分的关系。<strong>语言模型（LanguageModels, LMs）旨在准确预测语言符号的概率</strong>。从 ELIZA 到 GPT-4，语言模型经历了<strong>从规则模型到统计模型，再到神经网络模型的发展历程</strong>，逐步从呆板的机械式问答程序成长为具有强大泛化能力的多任务智能模型。</p>\n<h2 id=\"11-基于统计方法的语言模型\"><a class=\"markdownIt-Anchor\" href=\"#11-基于统计方法的语言模型\">#</a> 1.1 基于统计方法的语言模型</h2>\n<p>  <strong>基于统计的语言模型通过直接统计语言符号在语料库中出现的频率来预测语言符号的概率</strong>。其中，<strong>n-grams</strong> 是最具代表性的统计语言模型。<strong>n-grams 语言模型基于马尔可夫假设和离散变量的极大似然估计给出语言符号的概率。</strong></p>\n<h3 id=\"111-n-grams-语言模型\"><a class=\"markdownIt-Anchor\" href=\"#111-n-grams-语言模型\">#</a> 1.1.1 n-grams 语言模型</h3>\n<p>  n-grams 语言模型中的 n-gram 指的是长度为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span> 的词序列。n-grams 语言模型通过依次统计文本中的 n-gram 及其对应的 (n-1)-gram 在语料库中出现的相对频率来计算文本<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>ω</mi><mrow><mn>1</mn><mo>:</mo><mi>N</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\omega_{1:N}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ω</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mrel mtight\">:</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 出现的概率。计算公式如下所示：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>P</mi><mrow><mi>n</mi><mo>−</mo><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mi>s</mi></mrow></msub><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mn>1</mn><mo>:</mo><mi>N</mi></mrow></msub><mo stretchy=\"false\">)</mo><mo>=</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mi>n</mi></mrow><mi>N</mi></munderover><mfrac><mrow><mi>C</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mn>1</mn><mo>+</mo><mi>i</mi><mo>−</mo><mi>n</mi><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><mrow><mi>C</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mn>1</mn><mo>+</mo><mi>i</mi><mo>−</mo><mi>n</mi><mo>:</mo><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">P_{n-grams}(w_{1:N})=\\prod_{i=n}^N\\frac{C(w_{1+i-n:i})}{C(w_{1+i-n:i-1})}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.25833100000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mbin mtight\">−</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal mtight\">a</span><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mrel mtight\">:</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:3.106005em;vertical-align:-1.277669em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.8283360000000002em;\"><span style=\"top:-1.872331em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mathnormal mtight\">n</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∏</span></span></span><span style=\"top:-4.3000050000000005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.277669em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mrel mtight\">:</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mrel mtight\">:</span><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.936em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>  通俗可理解为前 n 个词出现的情况下，将后一个词在语料库中出现的概率作为预测概率。详细的解释可参考<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL1pKVS1MTE1zL0ZvdW5kYXRpb25zLW9mLUxMTXMvdHJlZS9tYWlu\"> github</span>。</p>\n<p>  <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span> 为变量，当<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">n=1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> 时，称之为 unigram，其不考虑文本的上下文关系。当<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">n=2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">2</span></span></span></span> 时，称之为 bigrams，其对前一个词进行考虑。当<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">n=3</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span></span></span></span> 时，称之为 trigrams，其对前两个词进行考虑。当<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi><mo>=</mo><mn>4</mn></mrow><annotation encoding=\"application/x-tex\">n=4</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">4</span></span></span></span> 时，称之为 4-grams，其对前三个词进行考虑…</p>\n<p>  n-grams 具备对未知文本的泛化能力。这也是其相较于传统基于规则的方法的优势。但是，这种泛化能力会随着 n 的增大而逐渐减弱。因此，在 n-grams 语言模型中，n 代表了拟合语料库的能力与对未知文本的泛化能力之间的权衡。<strong>当 n 过大时，语料库中难以找到与 n-gram 一模一样的词序列，可能出现大量 “零概率” 现象；在 n 过小时，n-gram 难以承载足够的语言信息，不足以反应语料库的特性</strong>。因此，在 n-grams 语言模型中，n 的值是影响性能的关键因素。</p>\n<h3 id=\"112-n-grams-的统计学原理\"><a class=\"markdownIt-Anchor\" href=\"#112-n-grams-的统计学原理\">#</a> 1.1.2 n-grams 的统计学原理</h3>\n<p>  n-grams 语言模型是在<strong> n 阶马尔可夫假设</strong>下，对语料库中出现的长度为 n 的词序列出现概率的<strong>极大似然估计</strong>。 详细证明见<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL1pKVS1MTE1zL0ZvdW5kYXRpb25zLW9mLUxMTXMvdHJlZS9tYWlu\"> github</span>。</p>\n<h2 id=\"12-基于rnn的语言模型\"><a class=\"markdownIt-Anchor\" href=\"#12-基于rnn的语言模型\">#</a> 1.2 基于 RNN 的语言模型</h2>\n<p>  n-grams 语言模型对未知序列有一定的泛化性，但也容易陷入 “零概率” 的困境。基于神经网络的语言模型不再通过显性的计算公式对语言符号的概率进行计算，而是利用语料库中的样本对神经网络模型进行训练。</p>\n<p>  循环神经网络（RecurrentNeuralNetwork,RNN）可以基于历史规律，对未来进行预测。<strong>基于 RNN 的语言模型，以词序列作为输入，基于被循环编码的上文和当前词来预测下一个词出现的概率。</strong></p>\n<h3 id=\"121-循环神经网络rnn\"><a class=\"markdownIt-Anchor\" href=\"#121-循环神经网络rnn\">#</a> 1.2.1 循环神经网络 RNN</h3>\n<p>  RNN 可以将历史状态以隐变量的形式循环叠加到当前状态上，对历史信息进行考虑。但是这样的环路结构给 RNN 的训练带来了挑战。在训练 RNN 时，涉及大量的矩阵联乘操作，容易引发梯度衰减或梯度爆炸问题。为了解决梯度消失和爆炸问题，GRU 和 LSTM 引入门控结构，取得了良好效果，成为主流的 RNN 网络架构。</p>\n<h3 id=\"122-基于rnn的语言模型\"><a class=\"markdownIt-Anchor\" href=\"#122-基于rnn的语言模型\">#</a> 1.2.2 基于 RNN 的语言模型</h3>\n<p>  对词序列<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo fence=\"true\">{</mo><msub><mi>ω</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>ω</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><msub><mi>ω</mi><mn>3</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo separator=\"true\">,</mo><msub><mi>ω</mi><mi>N</mi></msub><mo fence=\"true\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\left \\{ \\omega_1,\\omega_2,\\omega_3,...,\\omega_N \\right \\}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">{</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ω</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ω</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ω</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ω</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">}</span></span></span></span></span>，基于 RNN 的语言模型每次根据当前词<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>ω</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\omega_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ω</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和循环输入的隐藏状态<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mrow><mi>i</mi><mtext>−</mtext><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">h_{i−1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.902771em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span></span>，来预测下一个词<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>ω</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\omega_{i+1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.638891em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ω</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span></span> 出现的概率，即</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mn>1</mn><mo>:</mo><mi>N</mi></mrow></msub><mo stretchy=\"false\">)</mo><mo>=</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow></munderover><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>w</mi><mi>i</mi></msub><mo separator=\"true\">,</mo><msub><mi>h</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(w_{1:N})=\\prod_{i=1}^{N-1}P(w_{i+1}|w_i,h_{i-1})\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mrel mtight\">:</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:3.1060050000000006em;vertical-align:-1.277669em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.8283360000000004em;\"><span style=\"top:-1.872331em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∏</span></span></span><span style=\"top:-4.300005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.277669em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>w</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>w</mi><mi>i</mi></msub><mo separator=\"true\">,</mo><msub><mi>h</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(w_{i+1}|w_{1:i})=P(w_{i+1}|w_i,h_{i-1})\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mrel mtight\">:</span><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>  在 “<strong>自回归</strong>” 的范式下完成文本生成任务，第一轮，首先将第一个词输入给 RNN 语言模型，经过解码，得到一个输出词。然后，将第一轮输出的词与第一轮输入的词拼接，作为第二轮的输入，然后解码得到第二轮的输出。接着，将第二轮的输出和输入拼接，作为第三轮的输入，以此类推。在循环迭代的 “自回归” 过程中，不断生成新的词，这些词便构成了一段文本。</p>\n<p>  但上述 “自回归” 过程存在着两个问题：（1）<strong>错误级联放大</strong>，选用模型自己生成的词作为输入可能会有错误，这样的错误循环输入，将会不断的放大错误，导致模型不能很好拟合训练集；（2）<strong>串行计算效率低</strong>，因为下一个要预测的词依赖上一次的预测，每次预测之间是串行的，难以进行并行加速。为了解决上述两个问题，“<strong>Teacher Forcing</strong>” 在语言模型预训练过程中被广泛应用。<strong>在 Teacher Forcing 中，每轮都仅将输出结果与 “标准答案”（GroundTruth）进行拼接作为下一轮的输入</strong>。如例子中，第二轮循环中，用 “长颈鹿脖子” 来预测下一个词 “长”，而非选用 o1 中概率最高的词 “吃” 或者其他可能输出的词。</p>\n<p><img data-src=\"/images/AI/LLM_base/1.1.png\" alt=\"\"></p>\n<p>  但是，Teacher Forcing 的训练方式将导致<strong>曝光偏差</strong>（Exposure Bias）的问题。曝光偏差是指 Teacher Forcing <strong>训练模型的过程和模型在推理过程存在差异</strong>。Teacher Forcing 在训练中，模型将依赖于 “标准答案” 进行下一次的预测，但是在推理预测中，模型 “自回归” 的产生文本，没有 “标准答案” 可参考。所以模型在训练过程中和推理过程中存在偏差，可能推理效果较差。为解决曝光偏差的问题，Bengio 等人提出了针对 RNN 提出了<strong> Scheduled Sampling 方法</strong>。其在 Teacher Forcing 的训练过程中循序渐进的使用一小部分模型自己生成的词代替 “标准答案”，在训练过程中对推理中无 “标准答案” 的情况进行预演。</p>\n<h2 id=\"13-基于transformer-的语言模型\"><a class=\"markdownIt-Anchor\" href=\"#13-基于transformer-的语言模型\">#</a> 1.3 基于 Transformer 的语言模型</h2>\n<p>  Transformer 是一类基于注意力机制（Attention）的模块化构建的神经网络结构。</p>\n<h3 id=\"131-transformer\"><a class=\"markdownIt-Anchor\" href=\"#131-transformer\">#</a> 1.3.1 Transformer</h3>\n<p>  Transformer 是由两种模块组合构建的模块化网络结构。两种模块分别为：注意力（Attention）模块和全连接前馈 Fully-connectedFeedforwad）模块。</p>\n<p><img data-src=\"/images/AI/LLM_base/1.2.png\" alt=\"\"></p>\n<ul>\n<li>注意力层（AttentionLayer）</li>\n</ul>\n<p>  具体内容参考<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL1pKVS1MTE1zL0ZvdW5kYXRpb25zLW9mLUxMTXMvdHJlZS9tYWlu\"> github</span>。</p>\n<ul>\n<li>全连接前馈层（Fully-connected Feedforwad Layer）</li>\n</ul>\n<p>  <strong>全连接前馈层占据了 Tranformer 近三分之二的参数，掌管着 Tranformer 模型的记忆</strong>。其可以看作是一种 Key-Value 模式的记忆存储管理模块 [7]。全连接前馈层包含两层，两层之间由 ReLU 作为激活函数。设全连接前馈层的输入为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>v</mi></mrow><annotation encoding=\"application/x-tex\">v</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span></span></span></span>, 全连接前馈层可由下式表示：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>F</mi><mi>F</mi><mi>N</mi><mo stretchy=\"false\">(</mo><mi>v</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><msub><mi>W</mi><mn>1</mn></msub><mi>v</mi><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo><msub><mi>W</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">FFN(v)=\\max(0,W_1v+b_1)W_2+b_2\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mop\">max</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p>  其中，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>W</mi><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">W1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord\">1</span></span></span></span> 和<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>W</mi><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">W2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord\">2</span></span></span></span> 分别为第一层和第二层的权重参数，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">b1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">b</span><span class=\"mord\">1</span></span></span></span> 和<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">b2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">b</span><span class=\"mord\">2</span></span></span></span> 分别为第一层和第二层的偏置参数。其中第一层的可看作神经记忆中的 key，而第二层可看作 value。</p>\n<ul>\n<li>层正则化（LayerNormalization）</li>\n</ul>\n<p>  <strong>层正则化用以加速神经网络训练过程并取得更好的泛化性能。</strong> 具体内容参考<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL1pKVS1MTE1zL0ZvdW5kYXRpb25zLW9mLUxMTXMvdHJlZS9tYWlu\"> github</span>。</p>\n<ul>\n<li>残差连接（ResidualConnections）</li>\n</ul>\n<p>  <strong>引入残差连接可以有效解决梯度消失问题。在基本的 Transformer 编码模块中包含两个残差连接。</strong> 第一个残差连接是将自注意力层的输入由一条旁路叠加到自注意力层的输出上，然后输入给层正则化。第二个残差连接是将全连接前馈层的输入由一条旁路引到全连接前馈层的输出上，然后输入给层正则化。</p>\n<p>  上述<strong>将层正则化置于残差连接之后的网络结构被称为 Post-LN Transformer</strong>。与之相对的，还有一种<strong>将层正则化置于残差连接之前的网络结构，称之为 Pre-LN Transformers</strong>。对比两者，Post-LN Transformer 应对表征坍塌（Representation Collapse）的能力更强，但处理梯度消失略弱。而 Pre-LN Transformers 可以更好的应对梯度消失，但处理表征坍塌的能力略弱。</p>\n<h3 id=\"132-基于transformer-的语言模型\"><a class=\"markdownIt-Anchor\" href=\"#132-基于transformer-的语言模型\">#</a> 1.3.2 基于 Transformer 的语言模型</h3>\n<p>  相较于 RNN 模型串行的循环迭代模式，Transformer 并行输入的特性，使其<strong>容易进行并行计算</strong>。但是，Transformer 并行输入的范式也导致<strong>网络模型的规模随输入序列长度的增长而平方次增长</strong>。这为应用 Transformer 处理长序列带来挑战。</p>\n<h2 id=\"14-语言模型的采样方法\"><a class=\"markdownIt-Anchor\" href=\"#14-语言模型的采样方法\">#</a> 1.4 语言模型的采样方法</h2>\n<p>  语言模型的输出为一个向量，该向量的每一维代表着词典中对应词的概率。当前，两类主流的解码方法可以总结为 (1). 概率最大化方法；(2). 随机采样方法。</p>\n<h3 id=\"141-概率最大化方法\"><a class=\"markdownIt-Anchor\" href=\"#141-概率最大化方法\">#</a> 1.4.1 概率最大化方法</h3>\n<p>  设词典大小为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>D</mi></mrow><annotation encoding=\"application/x-tex\">D</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span></span></span></span>，输入文本为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo fence=\"true\">{</mo><msub><mi>ω</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>ω</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><msub><mi>ω</mi><mn>3</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo separator=\"true\">,</mo><msub><mi>ω</mi><mi>N</mi></msub><mo fence=\"true\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\left \\{ \\omega_1,\\omega_2,\\omega_3,...,\\omega_N \\right \\}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">{</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ω</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ω</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ω</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ω</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">}</span></span></span></span></span>，模型在<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">M</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span></span></span></span> 轮自回归后生成的文本为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo fence=\"true\">{</mo><msub><mi>ω</mi><mrow><mi>N</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator=\"true\">,</mo><msub><mi>ω</mi><mrow><mi>N</mi><mo>+</mo><mn>2</mn></mrow></msub><mo separator=\"true\">,</mo><msub><mi>ω</mi><mrow><mi>N</mi><mo>+</mo><mn>3</mn></mrow></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo separator=\"true\">,</mo><msub><mi>ω</mi><mrow><mi>N</mi><mo>+</mo><mi>M</mi></mrow></msub><mo fence=\"true\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\left \\{ \\omega_{N+1},\\omega_{N+2},\\omega_{N+3},...,\\omega_{N+M} \\right \\}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">{</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ω</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.328331em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ω</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.328331em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ω</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.328331em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">3</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ω</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.328331em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">M</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">}</span></span></span></span></span>。生成文档的出现的概率可由下式进行计算。</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mi>N</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>N</mi><mo>+</mo><mi>M</mi></mrow></msub><mo stretchy=\"false\">)</mo><mo>=</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mi>N</mi></mrow><mrow><mi>N</mi><mo>+</mo><mi>M</mi><mo>−</mo><mn>1</mn></mrow></munderover><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>w</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(w_{N+1:N+M})=\\prod_{i=N}^{N+M-1}P(w_{i+1}|w_{1:i})\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.328331em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span><span class=\"mrel mtight\">:</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">M</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:3.1226720000000006em;vertical-align:-1.294336em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.8283360000000004em;\"><span style=\"top:-1.855664em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∏</span></span></span><span style=\"top:-4.300005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">M</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.294336em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mrel mtight\">:</span><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>  基于概率最大化的解码方法旨在最大化<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mi>N</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>N</mi><mo>+</mo><mi>M</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(w_{N+1:N+M})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.328331em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span><span class=\"mrel mtight\">:</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">M</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>，以生成出可能性最高的文本。该问题的搜索空间大小为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>D</mi><mi>M</mi></msup></mrow><annotation encoding=\"application/x-tex\">D^M</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">M</span></span></span></span></span></span></span></span></span></span></span>，是 NP-Hard 问题。现有概率最大化方法通常采用启发式搜索方法。</p>\n<ul>\n<li>贪心搜索</li>\n</ul>\n<p>  <strong>贪心搜索在在每轮预测中都选择概率最大的词。贪心搜索只顾 “眼前利益”，忽略了 “远期效益”。当前概率大的词有可能导致后续的词概率都很小。贪心搜索容易陷入局部最优，难以达到全局最优解。</strong></p>\n<ul>\n<li>波束搜索（BeamSearch）</li>\n</ul>\n<p>  <strong>波束搜索在每轮预测中都先保留<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span> 个可能性最高的词</strong>。模型在结束<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">M</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span></span></span></span> 轮的推理后可以得到一个推理结果集合，从该集合中找出使<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mrow><mi>N</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>N</mi><mo>+</mo><mi>M</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(w_{N+1:N+M})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.328331em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span><span class=\"mrel mtight\">:</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">M</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 最大的预测结果。</p>\n<h3 id=\"142-随机采样方法\"><a class=\"markdownIt-Anchor\" href=\"#142-随机采样方法\">#</a> 1.4.2 随机采样方法</h3>\n<p>  概率最大的文本通常是最为常见的文本，其所生成的文本缺乏多样性。为了增加生成文本的多样性，<strong>随机采样的方法在预测时增加了随机性</strong>。在每轮预测时，其先选出一组可能性高的候选词，然后按照其概率分布进行随机采样，采样出的词作为本轮的预测结果。当前，<strong>主流的 Top-K 采样和 Top-P 采样</strong>方法分别通过指定候选词数量和划定候选词概率阈值的方法对候选词进行选择。在采样方法中加入<strong> Temperature 机制</strong>可以对候选词的概率分布进行调整。</p>\n<h2 id=\"15-语言模型的评测\"><a class=\"markdownIt-Anchor\" href=\"#15-语言模型的评测\">#</a> 1.5 语言模型的评测</h2>\n<p>  评测语言模型生成能力的方法可以分为两类。第一类方法不依赖具体任务，直接通过语言模型的输出来评测模型的生成能力，称之为内在评测（IntrinsicEvaluation）。第二类方法通过某些具体任务，如机器翻译、摘要生成等，来评测语言模型处理这些具体生成任务的能力，称之为外在评测（ExtrinsicEvaluation）。</p>\n<h3 id=\"151-内在评测\"><a class=\"markdownIt-Anchor\" href=\"#151-内在评测\">#</a> 1.5.1 内在评测</h3>\n<p>  在内在评测中，测试文本通常由与预训练中所用的文本独立同分布的文本构成，<strong>不依赖于具体任务</strong>。最为常用的内部评测指标是<strong>困惑度</strong>（Perplexity）。其度量了语言模型对测试文本感到 “困惑” 的程度。具体内容参考<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL1pKVS1MTE1zL0ZvdW5kYXRpb25zLW9mLUxMTXMvdHJlZS9tYWlu\"> github</span>。</p>\n<h3 id=\"152-外在评测\"><a class=\"markdownIt-Anchor\" href=\"#152-外在评测\">#</a> 1.5.2 外在评测</h3>\n<p>  在外在评测中，<strong>测试文本通常包括该任务上的问题和对应的标准答案，其依赖于具体任务。</strong> 外在评测方法通常可以分为<strong>基于统计指标的评测方法和基于语言模型的评测方法两类</strong>。</p>\n<ol>\n<li>基于统计指标的评测</li>\n</ol>\n<p>  基于统计指标的方法构造统计指标来评测语言模型的输出与标准答案间的契合程度，并以此作为评测语言模型生成能力的依据。BLEU（BiLingualEvaluation Understudy）和 ROUGE（Recall-Oriented Understudy for Gisting Evaluation）是应用最为广泛的两种统计指标。其中，BLEU 是精度导向的指标，而 ROUGE 是召回导向的指标。具体内容参考<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL1pKVS1MTE1zL0ZvdW5kYXRpb25zLW9mLUxMTXMvdHJlZS9tYWlu\"> github</span>。</p>\n<ol start=\"2\">\n<li>基于语言模型的评测</li>\n</ol>\n<p>  目前基于语言模型的评测方法主要分为两类：（1）基于上下文词嵌入（Contextual Embeddings）的评测方法；（2）基于生成模型的评测方法。典型的基于上下文词嵌入的评测方法是 BERTScore [24]。典型的基于生成模型的评测方法是 G-EVAL。与 BERTScore 相比，G-EVAL 无需人类标注的参考答案。这使其可以更好的适应到缺乏人类标注的任务中。</p>\n<h1 id=\"六-检索增强生成\"><a class=\"markdownIt-Anchor\" href=\"#六-检索增强生成\">#</a> 六、检索增强生成</h1>\n<p>  由于训练数据的正确性、时效性和完备性可能存在不足，其难以完全覆盖用户的需求。同时，由于参数空间有限，大语言模型对训练数据的学习也难以达到完美。上述训练数据和参数学习上的不足将导致：大语言模型在面对某些问题时无法给出正确答案，甚至出现 “幻觉”，即生成看似合理实则逻辑混乱或违背事实的回答。</p>\n<p>  为了解决这些问题并进一步提升大语言模型的生成质量，<strong>可以将相关信息存储在外部数据库中，供大语言模型进行检索和调用。这种从外部数据库中检索出相关信息来辅助改善大语言模型生成质量的系统被称之为检索增强生成（Retrieval-AugmentedGeneration，RAG）。</strong></p>\n<h2 id=\"61-检索增强生成简介\"><a class=\"markdownIt-Anchor\" href=\"#61-检索增强生成简介\">#</a> 6.1 检索增强生成简介</h2>\n<p>  检索增强生成（RAG）旨在通过<strong>检索和整合外部知识</strong>来增强大语言模型生成文本的准确性和丰富性，其是一个集成了<strong>外部知识库、信息检索器、大语言模型</strong>等多个功能模块的系统。RAG 利用信息检索、深度学习等多种技术为大语言模型在生成过程中引入最新的、特定领域的知识，从而克服传统大语言模型的局限性，提供更加精准和可靠的生成内容。</p>\n<h3 id=\"611-检索增强生成的组成\"><a class=\"markdownIt-Anchor\" href=\"#611-检索增强生成的组成\">#</a> 6.1.1 检索增强生成的组成</h3>\n<p>  RAG 通常集成了外部知识库（Corpus）、信息检索器（Retriever）、生成器（Generator，即大语言模型）等多个功能模块。其基本架构如下图所示。</p>\n<p><img data-src=\"/images/AI/LLM_base/6.1.png\" alt=\"\"></p>\n<p>  具体而言，给定一个自然语言问题（Query），检索器将问题进行编码，并从知识库（如维基百科）中高效检索出与问题相关的文档。然后，将检索到的知识和原始问题一并传递给大语言模型，大语言模型根据检索到的知识和原始问题生成最终的输出。</p>\n<p>  RAG 的核心优势在于不需要对大语言模型的内部知识进行更新（即不需要重新训练），便可改善大语言模型的幻觉现象，提高生成质量。这可以有效避免内部知识更新带来的计算成本和对旧知识的灾难性遗忘（Catastrophic Forgetting）。</p>\n<h2 id=\"62-检索增强生成架构\"><a class=\"markdownIt-Anchor\" href=\"#62-检索增强生成架构\">#</a> 6.2 检索增强生成架构</h2>\n<h3 id=\"621-rag架构分类\"><a class=\"markdownIt-Anchor\" href=\"#621-rag架构分类\">#</a> 6.2.1 RAG 架构分类</h3>\n<p>  针对不同的业务场景，RAG 中的生成器可以选用不同的大语言模型，考虑到大语言模型的开源 / 闭源、微调成本等问题，RAG 中的大语言模型可以是参数不可感知 / 调节的 “黑盒” 模型，也可以是参数可感知和微调的 “白盒” 模型。从是否对大语言模型进行微调的角度出发，本小节将 RAG 架构分类两大类：<strong>黑盒增强架构</strong>和<strong>白盒增强架构</strong>。</p>\n<p><img data-src=\"/images/AI/LLM_base/6.2.png\" alt=\"\"></p>\n<p>  黑盒增强架构可根据是否对检索器进行微调分为两类：<strong>无微调</strong>、<strong>检索器微调</strong>。白盒增强架构也可根据是否对检索器进行微调分为两类：<strong>仅微调大语言模型</strong>、<strong>检索器与大语言模型协同微调</strong>。</p>\n<h3 id=\"622-黑盒增强架构\"><a class=\"markdownIt-Anchor\" href=\"#622-黑盒增强架构\">#</a> 6.2.2 黑盒增强架构</h3>\n<ol>\n<li>无微调</li>\n</ol>\n<p>  无微调架构是所有 RAG 架构中形式最简单的。该架构中，<strong>检索器和语言模型经过分别独立的预训练后参数不再更新</strong>，直接组合使用。In-Context RALM 是该框架下的代表性方法。</p>\n<p><img data-src=\"/images/AI/LLM_base/6.3.png\" alt=\"\"></p>\n<ol start=\"2\">\n<li>检索器微调</li>\n</ol>\n<p>  虽然无微调架构在实现和部署上非常便捷，但它完全没有考虑检索器与语言模型之间潜在的协同效应，效果有待提升。为了进一步提升效果，可以采用检索器微调架构对检索器进行微调，以更好地适用于黑盒增强的环境。在检索器微调架构中，<strong>大语言模型的参数保持不变，仅用其输出指导检索器的微调</strong>。REPLUG LSR 是检索器微调框架的代表性方法。其微调检索器的过程中采用<strong> KL 散度损失函数来训练检索器</strong>，目的是对齐检索到的文档的相关性分布与这些文档对语言模型性能提升的贡献分布。</p>\n<p><img data-src=\"/images/AI/LLM_base/6.4.png\" alt=\"\"></p>\n<h3 id=\"623-白盒增强架构\"><a class=\"markdownIt-Anchor\" href=\"#623-白盒增强架构\">#</a> 6.2.3 白盒增强架构</h3>\n<ol>\n<li>仅微调语言模型</li>\n</ol>\n<p>  仅微调语言模型指的是<strong>检索器作为一个预先训练好的组件其参数保持不变，大语言模型根据检索器提供的上下文信息，对自身参数进行微调</strong>。RETRO 是仅<br>\n微调语言模型的代表性方法之一。</p>\n<p><img data-src=\"/images/AI/LLM_base/6.5.png\" alt=\"\"></p>\n<ol start=\"2\">\n<li>检索器和语言模型协同微调</li>\n</ol>\n<p>  在检索器和语言模型协同微调的架构中，<strong>检索器和语言模型的参数更新同步进行</strong>。这种微调的方式使得检索器能够在检索的同时学习如何更有效地支持语言模型的需求，而语言模型则可以更好地适应并利用检索到的信息，以进一步提升 RAG 的性能。</p>\n<p>  Atlas 是该架构的代表性工作，其架构如下图所示。与 REPLUGLSR 类<br>\n似，其在预训练和微调阶段使用<strong> KL 散度损失函数</strong>来联合训练检索器和语言模型，<br>\n以确保检索器输出的文档相关性分布与文档对语言模型的贡献分布相一致。不同<br>\n之处在于，Atlas 在预训练和微调过程中，<strong>检索器和语言模型参数同步被更新</strong>，检<br>\n索器学习向语言模型提供最相关的文档，而语言模型则学习如何利用这些文档来<br>\n改善其对查询的响应。为了确保检索结果与模型最新状态保持同步，Atlas 同样需<br>\n要定期更新语料库文档的向量编码，从而维持检索的准确性。</p>\n<p><img data-src=\"/images/AI/LLM_base/6.6.png\" alt=\"\"></p>\n<h3 id=\"624-对比与分析\"><a class=\"markdownIt-Anchor\" href=\"#624-对比与分析\">#</a> 6.2.4 对比与分析</h3>\n<p><img data-src=\"/images/AI/LLM_base/6.7.png\" alt=\"\"></p>\n<h2 id=\"63-知识检索\"><a class=\"markdownIt-Anchor\" href=\"#63-知识检索\">#</a> 6.3 知识检索</h2>\n<p>  在 RAG 中，检索的效果（召回率、精度、多样性等）会直接影响大语言模型的生成质量。此外，检索的时间也是 RAG 总耗时的关键部分，因此检索的效率将影响用户的使用体验。<strong>优化检索过程，提升检索的效果和效率</strong>，对改善 RAG 的性能具有重要意义。</p>\n<h3 id=\"631-知识库构建\"><a class=\"markdownIt-Anchor\" href=\"#631-知识库构建\">#</a> 6.3.1 知识库构建</h3>\n<p>在 RAG 框架中，知识库构建主要涉及<strong>数据采集及预处理</strong>与<strong>知识库增强</strong>两个步骤。</p>\n<ol>\n<li>数据采集及预处理</li>\n</ol>\n<p>  在构建文本型知识库的数据采集过程中，来自不同渠道的数据被整合、转换为统一的文档对象。这些文档对象不仅包含<strong>原始的文本信息</strong>，还携带有关文档的<strong>元信息</strong>（Metadata），例如文章标题，分类信息，时间信息，关键词等。元信息可以用于后续的检索和过滤。</p>\n<p>  在采集到相应的数据后，还需通过数据预处理来提升数据质量和可用性。在构建文本型知识库时，数据预处理主要包括<strong>数据清洗</strong>和<strong>文本分块</strong>两个过程。</p>\n<p>  文本分块的效果直接影响后续检索结果的质量。制定合适的分块策略至关重要，包括确定切分方法（如按句子或段落切分）、设定块大小，以及是否允许块之间有重叠。文本分块的具体实施流程通常开始于<strong>将长文本拆解为较小的语义单元，如句子或段落</strong>。随后，<strong>这些单元被逐步组合成更大的块，直到达到预设的块大小</strong>，构建出独立的文本片段。为了保持语义连贯性，<strong>通常还会在相邻的文本片段之间设置一定的重叠区域</strong>。</p>\n<ol start=\"2\">\n<li>知识库增强</li>\n</ol>\n<p>  知识库增强是通过改进和丰富知识库的内容和结构，以提升其质量和实用性。这一过程通常涉及<strong>查询生成</strong>与<strong>标题生成</strong>等多个步骤，以此为文档建立语义 “锚点”，方便检索时准确定位到相应文本。</p>\n<p>  <strong>查询生成</strong>指的是利用大语言模型生成与文档内容紧密相关的<strong>伪查询</strong>。这些伪查询从查询的角度来表达文档的语义，可以<strong>作为相关文档的 “键”，供检索时与用户查询进行匹配</strong>。</p>\n<p>  <strong>标题生成</strong>指的是利用大语言模型为没有标题的文档<strong>生成合适的标题</strong>。这些生成的标题提供了文档的关键词和上下文信息，能来用来<strong>帮助快速理解文档内容</strong>，并在检索时更准确地定位到与用户提问相关的信息。对于那些原始文档中缺乏标题的情况，<strong>通过语言模型生成标题</strong>显得尤为重要。</p>\n<h3 id=\"632-查询增强\"><a class=\"markdownIt-Anchor\" href=\"#632-查询增强\">#</a> 6.3.2 查询增强</h3>\n<p>  知识库涵盖的知识表达形式是有限的，但用户的提问方式却是千人千面的。这可能导致用户查询和知识库之间不能很好匹配，从而降低检索效果。为了解决此问题，可以<strong>对用户查询的语义和内容进行扩展，即查询增强</strong>，以更好的匹配知识库中的文本。</p>\n<ol>\n<li>查询语义增强</li>\n</ol>\n<p>  查询语义增强旨在<strong>通过同义改写和多视角分解等方法来扩展、丰富用户查询的语义</strong>，以提高检索的准确性和全面性。</p>\n<ul>\n<li>(1) 同义改写</li>\n</ul>\n<p>  同义改写通过<strong>将原始查询改写成相同语义下不同的表达方式</strong>，来解决用户查<br>\n询单一的表达形式可能无法全面覆盖到知识库中多样化表达的知识。<strong>改写工作可以调用大语言模型完成</strong>。</p>\n<ul>\n<li>(2) 多视角分解</li>\n</ul>\n<p>  多视角分解采用分而治之的方法来处理复杂查询，<strong>将复杂查询分解为来自不同视角的子查询</strong>，以检索到查询相关的不同角度的信息。</p>\n<ol start=\"2\">\n<li>查询内容增强</li>\n</ol>\n<p>  查询内容增强旨在通过<strong>生成与原始查询相关的背景信息和上下文</strong>，从而丰富查询内容，提高检索的准确性和全面性。<strong>生成背景文档</strong>是一种查询内容增强的方法。它指的是在原始查询的基础上，<strong>利用大语言模型生成与查询内容相关的背景文档</strong>。</p>\n<h3 id=\"633-检索器\"><a class=\"markdownIt-Anchor\" href=\"#633-检索器\">#</a> 6.3.3 检索器</h3>\n<p>  给定知识库和用户查询，检索器旨在找到知识库中与用户查询相关的知识文本。检索器可分为<strong>判别式检索器</strong>和<strong>生成式检索器</strong>两类。</p>\n<ol>\n<li>判别式检索器</li>\n</ol>\n<p>  判别式检索器<strong>通过判别模型对查询和文档是否相关进行打分</strong>。判别式检索器通常分为两大类：<strong>稀疏检索器</strong>和<strong>稠密检索器</strong>。稀疏检索器利用离散的、基于词频的文档编码向量进行检索，而稠密检索器则利用神经网络生成的连续的、稠密向量对文档进行检索。</p>\n<ul>\n<li>(1) 稀疏检索器</li>\n</ul>\n<p>  稀疏检索器（SparseRetriever）是指使用<strong>稀疏表示方法</strong>来匹配文本的模型。这类检索器通过统计文档中特定词项出现的统计特征来对文档进行编码，然后基于此编码计算查询与知识库中的文档的相似度来进行检索。典型的稀疏检索技术包括 TF-IDF 和 BM25 等，它们通过分析词项的分布和频率来评估文档与查询的相关性。</p>\n<p>  TF-IDF 基于词频（TF）和逆文档频率（IDF）来<strong>衡量词语在文档或语料库中的重要性</strong>，然后用此重要性对文本进行编码。词频（TF）表示词语在文档中的出现频率，计算公式为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mrow><mi mathvariant=\"normal\">t</mi><mi mathvariant=\"normal\">f</mi></mrow><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>j</mi></mrow></msub><mo>=</mo><mfrac><msub><mi>n</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>j</mi></mrow></msub><mrow><munder><mo>∑</mo><mi>k</mi></munder><msub><mi>n</mi><mrow><mi>k</mi><mo separator=\"true\">,</mo><mi>j</mi></mrow></msub></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\mathrm{tf}_{i,j}=\\frac{n_{i,j}}{\\sum_{k}n_{k,j}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathrm\">t</span><span class=\"mord mathrm\" style=\"margin-right:0.07778em;\">f</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.09327em;vertical-align:-0.9857100000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1075599999999999em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1863979999999999em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9857100000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>  逆文档频率（IDF）衡量词语的普遍性，计算公式为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mrow><mi mathvariant=\"normal\">i</mi><mi mathvariant=\"normal\">d</mi><mi mathvariant=\"normal\">f</mi></mrow><mi>i</mi></msub><mo>=</mo><mi>log</mi><mo>⁡</mo><mfrac><mrow><mi mathvariant=\"normal\">∣</mi><mi>D</mi><mi mathvariant=\"normal\">∣</mi></mrow><mrow><mi mathvariant=\"normal\">∣</mi><mo stretchy=\"false\">{</mo><mi>j</mi><mo>:</mo><msub><mi>t</mi><mi>i</mi></msub><mo>∈</mo><msub><mi>d</mi><mi>j</mi></msub><mo stretchy=\"false\">}</mo><mi mathvariant=\"normal\">∣</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\mathrm{idf}_i=\\log\\frac{|D|}{|\\{j:t_i\\in d_j\\}|}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathrm\">i</span><span class=\"mord mathrm\">d</span><span class=\"mord mathrm\" style=\"margin-right:0.07778em;\">f</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.399108em;vertical-align:-0.972108em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"mopen\">{</span><span class=\"mord mathnormal\" style=\"margin-right:0.05724em;\">j</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">t</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">}</span><span class=\"mord\">∣</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"mord\">∣</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.972108em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>  最终，TF-IDF 值为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mrow><mi mathvariant=\"normal\">t</mi><mi mathvariant=\"normal\">f</mi><mi mathvariant=\"normal\">i</mi><mi mathvariant=\"normal\">d</mi><mi mathvariant=\"normal\">f</mi></mrow><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>j</mi></mrow></msub><mo>=</mo><msub><mrow><mi mathvariant=\"normal\">t</mi><mi mathvariant=\"normal\">f</mi></mrow><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>j</mi></mrow></msub><mo>×</mo><msub><mrow><mi mathvariant=\"normal\">i</mi><mi mathvariant=\"normal\">d</mi><mi mathvariant=\"normal\">f</mi></mrow><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\mathrm{tfidf}_{i,j}=\\mathrm{tf}_{i,j}\\times\\mathrm{idf}_i\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathrm\">t</span><span class=\"mord mathrm\" style=\"margin-right:0.07778em;\">f</span><span class=\"mord mathrm\">i</span><span class=\"mord mathrm\">d</span><span class=\"mord mathrm\" style=\"margin-right:0.07778em;\">f</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathrm\">t</span><span class=\"mord mathrm\" style=\"margin-right:0.07778em;\">f</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathrm\">i</span><span class=\"mord mathrm\">d</span><span class=\"mord mathrm\" style=\"margin-right:0.07778em;\">f</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p>  TF-IDF 通过高词频和低文档频率产生高权重，倾向于过滤常见词语，保留重要词语。BM25 是一种改进的文本检索算法，它在 TF-IDF 基础上通过文档长度归一化和词项饱和度调整，更精确地评估词项重要性，优化了词频和逆文档频率的计算，并考虑了文档长度对评分的影响。虽然不涉及词项上下文，但是 BM25 在处理大规模数据时表现优异，广泛应用于搜索引擎和信息检索系统。</p>\n<ul>\n<li>(2) 稠密检索器</li>\n</ul>\n<p>  稠密检索器一般<strong>利用预训练语言模型对文本生成低维、密集的向量表示</strong>，通<br>\n过计算向量间的相似度进行检索。按照所使用的模型结构的不同，稠密检索器大<br>\n致可以分为两类：<strong>交叉编码类</strong>（Cross-Encoder）、<strong>双编码器类</strong>（Bi-Encoder）</p>\n<p><img data-src=\"/images/AI/LLM_base/6.8.png\" alt=\"\"></p>\n<p>  交叉编码类 “<strong>端到端</strong>” 的给出查询和文档的相似度。<strong>这类模型将查询和文档拼接在一起，随后利用预训练语言模型作为编码器（例如 BERT）生成一个向量表示。接着，通过一个分类器处理这个向量，最终输出一个介于 0 和 1 之间的数值，表示输入的查询和文档之间的相似程度</strong>。其优点在于模型结构简单，能够实现查询和文档之间的深度交互。然而，由于<strong>交叉编码类模型需要进行高复杂度的交叉注意力操作，计算量大，因此不适合在大规模检索阶段使用</strong>。这种模型更适用于对少量候选文档进行更精确排序的阶段，可以显著提升检索结果的相关性。</p>\n<p>  双编码类模型采用了一种 “两步走” 的策略。第一步，查询和文档首先各自通过独立的编码器生成各自的向量表示；第二步，对这两个向量之间的相似度进行计算，以评估它们的相关性。这种方法的优势在于，它<strong>允许预先离线计算并存储所有文档的向量表示，在线检索时则可直接进行向量匹配</strong>。因此，双编码器非常适合在工业环境中部署，具有极高的匹配效率。然而，在这种分离的处理方式中，查询与文档在提取特征向量时缺乏交互。这可能会对匹配的精确度产生影响。为了缓解查询与文档在提取特征向量时缺乏交互的问题，可以在双编码器的基础上引入查询与文档的交互，通过<strong>对比学习</strong>对双编码器进行微调，以<strong>使双编码器编码的特征向量可以兼顾查询和文档</strong>，以进一步提升双编码器的效果。</p>\n<ol start=\"2\">\n<li>生成式检索器</li>\n</ol>\n<p>  <strong>生成式检索器通过生成模型对输入查询直接生成相关文档的标识符</strong>。生成式检索器通常采用基于 Encoder-Decoder 架构的生成模型，如 T5、BART 等。生成式检索器的训练过程通常分为两个阶段。在第一阶段，模型通过序列到序列的学习方法，<strong>学习如何将查询映射到相关的文档标识符</strong>。这一阶段主要通过最大似然估计（MLE）来优化模型，确保生成的文档标识符尽可能准确。在第二阶段，<strong>通过数据增强和排名优化进一步提高检索效率和准确性</strong>。数据增强主要通过生成伪查询或使用文档片段作为查询输入，以增加训练数据的多样性和覆盖面。排名优化则涉及使用特定的损失函数，如对比损失或排名损失，来调整模型生成文档标识符的顺序和相关性，从而更好地匹配查询的需求</p>\n<p>  在生成式检索器中，<strong>DocID 的设计至关重要。其需要在语义信息的丰富性与标识符的简洁性之间取得平衡</strong>。常用的 DocID 形式分为两类：基于数字的 DocID 和基于词的 DocID。基于数字的 DocID 方法使用唯一的数字值或整数字符串来表示文档，虽然构建简单，但在处理大量文档时可能导致标识符数量激增，增加计算和存储负担。相比之下，基于词的 DocID 方法直接从文档的标题、URL 或 N-gram 中提取表示，能更自然地传达文档的语义信息。通常，标题是最佳选择，因为它提供了文档的宏观概述。但在缺乏高质量标题时，URL 或 N-gram 也可作为有效的替代方案。</p>\n<p>  尽管生成式检索器在性能上取得了一定的进步，但与稠密检索器相比，其效果仍稍逊一筹。此外，生成式检索器还面临着一系列挑战，包括如何突破模型输入长度的限制、如何有效处理大规模文档以及动态新增文档的表示学习等，这些都是亟待解决的问题。</p>\n<h3 id=\"634-检索效率增强\"><a class=\"markdownIt-Anchor\" href=\"#634-检索效率增强\">#</a> 6.3.4 检索效率增强</h3>\n<p>  知识库中通常包含海量的文本，对知识库中文本进行逐一检索缓慢而低效。为提升检索效率，可以引入<strong>向量数据库</strong>来实现检索中的高效向量存储和查询。向量数据库的核心是设计高效的相似度索引算法。</p>\n<ol>\n<li>相似度索引算法</li>\n</ol>\n<p>  在向量检索中，常用的索引技术主要分成三大类：<strong>基于空间划分的方法</strong>、<strong>基于量化方法</strong>和<strong>基于图的方法</strong>。</p>\n<p>  <strong>基于空间划分的方法</strong>将搜索空间划分为多个区域来实现索引，主要包括<strong>基于树的索引方法</strong>和<strong>基于哈希的方法</strong>两类。其中，基于树的索引方法通过一系列规则递归地划分空间，形成一种树状结构，每个叶节点代表一个较小区域，区域内的数据点彼此接近。在查询时，<strong>算法从树的根节点出发，逐步深入到合适的叶节点，最后在叶节点内部进行数据点的相似度比较，以找到最近的向量</strong>。常见的基于树的索引包括 KD 树 [4] 和 Ball 树 [13] 等。而基于哈希的方法（如局部敏感哈希（LSH）[11]）<strong>通过哈希函数将向量映射到哈希表的不同桶中，使得相似向量通常位于同一桶内</strong>。</p>\n<p>  <strong>基于图的方法</strong>通过构建一个邻近图，将向量检索转化为图的遍历问题。这类方法在索引构建阶段，将数据集中的每个向量表示为图中的一个节点，并根据向量间的距离或相似性建立边的连接。不同的图索引结构主要体现在其独特的赋边策略上。索引构建的核心思想源于小世界网络模型，旨在创建一个结构，使得从任意入口点出发，能在较少步数内到达查询点的最近邻。这种结构允许在搜索时使用贪婪算法，逐步逼近目标。然而，图索引设计面临稀疏性和稠密性的权衡：较稀疏的图结构每步计算代价低，而较稠密的图则可能缩短搜索路径。基于图的代表性方法有 NSW [32]、IPNSW [37] 和 HNSW [31] 等。</p>\n<p>  <strong>基于乘积量化的方法</strong>通过将高维向量空间划分为多个子空间，并在每个子空间中进行聚类得到码本和码字，以此作为构建索引的基础 [18]。这类方法主要包括训练和查询两个阶段。在训练阶段，该方法学习如何将高维向量最优地量化为码字 ID 序列。通常这个过程涉及将原始空间划分为多个子空间，在每个子空间内进行聚类，并通过聚类中心得到码字和码本。每个子空间内的聚类中心点即为码字，所有码字的集合构成码本。每个训练样本的每个子向量可以都用相应子空间的码字来近似，这样就实现了码字 ID 序列来表示训练样本，达到了数据量化的目的。在查询阶段，系统同样将查询向量划分为子向量，并在每个子空间中找到最近的码字，得到码字 ID 序列。随后，系统计算查询向量的每个子向量到所有对应子空间的码字的距离，形成距离表。最后，系统利用这个距离表和数据库中每个向量的码字 ID 序列，快速查找并累加各个子向量的对应距离，得到查询向量与数据库向量之间的近似距离。通过对这些距离进行排序，系统最终得到最近邻结果。该方法在减少内存占用和加快距离计算速度方面表现出色，但量化过程中会不可避免地会引入一些误差。在某些需要精度更高的应用场景中，我们可以在 PQ 的基础上进一步进行精确排序，以得到精确的最近邻结果。</p>\n<ol start=\"2\">\n<li>常见软件库介绍</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>向量数据库</th>\n<th>URL</th>\n<th>GitHub Star</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>milvus</td>\n<td><span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL21pbHZ1cy1pby9taWx2dXM=\">https://github.com/milvus-io/milvus</span></td>\n<td>28.4K</td>\n</tr>\n<tr>\n<td>typesense</td>\n<td><span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL3R5cGVzZW5zZS90eXBlc2Vuc2U=\">https://github.com/typesense/typesense</span></td>\n<td>19.0K</td>\n</tr>\n<tr>\n<td>qdrant</td>\n<td><span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL3FkcmFudC9xZHJhbnQ=\">https://github.com/qdrant/qdrant</span></td>\n<td>18.9K</td>\n</tr>\n<tr>\n<td>chroma</td>\n<td><span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL2Nocm9tYS1jb3JlL2Nocm9tYQ==\">https://github.com/chroma-core/chroma</span></td>\n<td>13.7K</td>\n</tr>\n<tr>\n<td>weaviate</td>\n<td><span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL3dlYXZpYXRlL3dlYXZpYXRl\">https://github.com/weaviate/weaviate</span></td>\n<td>10.4K</td>\n</tr>\n<tr>\n<td>pinecone</td>\n<td><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cucGluZWNvbmUuaW8v\">https://www.pinecone.io/</span></td>\n<td>×</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"635-检索结果重排\"><a class=\"markdownIt-Anchor\" href=\"#635-检索结果重排\">#</a> 6.3.5 检索结果重排</h3>\n<p>  检索器可能检索到与查询相关性不高的文档。这些文档如果直接输入给大语言模型，可能会引发生成质量的下降。为此，在将其输入给大语言模型之前，<strong>还需要对其进行进一步的精选。精选的主要途径是对检索到的文档进行重新排序，简称重排</strong>，然后从中选择出排序靠前的文档。重排方法主要分为两类：<strong>基于交叉编码的方法</strong>和<strong>基于上下文学习的方法</strong>。</p>\n<ol>\n<li>\n<p>基于交叉编码的重排方法利用<strong>交叉编码器</strong>（Cross-Encoders）来评估文档与查询之间的语义相关性。</p>\n</li>\n<li>\n<p>基于上下文学习的重排方法是指<strong>通过设计精巧的 Prompt，使用大语言模型来执行重排任务</strong>。这种方法可以利用大语言模型优良的深层语义理解能力，从而取得了良好的表现。</p>\n</li>\n</ol>\n<h2 id=\"64-生成增强\"><a class=\"markdownIt-Anchor\" href=\"#64-生成增强\">#</a> 6.4 生成增强</h2>\n<p>  检索器得到相关信息后，将其传递给大语言模型以期增强模型的生成能力。利用这些信息进行生成增强是一个复杂的过程，不同的方式会显著影响 RAG 的性能。</p>\n<h3 id=\"641-何时增强\"><a class=\"markdownIt-Anchor\" href=\"#641-何时增强\">#</a> 6.4.1 何时增强</h3>\n<p>  大语言模型在训练过程中掌握了大量知识，这些知识被称为<strong>内部知识</strong>（Self Knowledge）。判断是否需要增强的核心在于<strong>判断大语言模型是否具有内部知识</strong>。判断模型是否具有内部知识的方法可以分为两类：（1）<strong>外部观测法</strong>，通过 Prompt 直接询问模型是否具备内部知识，或应用统计方法对是否具备内部知识进行估计，这种方法无需感知模型参数；（2）<strong>内部观测法</strong>，通过检测模型内部神经元的状态信息来判断模型是否存在内部知识，这种方法需要对模型参数进行侵入式的探测。</p>\n<ol>\n<li>外部观测法</li>\n</ol>\n<p>  对于大语言模型，可以通过两种问询的方式来判断大语言模型是否具备相应的内部知识：（1）<strong>Prompt 直接询问大语言模型是否含有相应的内部知识</strong>；（2）<strong>反复询问大语言模型同一个问题观察模型多次回答的一致性</strong>。此外，我们也可以通过翻看大语言模型的 “教育经历”，即<strong>通过训练数据来判断其是否具备内部知识</strong>。但是，许多大语言模型的训练数据并未公开，无法直接观测它们的训练数据。在这种情况下，可以通过<strong>设计伪训练数据统计量来拟合真实训练数据的分布</strong>，从而间接评估模型对特定知识的学习情况。</p>\n<ol start=\"2\">\n<li>内部观测法</li>\n</ol>\n<p>  由于模型的内部知识检索主要发生在中间层的前馈网络中，因此在处理包含或不包含内部知识的不同问题时，<strong>模型的中间层会展现出不同的动态变化</strong>。基于这一特性，可以训练分类器进行判别，这种方法被称为<strong>探针</strong>。</p>\n<p><img data-src=\"/images/AI/LLM_base/6.9.png\" alt=\"\"></p>\n<h3 id=\"642-何处增强\"><a class=\"markdownIt-Anchor\" href=\"#642-何处增强\">#</a> 6.4.2 何处增强</h3>\n<p>  得益于大语言模型的上下文学习能力、注意力机制的可扩展性以及自回归生成能力，其<strong>输入端、中间层和输出端都可以进行知识融合操作</strong>。在输入端，可以将问题和检索到的外部知识拼接在 Prompt 中，然后输入给大语言模型；在中间层，可以采用交叉注意力将外部知识直接编码到模型的隐藏状态中；在输出端，可以利用外部知识对生成的文本进行后矫正。</p>\n<ol>\n<li>在输入端增强。</li>\n</ol>\n<p>  在输入端增强的方法<strong>直观且易于实现</strong>。在输入端增强的方法直接将检索到的外部知识文本与用户查询拼接到 Prompt 中，然后输入给大语言模型。其是当前主流的增强方法。此方式的<strong>重点在于 Prompt 设计</strong>以及检索到的外部知识的排序。在设计 Prompt 的过程中，可以运用 CoT 等 Prompt 技巧。</p>\n<ol start=\"2\">\n<li>在中间层增强</li>\n</ol>\n<p>  在中间层增强增强的方法利用注意力机制的灵活性，先将检索到的<strong>外部知识转换为向量表示</strong>，然后将这些向量表示通过<strong>交叉注意力</strong>融合到模型的隐藏状态中。这种方法能够<strong>更深入地影响模型的内部表示</strong>，可能有助于模型更好地理解和利用外部知识。同时，由于向量表示通常比原始文本更为紧凑，这种方法可以<strong>减少对模型输入长度的依赖</strong>。然而，这种方法需要对模型的结构进行复杂的设计和调整，<strong>无法应用于黑盒模型</strong>。</p>\n<ol start=\"3\">\n<li>在输出端增强</li>\n</ol>\n<p>  在输出端增强的方法利用检索到的外部知识对大语言模型生成的文本进行<strong>校准</strong>，是一种<strong>后处理</strong>的方法。在此类方法中，模型首先在无外部知识的情况下生成一个初步回答，然后再利用检索到的外部知识来验证或校准这一答案。<strong>校验过程基于生成文本与检索文本的知识一致性对输出进行矫正</strong>。矫正可以通过将初步回答与检索到的信息提供给大模型，让大模型检查并调整生成的回答来完成。这种方法的优点是可以<strong>确保生成的文本与外部知识保持一致</strong>，提高答案的准确性和可靠性。然而，其效果在很大程度上依赖于检索到的外部知识的质量和相关性。若检索到的文档不准确或不相关，则会导致错误的校准结果。</p>\n<h3 id=\"643-多次增强\"><a class=\"markdownIt-Anchor\" href=\"#643-多次增强\">#</a> 6.4.3 多次增强</h3>\n<p>  在实际应用中，用户对大语言模型的提问可能是<strong>复杂或模糊</strong>的。复杂问题往往涉及多个知识点，需要多跳（multi-hop）的理解；而模糊问题往往指代范围不明，难以一次就理解问题的含义。对于复杂问题和模糊问题，难以通过一次检索增强就确保生成正确，多次迭代检索增强在所难免。处理复杂问题时，常采用<strong>分解式增强</strong>的方案。该方案将复杂问题分解为多个子问题，子问题间进行迭代检索增强，最终得到正确答案。处理模糊问题时，常采用<strong>渐进式增强</strong>的方案。该方案将问题的不断细化，然后分别对细化的问题进行检索增强，力求给出全面的答案，以覆盖用户需要的答案。</p>\n<ol>\n<li>分解式增强</li>\n</ol>\n<p>  复杂问题通常包含多个知识点。对复杂问题进行作答，需要多跳理解。因此，在复杂问题的检索增强中，我们通常无法仅通过一次检索增强就得到满意的答案。在这种情况下，模型可以将多跳问题分解为一个个子问题，然后在子问题间迭代地进行检索增强，最后得出正确结论，即分解式增强。</p>\n<p>  <strong>DEMONSTRATE–SEARCH–PREDICT（DSP）</strong> 是一种具有代表性的分解式增强框架。该框架主要包含以下三个模块：（1）<strong>DEMONSTRATE 模块</strong>，通过上下文学习的方法，将复杂问题分解为子问题；（2）<strong>SEARCH 模块</strong>，对子问题进行迭代检索增强，为最终决策提供综合的外部知识；（3）<strong>PREDICT 模块</strong>，根据 SEARCH 提供的综合外部知识生成最终回答。</p>\n<p><img data-src=\"/images/AI/LLM_base/6.10.png\" alt=\"\"></p>\n<ol start=\"2\">\n<li>渐进式增强</li>\n</ol>\n<p>  在模糊问题中，问题主体通常指代不明，容易引发歧义。在处理模糊问题时，可以对问题进行渐进式地拆解、细化，然后对细化后的问题进行检索，利用检索到的信息增强大模型。这种渐进式的增强方法可以帮助大语言模型掌握更全面的信息。</p>\n<p>  <strong>TREEOFCLARIFICATIONS（TOC）</strong> 是渐进式增强的代表性框架。该框架通过递归式检索来引导大语言模型在<strong>树状结构</strong>中探索给定模糊问题的多种澄清路径。TOC 框架首先启动第一轮检索，根据检索到的相关文档和原始问题，生成一系列具体的细化问题在此过程中，框架会根据细化问题与原问题的相关性及知识一致性进行剪枝。随后，针对每个细化问题，框架独立展开深入的检索并对问题进一步细化，最终，我们能够构建出多条完整的知识路径，每条路径的末端（叶节点）都代表了对原始问题的不同但是有效的解答。通过整合所有有效的叶节点，我们能够得出一个精确且全面的长回答</p>\n<p><img data-src=\"/images/AI/LLM_base/6.11.png\" alt=\"\"></p>\n<p>  这种渐进式的检索方法能够显著改善大语言模型对模糊问题的生成效果。然而，其需要进行多轮检索并生成多个答案路径，整个系统的计算量会随着问题复杂度呈指数级增长。此外，多轮的检索与生成不仅会带来显著的时间延迟，多个推理路径还为推理带来不稳定性，容易引发错误。</p>\n<h3 id=\"644-降本增效\"><a class=\"markdownIt-Anchor\" href=\"#644-降本增效\">#</a> 6.4.4 降本增效</h3>\n<p>  检索出的外部知识通常包含大量原始文本。将其通过 Prompt 输入给大语言模型时，会大幅度增加输入 Token 的数量，从而增加了大语言模型的推理计算成本。此问题可从<strong>去除冗余文本</strong>与<strong>复用计算结果</strong>两个角度进行解决。</p>\n<ol>\n<li>去除冗余文本</li>\n</ol>\n<p>  去除冗余文本的方法通过对检索出的原始文本的词句进行过滤，从中选择出部分有益于增强生成的部分。去除冗余文本的方法主要分为三类：<strong>Token 级别的方法</strong>，<strong>子文本级别的方法</strong>以及<strong>全文本级别的方法</strong>。</p>\n<ol start=\"2\">\n<li>复用计算结果</li>\n</ol>\n<p>  在大语言模型进行推理的自回归过程中，每个 Token 都需要用到之前 Token 注意力模块涉及的 Key 和 Value 的结果。为了避免对每个 Token 都重新计算前面的 Key 和 Value 的结果，可以将之前计算的 Key 和 Value 的结果进行缓存（即 KV-cache），在需要是直接从 KV-cache 中调用相关结果，从而避免重复计算。</p>\n<p>  综上，通过结合上述<strong>输入 Prompt 压缩</strong>与<strong> KV-cache 机制</strong>，RAG 框架可以在保持高性能的同时，显著提升其效率。这不仅有助于在资源受限的环境中部署模型，还可以提高模型在实际应用中的响应速度。</p>\n<h2 id=\"65-实践与应用\"><a class=\"markdownIt-Anchor\" href=\"#65-实践与应用\">#</a> 6.5 实践与应用</h2>\n<h3 id=\"651-搭建简单rag系统\"><a class=\"markdownIt-Anchor\" href=\"#651-搭建简单rag系统\">#</a> 6.5.1 搭建简单 RAG 系统</h3>\n<p>  为了助力开发者们高效且便捷地构建 RAG 系统，当前已有诸多成熟开源框架可供选择，其中最具代表性的便是<strong> LangChain</strong> 与<strong> LlamaIndex</strong>。</p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2025/01/02/AI/MinHash/",
            "url": "http://qianqiu-cell.github.io/2025/01/02/AI/MinHash/",
            "title": "使用 MinHash 进行文本去重",
            "date_published": "2025-01-01T16:00:00.000Z",
            "content_html": "<h1 id=\"一-minhash\"><a class=\"markdownIt-Anchor\" href=\"#一-minhash\">#</a> 一、MinHash</h1>\n<p>MinHash 是一种<strong>用于近似集合相似度计算的技术</strong>。它被广泛用于大规模数据集中的快速相似度估计，特别是在处理文本、图像和网络数据等领域。</p>\n<p>MinHash 的基本思想是通过将集合中的元素哈希成一个较小的签名（通常是一个固定长度的整数或比特串），从而<strong>快速地比较两个集合之间的相似度</strong>。</p>\n<p>MinHash 算法的主要步骤如下：</p>\n<ul>\n<li>集合转换成签名：对于一个集合中的元素，通过哈希函数将其映射到一个固定长度的哈希值。通常会使用多个哈希函数生成多个哈希值，这样就得到了一个签名。</li>\n<li>选择最小值：从生成的哈希值中选取最小的一个作为该集合的 MinHash 值。</li>\n<li>重复以上步骤：对于每个集合，重复以上两个步骤，得到所有元素的 MinHash 值。</li>\n</ul>\n<p>MinHash 的关键优势在于它可以<strong>以很小的内存占用和低计算成本来估计集合之间的相似度</strong>。这对于处理大规模数据集是非常重要的。</p>\n<p>需要注意的是，MinHash 是一种概率性算法，它提供的相似度估计是以一定的概率为基础的。因此，在应用中需要根据具体情况进行适当的参数设置和结果解释。</p>\n<h1 id=\"二-lsh\"><a class=\"markdownIt-Anchor\" href=\"#二-lsh\">#</a> 二、LSH</h1>\n<p>局部敏感哈希（Locality-Sensitive Hashing，LSH）是一种用于<strong>在高维空间中快速搜索相似项的近似搜索技术</strong>。它特别适用于处理<strong>大规模数据集</strong>，其中传统的精确搜索方法可能变得过于昂贵或不可行。</p>\n<p>LSH 的主要思想是将相似的项映射到相同的桶（buckets）中，从而可以在相似的项之间进行快速的搜索。它通过在数据集中构建哈希表来实现这一目的。</p>\n<p>以下是 LSH 的一般工作流程：</p>\n<ul>\n<li>特征提取：将数据点表示为特征向量，这些特征可以是任意类型的，例如文本、图像或数值数据。</li>\n<li>哈希函数选择：选择一组哈希函数，这些函数将特征向量映射到哈希空间。这些哈希函数通常被设计为局部敏感的，也就是说，相似的项在哈希空间中有更高的概率被映射到相同的桶中。</li>\n<li>桶的构建：将所有数据点通过哈希函数映射到桶中。</li>\n<li>查询：给定一个查询项，将其通过相同的哈希函数映射到哈希空间，并查找相同桶中的项，以找到近似的邻居。</li>\n<li>候选项筛选：对于返回的相邻项集，通过进一步的计算或筛选来确定最终的相似项。</li>\n</ul>\n<p>常见的 LSH 变体包括：</p>\n<ul>\n<li>MinHash LSH * 用于处理集合数据的 LSH 变体，通过将集合映射到 MinHash 签名来进行相似度搜索。</li>\n<li>LSH Forest * 用于高维空间中的范围搜索，可以有效地处理最近邻搜索。</li>\n<li>SimHash LSH * 用于处理高维二进制数据的 LSH 变体，通过将特征向量映射到二进制码并进行哈希操作。</li>\n<li>Cosine LSH * 用于处理余弦相似度的 LSH 变体，通常用于文本或向量空间模型中的相似性搜索。</li>\n</ul>\n<p>LSH 是一种强大的技术，可以用于许多领域，包括信息检索、推荐系统、图像和音频处理等。它提供了一种有效的方法来解决大规模数据集中的相似性搜索问题。</p>\n<h1 id=\"三-jaccard相似度\"><a class=\"markdownIt-Anchor\" href=\"#三-jaccard相似度\">#</a> 三、Jaccard 相似度</h1>\n<p>给定两个集合 A,B，Jaccard 系数定义为 A 与 B 交集的大小与 A 与 B 并集的大小的比值，定义如下：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>Jaccard</mtext><mo stretchy=\"false\">(</mo><mi>A</mi><mo separator=\"true\">,</mo><mi>B</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mi>A</mi><mo>∩</mo><mi>B</mi></mrow><mrow><mi>A</mi><mo>∪</mo><mi>B</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\text{Jaccard}(A,B)=\\frac{A\\cap B}{A\\cup B}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">Jaccard</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">A</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.04633em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.36033em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">A</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∪</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">A</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∩</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>Jaccard 相似度在如下问题取得较好效果：<strong>在大的语料库中寻找文本内容相似的文档，这里主要指字面上的相似，而非语义上的相似</strong>。</p>\n<h1 id=\"四-参考程序\"><a class=\"markdownIt-Anchor\" href=\"#四-参考程序\">#</a> 四、参考程序</h1>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">from</span> datasketch <span class=\"token keyword\">import</span> MinHash<span class=\"token punctuation\">,</span> MinHashLSH</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\"># 创建一个 MinHash 对象</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">create_minhash</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    minhash <span class=\"token operator\">=</span> MinHash<span class=\"token punctuation\">(</span>num_perm<span class=\"token operator\">=</span><span class=\"token number\">128</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># num_perm 是哈希函数的数量，可以根据需要调整</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">for</span> d <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>        minhash<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span>d<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span><span class=\"token string\">'utf8'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token keyword\">return</span> minhash</pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token comment\"># 创建一些示例数据（中文长句子）</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>sentences <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    <span class=\"token string\">\"今天天气很好，阳光明媚，适合出门散步。\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    <span class=\"token string\">\"我喜欢读书，尤其是科幻小说。\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    <span class=\"token string\">\"这个城市的夜景非常漂亮，尤其是灯光璀璨的CBD区。\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    <span class=\"token string\">\"我的家乡是一个美丽的小镇，四季分明，景色宜人。\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    <span class=\"token string\">\"学习新知识让我感到充实和快乐。\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    <span class=\"token string\">\"我喜欢健身，每天都会去健身房锻炼。\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    <span class=\"token string\">\"这家餐厅的菜品非常美味，尤其是他们的特色菜。\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>    <span class=\"token string\">\"我喜欢旅行，尤其喜欢去一些自然风光优美的地方。\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    <span class=\"token string\">\"听音乐是我放松心情的最爱之一。\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>    <span class=\"token string\">\"看电影是我周末最喜欢做的事情之一，我喜欢各种类型的电影。\"</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre></pre></td></tr><tr><td data-num=\"22\"></td><td><pre><span class=\"token comment\"># 创建 MinHash 对象并插入到 LSH 中</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>lsh <span class=\"token operator\">=</span> MinHashLSH<span class=\"token punctuation\">(</span>threshold<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> num_perm<span class=\"token operator\">=</span><span class=\"token number\">128</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># threshold 是相似度阈值，可以根据需要调整</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre></pre></td></tr><tr><td data-num=\"25\"></td><td><pre><span class=\"token keyword\">for</span> idx<span class=\"token punctuation\">,</span> sentence <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>sentences<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>    minhash <span class=\"token operator\">=</span> create_minhash<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>sentence<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>    lsh<span class=\"token punctuation\">.</span>insert<span class=\"token punctuation\">(</span>idx<span class=\"token punctuation\">,</span> minhash<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre><span class=\"token comment\"># 查找相似的集合</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>query_minhash <span class=\"token operator\">=</span> create_minhash<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token string\">'听音乐是我放松心情的最爱'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>results <span class=\"token operator\">=</span> lsh<span class=\"token punctuation\">.</span>query<span class=\"token punctuation\">(</span>query_minhash<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre><span class=\"token comment\"># 输出相似度分数</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre><span class=\"token keyword\">for</span> result <span class=\"token keyword\">in</span> results<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>    minhash <span class=\"token operator\">=</span> create_minhash<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>sentences<span class=\"token punctuation\">[</span>result<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>    jaccard_similarity <span class=\"token operator\">=</span> query_minhash<span class=\"token punctuation\">.</span>jaccard<span class=\"token punctuation\">(</span>minhash<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"与 sentence 相似的句子 </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>result<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\"> 的相似度分数为: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>jaccard_similarity<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre><span class=\"token comment\"># output</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>与 sentence 相似的句子 <span class=\"token number\">8</span> 的相似度分数为<span class=\"token punctuation\">:</span> <span class=\"token number\">0.8046875</span></pre></td></tr></table></figure>",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2025/01/02/AI/N-gram/",
            "url": "http://qianqiu-cell.github.io/2025/01/02/AI/N-gram/",
            "title": "N-gram 模型",
            "date_published": "2025-01-01T16:00:00.000Z",
            "content_html": "<h1 id=\"一-引言\"><a class=\"markdownIt-Anchor\" href=\"#一-引言\">#</a> 一、引言</h1>\n<p>  n-gram 算法通过统计文本中连续 n 个词的序列（或称为 “词组”）出现的频率，为各种 NLP 任务提供了有力的支持。</p>\n<p>  N-gram 模型的基本原理是基于马尔可夫假设，在训练 N-gram 模型时使用最大似然估计模型参数 —— 条件概率.</p>\n<h1 id=\"二-示例\"><a class=\"markdownIt-Anchor\" href=\"#二-示例\">#</a> 二、示例</h1>\n<p>  例如，对于 “The cow jumps over the moon” 这句话。如果 N=2（称为二元模型），那么 ngram 将为：</p>\n<pre><code>the cow\ncow jumps\njumps over\nover the\nthe moon\n</code></pre>\n<p>  在这种情况下有 5 个 n 元语法。请注意，从  <code>the-&gt;cow</code>  转移到  <code>cow-&gt;jumps</code>  到  <code>Jumps-&gt;over</code>  等，本质上是向前移动一个单词以生成下一个二元组。</p>\n<p>  如果 N=3，则 n 元语法将为：</p>\n<pre><code>the cow jumps\ncow jumps over\njumps over the\nover the moon\n</code></pre>\n<p>  在这种情况下有 4 个 n 元语法。当 N=1 时，被称为一元语法，本质上是句子中的各个单词。当 N=2 时，称为二元组；当 N=3 时，称为三元组。当 N&gt;3 时，这通常被称为多元组等等。</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>N</mi><mrow><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi></mrow></msub><mo>=</mo><mi>X</mi><mo>−</mo><mo stretchy=\"false\">(</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">N_{gram}=X-(N-1)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal mtight\">a</span><span class=\"mord mathnormal mtight\">m</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<h1 id=\"三-n-gram-算法的优缺点\"><a class=\"markdownIt-Anchor\" href=\"#三-n-gram-算法的优缺点\">#</a> 三、n-gram 算法的优缺点</h1>\n<p>（1）优点</p>\n<ul>\n<li>简单易实现：n-gram 算法基于统计原理，实现起来相对简单直观。</li>\n<li>通用性强：n-gram 算法可以应用于多种 NLP 任务，具有广泛的适用性。</li>\n<li>效果好：在适当的 n 值下，n-gram 算法能够捕捉到文本中的局部统计信息，对于某些任务具有较好的效果。</li>\n</ul>\n<p>（2）缺点</p>\n<ul>\n<li>数据稀疏性：随着 n 的增加，n-gram 的数量急剧增长，导致很多 n-gram 在文本中只出现一次或根本不出现，这使得频率统计变得不可靠。</li>\n<li>上下文信息有限：n-gram 只考虑了固定长度的上下文信息，无法捕捉更复杂的语义关系。对于较长的句子或篇章，n-gram 可能无法充分表达其整体意义。</li>\n<li>计算复杂度高：当 n 较大或文本较长时，生成和统计 n-gram 的计算复杂度会显著增加，可能导致性能问题。</li>\n</ul>\n<h1 id=\"三-程序实现\"><a class=\"markdownIt-Anchor\" href=\"#三-程序实现\">#</a> 三、程序实现</h1>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> re</pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">generate_ngrams</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">,</span>n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token comment\"># split sentences into tokens</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    tokens<span class=\"token operator\">=</span>re<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\\\s+\"</span><span class=\"token punctuation\">,</span>text<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    ngrams<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token comment\"># collect the n-grams</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>tokens<span class=\"token punctuation\">)</span><span class=\"token operator\">-</span>n<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>       temp<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>tokens<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> j <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">,</span>i<span class=\"token operator\">+</span>n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>       ngrams<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token string\">\" \"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>temp<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    <span class=\"token keyword\">return</span> ngrams</pre></td></tr><tr><td data-num=\"15\"></td><td><pre></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>sentence <span class=\"token operator\">=</span> <span class=\"token string\">'_start_ this is ngram _generation_'</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>my_ngrams <span class=\"token operator\">=</span> generate_ngrams<span class=\"token punctuation\">(</span>sentence<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>w <span class=\"token keyword\">for</span> w <span class=\"token keyword\">in</span> my_ngrams<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>  输出：</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token string\">'_start_ this is'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'this is ngram'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'is ngram _generation_'</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><p>  或者使用 NLTK 包</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">from</span> nltk <span class=\"token keyword\">import</span> ngrams</pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>sentence <span class=\"token operator\">=</span> <span class=\"token string\">'_start_ this is ngram _generation_'</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>my_ngrams <span class=\"token operator\">=</span> ngrams<span class=\"token punctuation\">(</span>sentence<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>w <span class=\"token keyword\">for</span> w <span class=\"token keyword\">in</span> my_ngrams<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>  输出：</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span><span class=\"token string\">'_start_'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'this'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'is'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'this'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'is'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ngram'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'is'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ngram'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'_generation_'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure>",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2025/01/02/AI/TIR/",
            "url": "http://qianqiu-cell.github.io/2025/01/02/AI/TIR/",
            "title": "TIR(ToRE) 集成工具推理",
            "date_published": "2025-01-01T16:00:00.000Z",
            "content_html": "<ul>\n<li>ToRA github 网站：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL21pY3Jvc29mdC9Ub1JB\">https://github.com/microsoft/ToRA</span></li>\n<li>集成工具推理相关数据集：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9kYXRhc2V0cy9BSS1NTy9OdW1pbmFNYXRoLVRJUj9yb3c9MA==\">https://huggingface.co/datasets/AI-MO/NuminaMath-TIR?row=0</span></li>\n</ul>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/12/31/AI/Top_k/",
            "url": "http://qianqiu-cell.github.io/2024/12/31/AI/Top_k/",
            "title": "Top_k, Top_p, Temperature 参数",
            "date_published": "2024-12-30T16:00:00.000Z",
            "content_html": "<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI4NTY4NjYvYXJ0aWNsZS9kZXRhaWxzLzE0MDMwODA4Mw==\">https://blog.csdn.net/u012856866/article/details/140308083</span></p>\n<h1 id=\"一-引言\"><a class=\"markdownIt-Anchor\" href=\"#一-引言\">#</a> 一、引言</h1>\n<p>大多数语言模型都是通过生成 token 序列（sequence）中的下一个 token。每次模型生成下一个 token 时，会输入完整的 token 序列并预测下一个 token。这种策略被称为自回归生成（autoregressive generation）。</p>\n<p>为了生成输出文本，在每一步预测下一个 token 的过程中，模型会给出一个概率分布，表示它对下一个单词的预测。例如，如果输入的文本是 “我最喜欢的”，那么模型可能会给出下面的概率分布：</p>\n<p><img data-src=\"/images/AI/Top_k/1.png\" alt=\"\"></p>\n<p>有如下几种常见的方法，来根据概率分布选择下一个单词：</p>\n<ul>\n<li>贪心解码（Greedy Decoding）：直接选择概率最高的单词。这种方法简单高效，但是可能会导致生成的文本过于单调和重复。</li>\n<li>随机采样（Random Sampling）：按照概率分布随机选择一个单词。这种方法可以增加生成的多样性，但是可能会导致生成的文本不连贯和无意义。</li>\n<li>Beam Search（集束搜索）：维护一个大小为 k 的候选序列集合，每一步从每个候选序列的概率分布中选择概率最高的 k 个单词，然后保留总概率最高的 k 个候选序列。这种方法可以平衡生成的质量和多样性，但是可能会导致生成的文本过于保守和不自然。<strong>后续的 top-k、top-p 和 temperature 都是作用于单个束，如果存在多个束，则对每一个束单独执行 top-k、top-p 和 temperature 操作。</strong></li>\n</ul>\n<p>top-k 采样和 top-p 采样是介于贪心解码和随机采样之间的方法，也是目前大模型解码策略中常用的方法。</p>\n<h1 id=\"二-top-k采样\"><a class=\"markdownIt-Anchor\" href=\"#二-top-k采样\">#</a> 二、top-k 采样</h1>\n<p>Top-k 采样是对前面 “贪心策略” 的优化，它从排名前  <code>k</code>  的 token 中进行<strong>抽样</strong>，允许其他分数或概率较高的 token 也有机会被选中。在很多情况下，这种抽样带来的随机性有助于提高生成质量。</p>\n<p>【top-k 采样思路】：在每一步，<strong>只从概率最高的 k 个单词中进行随机采样</strong>，而不考虑其他低概率的单词。</p>\n<p><img data-src=\"/images/AI/Top_k/2.png\" alt=\"\"></p>\n<p>通过调整 k 的大小，即可控制采样列表的大小。“贪心策略” 其实就是 k = 1 的 top-k 采样。</p>\n<h1 id=\"三-top-p采样\"><a class=\"markdownIt-Anchor\" href=\"#三-top-p采样\">#</a> 三、top-p 采样</h1>\n<p>top-k 有一个缺陷，那就是 k 值的选取难以确定，于是出现了动态设置 token 候选列表大小策略 —— 即核采样（Nucleus Sampling）。</p>\n<p>【top-p 采样思路】：在每一步，只从累积概率超过某个阈值 p 的最小单词集合中进行随机采样，而不考虑其他低概率的单词。这种方法也被称为核采样（nucleus sampling），因为它只关注概率分布的核心部分，而忽略了尾部部分。</p>\n<p><img data-src=\"/images/AI/Top_k/3.png\" alt=\"\"></p>\n<p>top-p 值通常设置为比较高的值（如 0.75），目的是限制低概率 token 的长尾。可以同时使用 top-k 和 top-p。<strong>如果 k 和 p 同时启用，则 p 在 k 之后起作用</strong>。</p>\n<h1 id=\"四-temperature采样\"><a class=\"markdownIt-Anchor\" href=\"#四-temperature采样\">#</a> 四、Temperature 采样</h1>\n<p>Temperature 采样受统计热力学的启发，高温意味着更可能遇到低能态。</p>\n<p><strong>Temperature 这个参数可以告诉机器如何在质量和多样性之间进行权衡。较低的 temperature 意味着更高的质量，而较高的 temperature 意味着更高的多样性</strong></p>\n<p>Temperature 采样公式时在 softmax 上加了一个超参数，用来平衡 diverse（多样性），一般的 softmax 公式如下：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>P</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>w</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy=\"false\">(</mo><msub><mi>s</mi><mi>w</mi></msub><mo stretchy=\"false\">)</mo></mrow><mrow><munder><mo>∑</mo><mrow><msup><mi>w</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo>∈</mo><mi>V</mi></mrow></munder><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy=\"false\">(</mo><msub><mi>s</mi><msup><mi>w</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup></msub><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">P_t(w)=\\frac{exp(s_w)}{\\sum_{w^{\\prime}\\in V}exp(s_{w^{\\prime}})}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.44008em;vertical-align:-1.01308em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.17862099999999992em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6828285714285715em;\"><span style=\"top:-2.786em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mrel mtight\">∈</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32708000000000004em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32797999999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6828285714285715em;\"><span style=\"top:-2.786em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01308em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>加入温度超参数计算过程如下：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>P</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>w</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy=\"false\">(</mo><msub><mi>s</mi><mi>w</mi></msub><mi mathvariant=\"normal\">/</mi><mi>τ</mi><mo stretchy=\"false\">)</mo></mrow><mrow><munder><mo>∑</mo><mrow><msup><mi>w</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo>∈</mo><mi>V</mi></mrow></munder><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy=\"false\">(</mo><msub><mi>s</mi><msup><mi>w</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup></msub><mi mathvariant=\"normal\">/</mi><mi>τ</mi><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">P_t(w)=\\frac{exp(s_w/\\tau)}{\\sum_{w^{\\prime}\\in V}exp(s_{w^{\\prime}}/\\tau)}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.44008em;vertical-align:-1.01308em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.17862099999999992em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6828285714285715em;\"><span style=\"top:-2.786em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mrel mtight\">∈</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32708000000000004em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32797999999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6828285714285715em;\"><span style=\"top:-2.786em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">/</span><span class=\"mord mathnormal\" style=\"margin-right:0.1132em;\">τ</span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">/</span><span class=\"mord mathnormal\" style=\"margin-right:0.1132em;\">τ</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01308em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>τ</mi></mrow><annotation encoding=\"application/x-tex\">\\tau</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.1132em;\">τ</span></span></span></span> 的值越大，概率分布就越接近于 uniform（均匀分布），<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>τ</mi></mrow><annotation encoding=\"application/x-tex\">\\tau</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.1132em;\">τ</span></span></span></span> 的值越小，概率密度就越几种在某几个 token 上，可以生成具有更小多样性的句子。</p>\n<p><img data-src=\"/images/AI/Top_k/4.png\" alt=\"\"></p>\n<h1 id=\"五-联合采样\"><a class=\"markdownIt-Anchor\" href=\"#五-联合采样\">#</a> 五、联合采样</h1>\n<p>通常将 top-k、top-p、Temperature 联合起来使用。使用的先后顺序是 top-k-&gt;top-p-&gt;Temperature。举例说明如下：</p>\n<p>（1）首先设置 top-k = 3，表示保留概率最高的 3 个 token。这样就会保留女孩、鞋子、大象这 3 个 token。</p>\n<p>女孩：0.664<br>\n 鞋子：0.199<br>\n 大象：0.105</p>\n<p>（2）接下来，使用 top-p 的方法，保留概率的累计和达到 0.8 的单词，也就是选取女孩和鞋子这两个 token。</p>\n<p>（3）最后使用 Temperature = 0.7 进行归一化，变成：</p>\n<p>女孩：0.660<br>\n 鞋子：0.340</p>\n<p>接着，从上述分布中进行随机采样，选取一个单词作为最终的生成结果。</p>\n<h1 id=\"六-frequency-penalty-和-presence-penalty\"><a class=\"markdownIt-Anchor\" href=\"#六-frequency-penalty-和-presence-penalty\">#</a> 六、frequency penalty 和 presence penalty</h1>\n<p><strong>频率惩罚和存在惩罚（frequency and presence penalties）</strong>。 这些参数是另一种让模型在质量和多样性之间进行权衡的方法。<strong>temperature 参数通过在 token 选择（token sampling）过程中添加随机性来实现输出内容的多样性，而频率惩罚和存在惩罚则通过对已在文本中出现的 token 施加惩罚以增加输出内容的多样性。</strong></p>\n<ul>\n<li><strong>频率惩罚（frequency penalty）</strong>：让 token 每次在文本中出现都受到惩罚。这可以阻止重复使用相同的 token / 单词 / 短语。</li>\n<li><strong>存在惩罚（presence penalty）</strong>：一种固定的惩罚，如果一个 token 已经在文本中出现过，就会受到惩罚。这会导致模型引入更多新的 token / 单词 / 短语，从而使其讨论的主题更加多样化。</li>\n</ul>\n<p>在不确定的情况下，将它们设置为零是一个最安全的选择！</p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/12/31/AI/attention/",
            "url": "http://qianqiu-cell.github.io/2024/12/31/AI/attention/",
            "title": "注意力机制综述",
            "date_published": "2024-12-30T16:00:00.000Z",
            "content_html": "<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82MzEzOTg1MjU=\">https://zhuanlan.zhihu.com/p/631398525</span><span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82NzY2NTUzNTI=\">https://zhuanlan.zhihu.com/p/676655352</span><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVVUNDIxazdyQS8/c3BtX2lkX2Zyb209MzMzLjEwMDcudG9wX3JpZ2h0X2Jhcl93aW5kb3dfY3VzdG9tX2NvbGxlY3Rpb24uY29udGVudC5jbGljayZhbXA7dmRfc291cmNlPWUwMTE3MmVhMjkyYzFjNjA1YjM0NjEwMWQ3MDA2YzYx\">https://www.bilibili.com/video/BV1UT421k7rA/?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click&amp;vd_source=e01172ea292c1c605b346101d7006c61</span>、<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82ODc4MzIxNzI=\">https://zhuanlan.zhihu.com/p/687832172</span></p>\n<h1 id=\"一-注意力机制简述\"><a class=\"markdownIt-Anchor\" href=\"#一-注意力机制简述\">#</a> 一、注意力机制简述</h1>\n<p>  注意力机制从本质上讲和人类的选择性注意力机制类似，核心目标也是<strong>从众多信息中选出对当前任务目标更加关键的信息</strong>。最典型的注意力机制包括<strong>自注意力机制、空间注意力机制和时间注意力机制</strong>。这些注意力机制允许模型<strong>对输入序列的不同位置分配不同的权重</strong>，以便在处理每个序列元素时专注于最相关的部分。</p>\n<p>  最初的注意力机制将注意力汇聚的输出计算成为值的加权和。通过 Query 与 Key 的注意力汇聚（即，<strong>给定一个 Query，计算 Query 与 Key 的相关性，然后根据 Query 与 Key 的相关性去和对应的 Value 进行相乘</strong>）实现对 Value 的注意力权重分配，生成最终的输出结果。</p>\n<p><img data-src=\"/images/AI/attention/1.1.jpg\" alt=\"\"></p>\n<p>  在上图中需要将中文的 &quot;我&quot; 翻译成英文的 &quot;me&quot;，这就需要 &quot;我&quot; 和 &quot;me&quot; 之间的注意力分数相对于 &quot;我&quot; 和其他英文单词的要高。Query， Key，和 Value 的含义可以如下理解：</p>\n<ul>\n<li>Query：可以将 &quot;我&quot; 看作成 Query，因为 &quot;我&quot; 是当前要查询的目标，即<strong>当前输入的特征表示</strong>。</li>\n<li>Key：键矩阵里的数据用来计算这些词之间的相似度，可以将<strong>每个单词的重要特征表示</strong>看作成 Key。</li>\n<li>Value：值矩阵用来根据相似度计算出最终的输出结果，<strong>每个单词本身的特征向量</strong>看作为 Value，一般和 Key 成对出现，也就是我们常说的 &quot;键 - 值&quot; 对。</li>\n</ul>\n<h1 id=\"二-transformer的注意力层\"><a class=\"markdownIt-Anchor\" href=\"#二-transformer的注意力层\">#</a> 二、Transformer 的注意力层</h1>\n<p>  在 Transformer 架构中，有两大的组件，分别是编码器（Encoder）和解码器（Decoder）， 编码器主要是将<strong>输入序列</strong>映射到潜在语义空间（<strong>注意力向量</strong>，也叫上下文向量），而解码器则是将<strong>注意力向量</strong>映射到<strong>输出序列</strong>。</p>\n<p>  在 Transformer 架构中，有 3 种不同的注意力层：</p>\n<p>解码器中的交叉注意力层（Cross attention layer）<br>\n编码器中的全局自注意力层（Global self attention layer）<br>\n解码器中的因果自注意力层（Causal attention layer）</p>\n<p><img data-src=\"/images/AI/attention/2.1.jpg\" alt=\"\"></p>\n<h1 id=\"三-自注意力机制\"><a class=\"markdownIt-Anchor\" href=\"#三-自注意力机制\">#</a> 三、自注意力机制</h1>\n<p>  在自注意力机制中，Query，Key，Value 均通过输入序列的 embedding 映射到。即</p>\n<ul>\n<li>Q = 输入序列中的当前位置词向量</li>\n<li>K = 输入序列中的所有位置词向量</li>\n<li>V = 输入序列中的所有位置词向量</li>\n</ul>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>key_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>query_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>value_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>q <span class=\"token operator\">=</span> query_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>k <span class=\"token operator\">=</span> key_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>v <span class=\"token operator\">=</span> value_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>  具体的操作为：</p>\n<p>  先根据 Query，Key 计算两者的相关性，然后再通过 softmax 函数得到 注意力分数，使用 softmax 函数是为了使得所有的注意力分数在 [0,1] 之间，并且和为 1。这里的重点在于如何计算 Query，Key 的相关性。Query，Key 的相关性公式一般表示如下：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>score</mtext><mo stretchy=\"false\">(</mo><mi>q</mi><mo separator=\"true\">,</mo><msub><mi>k</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mtext>softmax</mtext><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">(</mo><mi>q</mi><mo separator=\"true\">,</mo><msub><mi>k</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">(</mo><mi>q</mi><mo separator=\"true\">,</mo><msub><mi>k</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>exp</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">(</mo><mi>q</mi><mo separator=\"true\">,</mo><msub><mi>k</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\text{score}(q,k_i)=\\text{softmax}(\\alpha(q,k_i))=\\frac{\\exp(\\alpha(q,k_i))}{\\sum_{j=1}^n\\exp(\\alpha(q,k_j))}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">score</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">softmax</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.55711em;vertical-align:-1.1301100000000002em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.305708em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.804292em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.43581800000000004em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\">exp</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mop\">exp</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1301100000000002em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>其中 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi><mo stretchy=\"false\">(</mo><mi>q</mi><mo separator=\"true\">,</mo><msub><mi>k</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\alpha(q,k_i)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 即表示自注意力机制，自注意力机制有很多变体，比如：加性注意力、缩放点积注意力等等。</p>\n<p>  之后根据注意力分数进行加权求和，得到带注意力分数的 Value，以方便进行下游任务。</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>output</mtext><mo>=</mo><mtext>score</mtext><mo stretchy=\"false\">(</mo><mi>Q</mi><mo separator=\"true\">,</mo><mi>K</mi><mo stretchy=\"false\">)</mo><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">\\text{output}=\\text{score}(Q,K)V\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.80952em;vertical-align:-0.19444em;\"></span><span class=\"mord text\"><span class=\"mord\">output</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">score</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mclose\">)</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span></p>\n<h2 id=\"31-加性注意力机制\"><a class=\"markdownIt-Anchor\" href=\"#31-加性注意力机制\">#</a> 3.1 加性注意力机制</h2>\n<p><img data-src=\"/images/AI/attention/3.1.png\" alt=\"\"></p>\n<p>加性注意力机制的核心思想是<strong>通过一个加性函数结合查询（Query）、键（Key）信息来计算注意力权重</strong>，之后再<strong>依据这些权重对值（Value）进行加权求和</strong>。其具体步骤如下：</p>\n<ul>\n<li>输入映射：给定一个查询向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span></span></span></span> 和键向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>k</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">k_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，通过线性变换将 Query 和 Key 映射到一个共同的空间中，通常使用 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>W</mi><mi>q</mi></msub></mrow><annotation encoding=\"application/x-tex\">W_q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>W</mi><mi>k</mi></msub></mrow><annotation encoding=\"application/x-tex\">W_k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>。</li>\n<li>加性融合与激活：对于每个键 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>k</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">k_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，将查询 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span></span></span></span> 与其进行加性融合，然后通过一个非线性激活函数（如 tanh 或 ReLU）来增强表达能力，最后将融合后的向量通过一个线性层（权重矩阵<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>W</mi><mi>v</mi></msub></mrow><annotation encoding=\"application/x-tex\">W_v</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>），上述两步的公式如下，其中<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi><mo stretchy=\"false\">(</mo><mi>q</mi><mo separator=\"true\">,</mo><msub><mi>k</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\alpha(q,k_i)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 表示注意力函数</li>\n</ul>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>α</mi><mo stretchy=\"false\">(</mo><mi>q</mi><mo separator=\"true\">,</mo><msub><mi>k</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>=</mo><msubsup><mi>W</mi><mi>v</mi><mtext>T</mtext></msubsup><mtext>tanh</mtext><mo stretchy=\"false\">(</mo><msubsup><mi>W</mi><mi>q</mi><mi>T</mi></msubsup><mi>q</mi><mo>+</mo><msub><mi>W</mi><mi>k</mi></msub><msub><mi>k</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\alpha(q,k_i)=W_v^{\\text{T}}\\text{tanh}(W_q^Tq+W_kk_i)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.274439em;vertical-align:-0.383108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">T</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mord text\"><span class=\"mord\">tanh</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.891331em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.383108em;\"><span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<ul>\n<li>注意力权重计算：利用 softmax 函数，得到注意力权重<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>a</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">a_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，用于表示对每个值<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">v_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 的重视程度。具体公式如下：</li>\n</ul>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>a</mi><mi>i</mi></msub><mo>=</mo><mtext>softmax</mtext><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">(</mo><mi>q</mi><mo separator=\"true\">,</mo><msub><mi>k</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mtext>exp</mtext><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">(</mo><mi>q</mi><mo separator=\"true\">,</mo><msub><mi>k</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mtext>exp</mtext><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">(</mo><mi>q</mi><mo separator=\"true\">,</mo><msub><mi>k</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">a_i=\\text{softmax}(\\alpha(q,k_i))=\\frac{\\text{exp}(\\alpha(q,k_i))}{\\sum_{j=1}^n\\text{exp}(\\alpha(q,k_j))}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">softmax</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.55711em;vertical-align:-1.1301100000000002em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.305708em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.804292em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.43581800000000004em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord text\"><span class=\"mord\">exp</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord\">exp</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1301100000000002em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<ul>\n<li>加权求和：最后，根据计算出的注意力权重<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>a</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">a_{i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 对所有值向量<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">v_{i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 进行加权求和，得到最终的上下文向量<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>c</mi></mrow><annotation encoding=\"application/x-tex\">c</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">c</span></span></span></span>：</li>\n</ul>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>c</mi><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>a</mi><mi>i</mi></msub><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">c=\\sum_{i=1}^n a_iv_i\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">c</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.929066em;vertical-align:-1.277669em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.6513970000000002em;\"><span style=\"top:-1.872331em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3000050000000005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.277669em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<h2 id=\"32-缩放点积注意力机制\"><a class=\"markdownIt-Anchor\" href=\"#32-缩放点积注意力机制\">#</a> 3.2 缩放点积注意力机制</h2>\n<p><img data-src=\"/images/AI/attention/3.2.png\" alt=\"\"></p>\n<p>这是 Transformer 文章提出的注意力计算方法，缩放点积注意力机制的基本思想是，对于查询（Query）和一系列键值对（Key-Value Pairs）的集合，<strong>通过计算查询与每个键的点积，并利用 softmax 函数将这些点积转换为概率分布，以此来确定每个值的重要性，最终加权求和得到输出</strong>。具体如下：</p>\n<ul>\n<li T=\"\">点积计算：首先，对每个查询向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span></span></span></span> 与所有键向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>k</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">k_{i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 计算点积，生成原始匹配分数矩阵 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>S</mi></mrow><annotation encoding=\"application/x-tex\">S</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span></span></span></span>，即 S_{i}=q\\cdot k_{i}^</li>\n<li>缩放操作：然后，将上述匹配分数除以<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub><mtext>​</mtext></mrow><annotation encoding=\"application/x-tex\">d_{k}​</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">​</span></span></span></span>​，以完成缩放操作，确保数值稳定性。上述两步的公式如下，其中<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi><mo stretchy=\"false\">(</mo><mi>q</mi><mo separator=\"true\">,</mo><msub><mi>k</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\alpha(q,k_i)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 表示注意力函数</li>\n</ul>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>α</mi><mo stretchy=\"false\">(</mo><mi>q</mi><mo separator=\"true\">,</mo><msub><mi>k</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mi>q</mi><mo>⋅</mo><msubsup><mi>k</mi><mi>i</mi><mi>T</mi></msubsup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac></mrow><annotation encoding=\"application/x-tex\">\\alpha(q,k_i)=\\frac{q\\cdot k_{i}^{T}}{\\sqrt{d_{k}}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.448331em;vertical-align:-0.93em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5183309999999999em;\"><span style=\"top:-2.25278em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.85722em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.81722em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.18278000000000005em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-2.441336em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.258664em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.93em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<ul>\n<li>注意力权值计算：接下来，应用 softmax 函数到缩放后的分数上，将其转化为概率分布，反映了每个值相对于查询的重要性。</li>\n</ul>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>a</mi><mi>i</mi></msub><mo>=</mo><mtext>softmax</mtext><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">(</mo><mi>q</mi><mo separator=\"true\">,</mo><msub><mi>k</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mtext>exp</mtext><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">(</mo><mi>q</mi><mo separator=\"true\">,</mo><msub><mi>k</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mtext>exp</mtext><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">(</mo><mi>q</mi><mo separator=\"true\">,</mo><msub><mi>k</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">a_i=\\text{softmax}(\\alpha(q,k_i))=\\frac{\\text{exp}(\\alpha(q,k_i))}{\\sum_{j=1}^n\\text{exp}(\\alpha(q,k_j))}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">softmax</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.55711em;vertical-align:-1.1301100000000002em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.305708em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.804292em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.43581800000000004em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord text\"><span class=\"mord\">exp</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord\">exp</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1301100000000002em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<ul>\n<li>加权求和：最后，使用得到的概率分布对值矩阵 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span> 进行加权求和，生成最终的上下文向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>c</mi></mrow><annotation encoding=\"application/x-tex\">c</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">c</span></span></span></span>，即每个查询位置的输出。以上步骤的公式如下：</li>\n</ul>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>c</mi><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>a</mi><mi>i</mi></msub><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">c=\\sum_{i=1}^n a_{i}v_{i}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">c</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.929066em;vertical-align:-1.277669em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.6513970000000002em;\"><span style=\"top:-1.872331em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3000050000000005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.277669em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<h1 id=\"三-交叉注意力机制\"><a class=\"markdownIt-Anchor\" href=\"#三-交叉注意力机制\">#</a> 三、交叉注意力机制</h1>\n<p>交叉注意力机制计算流程类似于自注意力机制，但有一个关键区别：<strong>自注意力机制中的查询、键和值都来自同一个输入序列，而交叉注意力机制的查询和键 / 值来自不同的输入序列</strong>。即：</p>\n<ul>\n<li>查询<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">Q</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{Q}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8805499999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">Q</span></span></span></span></span> 来自一个输入序列（如问题）。</li>\n<li>键<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">K</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{K}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68611em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">K</span></span></span></span></span> 和值<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">V</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{V}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68611em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbf\" style=\"margin-right:0.01597em;\">V</span></span></span></span></span> 来自另一个输入序列（如段落或上下文）。</li>\n</ul>\n<p>在 Transformer 中，交叉注意力层位于字面上的中心位置；它连接了编码器和解码器。</p>\n<ul>\n<li>Q = 解码器中因果注意力层的输出向量</li>\n<li>K = 编码器输出的注意力向量</li>\n<li>V = 编码器输出的注意力向量</li>\n</ul>\n<h1 id=\"四-因果注意力层\"><a class=\"markdownIt-Anchor\" href=\"#四-因果注意力层\">#</a> 四、因果注意力层</h1>\n<p>因果注意力层对<strong>解码器中输出序列</strong>执行类似于全局自注意力层的工作；但与编码器的全局自注意力层有不同的处理方式。</p>\n<p>Transformer 是一个 “自回归” 模型，每个序列元素的输出只依赖于前面的序列元素，模型具有 “因果” 性。</p>\n<p>要构建一个因果自注意力层，在计算注意力分数和求和注意力值时需要使用<strong>适当的掩码</strong>，因为输出序列也是一次性输入的，但在计算前面分词的时候是不希望它后面的分词也参与计算的。</p>\n<ul>\n<li>Q = 输出序列中的当前位置词向量</li>\n<li>K = 输出序列中的所有位置词向量</li>\n<li>V = 输出序列中的所有位置词向量</li>\n</ul>\n<p><img data-src=\"/images/AI/attention/4.1.png\" alt=\"\"></p>\n<h1 id=\"五-其他注意力机制\"><a class=\"markdownIt-Anchor\" href=\"#五-其他注意力机制\">#</a> 五、其他注意力机制</h1>\n<h2 id=\"51-flash-attention\"><a class=\"markdownIt-Anchor\" href=\"#51-flash-attention\">#</a> 5.1 Flash Attention</h2>\n<p><img data-src=\"/images/AI/attention/5.1.png\" alt=\"\"></p>\n<p>FlashAttention 旨在<strong>加速注意力计算并减少内存占用</strong>。FlashAttention 利用底层硬件的内存层次知识，例如 GPU 的内存层次结构，来提高计算速度和减少内存访问开销。 FlashAttention 的核心原理是通过<strong>将输入分块并在每个块上执行注意力操作</strong>，从而减少对高带宽内存（HBM）的读写操作。具体而言，FlashAttention 使用平铺和重计算等经典技术，将输入块从 HBM 加载到 SRAM（快速缓存），在 SRAM 上执行注意力操作，并将结果更新回 HBM。FlashAttention 减少了内存读写量，从而实现了 2-4 倍的时钟时间加速。</p>\n<p>文章《FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness》在论文第一句指出 “Transformers are slow and memory-hungry on long sequences, since the time and memory complexity of self-attention are quadratic in sequence length.”，可以看出<strong>由于 Transformer 中 self-attention 的时间和内存复杂度是序列长度的二次方，所以序列过长时，算法速度会变慢，需要消耗很高的内存</strong>。</p>\n<h3 id=\"1-预备知识\"><a class=\"markdownIt-Anchor\" href=\"#1-预备知识\">#</a> (1) 预备知识</h3>\n<p>（1）HBM（High Bandwidth Memory, 高带宽内存）和 SRAM（Static Random-Access Memory, 快速缓存）</p>\n<p>HBM 和 SRAM 是两种不同类型的计算机内存。</p>\n<ul>\n<li>HBM 是一种<strong>高带宽内存接口</strong>，用于 3D 堆叠的 SDRAM，<strong>具有较高的带宽和较低的功耗</strong>。</li>\n<li>SRAM 是一种<strong>静态随机访问存储器</strong>，用于高速缓存等内部存储器，<strong>具有更快的访问速度和更低的延迟</strong>，但成本更高且占用更多芯片空间。</li>\n</ul>\n<p>下图是 GPU A100 的内存分布：</p>\n<p><img data-src=\"/images/AI/attention/5.2jpg\" alt=\"\"></p>\n<p>（2）MAC (Memory Access Cost，存储访问开销)</p>\n<p>MAC（Memory Access Cost，存储访问开销）是指在计算机系统中，<strong>访问内存或存储器所需的时间和资源开销</strong>。它是衡量计算机程序或算法性能的重要指标之一。 MAC 的值取决于多个因素，包括内存层次结构、缓存命中率、内存带宽、存储器延迟等。较低的 MAC 值表示访问内存的开销较小，而较高的 MAC 值表示访问内存的开销较大。</p>\n<h2 id=\"2-flashattention-原理\"><a class=\"markdownIt-Anchor\" href=\"#2-flashattention-原理\">#</a> (2) FlashAttention 原理</h2>\n<p>传统 Attention 的计算过程如下：</p>\n<p><img data-src=\"/images/AI/attention/5.3.jpg\" alt=\"\"></p>\n<p>FlashAttention 的核心思想是减少 HBM 的读写，使用到的核心方法为分块计算，重新计算</p>\n<ul>\n<li>分块计算：通过分块计算，融合多个操作，减少中间结果缓存</li>\n<li>重新计算：反向传播时，重新计算中间结果</li>\n</ul>\n<p>因为 Attention 计算中涉及 softmax，所以不能简单的分块后直接计算。softmax 操作是 row-wise 的，即每行都算一次 softmax，所以需要用到平铺算法来分块计算 softmax。<strong>FlashAttention 采用 safe softmax，来进行分块计算</strong>，具体的的过程如下：</p>\n<p><img data-src=\"/images/AI/attention/5.4.jpg\" alt=\"\"></p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/12/30/AI/RFT/",
            "url": "http://qianqiu-cell.github.io/2024/12/30/AI/RFT/",
            "title": "RFT（拒绝采样）",
            "date_published": "2024-12-29T16:00:00.000Z",
            "content_html": "<p>参考：论文《Scaling Relationship on Learning Mathematical Reasoning with Large Language Models》、<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuemhpaHUuY29tL3RhcmRpcy9iZC9hcnQvNzAzODQ4NjI3\">https://www.zhihu.com/tardis/bd/art/703848627</span>、<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC81MDc4MzA1NzY=\">https://zhuanlan.zhihu.com/p/507830576</span></p>\n<p>  RFT（Rejection sampling Fine-Tuning，拒绝采样微调）的整体思路是使用多个模型生成推理路径，经过质量筛选和多样性筛选之后，获得增强的数据集，其中每一个问题都对应了多种解析，用作训练集训练模型。RFT 的步骤如下：</p>\n<p>1、<strong>训练一轮小模型和大模型</strong>：首先利用数据集（如 GSM8K）<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>D</mi><mo>=</mo><mo stretchy=\"false\">{</mo><msub><mi>q</mi><mi>i</mi></msub><mo separator=\"true\">,</mo><msub><mi>r</mi><mi>i</mi></msub><mo separator=\"true\">,</mo><msub><mi>a</mi><mi>i</mi></msub><msub><mo stretchy=\"false\">}</mo><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">D=\\{q_i,r_i,a_i\\}_{i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">{</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">}</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 将预训练大语言模型 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>ρ</mi></mrow><annotation encoding=\"application/x-tex\">\\rho</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">ρ</span></span></span></span> 通过监督微调获得 SFT 模型<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>π</mi></mrow><annotation encoding=\"application/x-tex\">\\pi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>q</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">q_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 其中表示问题，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>r</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">r_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 表示推理，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>a</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">a_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 表示答案；</p>\n<p>2、<strong>选择推理路径</strong>：对于每一个问题<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>q</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">q_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，使用 SFT 模型 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>π</mi></mrow><annotation encoding=\"application/x-tex\">\\pi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span></span></span></span> 来生成<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> 个候选推理路径<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>r</mi></mrow><annotation encoding=\"application/x-tex\">r</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span></span></span></span> 和答案<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>a</mi></mrow><annotation encoding=\"application/x-tex\">a</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">a</span></span></span></span>，过滤掉模型生成答案和标准答案不一致的推理路径，并删除具有相同方程列表的其他推理路径以降低推理路径的重复，增加数据集的多样性；</p>\n<p>3、<strong>获得增强数据集</strong>定义<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>D</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo>=</mo><mi>D</mi><mo>∪</mo><mo stretchy=\"false\">{</mo><mi>q</mi><mi>i</mi><mo separator=\"true\">,</mo><msub><mi>r</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>j</mi></mrow></msub><mo separator=\"true\">,</mo><msub><mi>a</mi><mi>i</mi></msub><msub><mo stretchy=\"false\">}</mo><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>j</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">D&#x27;=D\\cup\\{qi,r_{i,j},a_i\\}_{i,j}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.751892em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∪</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mopen\">{</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mord mathnormal\">i</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">}</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span> 作为增强数据集。使用数据集<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>D</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup></mrow><annotation encoding=\"application/x-tex\">D&#x27;</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.751892em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span></span></span></span> 在预训练模型<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>ρ</mi></mrow><annotation encoding=\"application/x-tex\">\\rho</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">ρ</span></span></span></span> 上进行微调得到<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>π</mi><mrow><mi>R</mi><mi>F</mi><mi>T</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\pi_{RFT}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，得到 RFT 模型。<br>\n使用新的数据集微调模型：使用新的推理数据集 R^s 微调一轮小模型，并将其用于微调右边的 llama2-70B；</p>\n<p>  从单个 SFT 模型中采样的推理路径可能在逻辑上是非多样化的。因此，可以利用从不同模型聚合的拒绝采样推理路径来进一步提高数学推理性能，实现多模型拒绝采样。</p>\n<p>  RFT 的关键点是步骤 2 中选择推理路径。具体做法如下图所示：</p>\n<p><img data-src=\"/images/AI/RFT/1.1.png\" alt=\"\"></p>\n<p>  面对重复路径时，利用 Levenstein Distance（莱文斯坦距离算法）获得与所有已经保存路径最不相似的推理路径，从而增加增强数据集的多样性。</p>\n<p>  莱文斯坦距离指的是将一个字符串变为另一个字符串需要进行编辑操作最少的次数。其中，允许的编辑操作有以下三种：</p>\n<ul>\n<li>「替换」：将一个字符替换成另一个字符</li>\n<li>「插入」：插入一个字符</li>\n<li>「删除」：删除一个字符</li>\n</ul>\n<p>  莱文斯坦距离用于衡量两个字符串之间的差异，被广泛应用于拼写纠错检查、DNA 分析、语音识别等领域。</p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/12/29/AI/PrecisionRecall/",
            "url": "http://qianqiu-cell.github.io/2024/12/29/AI/PrecisionRecall/",
            "title": "准确率、精确率、召回率等指标定义",
            "date_published": "2024-12-28T16:00:00.000Z",
            "content_html": "<h1 id=\"一-混淆矩阵\"><a class=\"markdownIt-Anchor\" href=\"#一-混淆矩阵\">#</a> 一、混淆矩阵</h1>\n<p>  在机器学习领域，混淆矩阵（Confusion Matrix），又称为可能性矩阵或错误矩阵。混淆矩阵的结构一般如下图表示的方法。</p>\n<p><img data-src=\"/images/AI/PrecisionRecall/1.1.png\" alt=\"\"></p>\n<p>  混淆矩阵要表达的含义：</p>\n<ul>\n<li>混淆矩阵的每一列代表了<strong>预测类别</strong>，每一列的总数表示预测为该类别的数据的数目；</li>\n<li>每一行代表了数据的<strong>真实归属类别</strong>，每一行的数据总数表示该类别的数据实例的数目；</li>\n</ul>\n<p>  每一类的具体定义如下：</p>\n<ul>\n<li>True Positive（TP）：真正类。样本的真实类别是正类，并且模型识别的结果也是正类。</li>\n<li>False Negative（FN）：假负类。样本的真实类别是正类，但是模型将其识别为负类。</li>\n<li>False Positive（FP）：假正类。样本的真实类别是负类，但是模型将其识别为正类。</li>\n<li>True Negative（TN）：真负类。样本的真实类别是负类，并且模型将其识别为负类。</li>\n</ul>\n<p>  该矩阵可用于易于理解的二类分类问题，但通过向混淆矩阵添加更多行和列，可轻松应用于具有 3 个或更多类值的问题。</p>\n<p>  记住以下两个关键的理解方法：</p>\n<ul>\n<li>根据图片，横着的是数据真实的类别，竖着的是模型预测的类别，先横后竖，先真实类别，后模型预测的类别；</li>\n<li>True 表示预测正确，False 表示预测错误；Positive 表示模型预测为正样本，Negative 表示模型预测为负样本，所有的单词的意思都是和模型预测有关。</li>\n</ul>\n<p>  混淆矩阵是对分类问题的预测结果的总结。使用计数值汇总正确和不正确预测的数量，并按每个类进行细分，这是混淆矩阵的关键所在。混淆矩阵显示了分类模型的在进行预测时会对哪一部分产生混淆。它不仅可以让您了解分类模型所犯的错误，更重要的是可以了解哪些错误类型正在发生。正是这种对结果的分解克服了仅使用分类准确率所带来的局限性。</p>\n<h1 id=\"二-从混淆矩阵得到分类指标\"><a class=\"markdownIt-Anchor\" href=\"#二-从混淆矩阵得到分类指标\">#</a> 二、从混淆矩阵得到分类指标</h1>\n<p>  从混淆矩阵当中，可以得到更高级的分类指标：Accuracy（精确率），Precision（正确率或者准确率），Recall（召回率），Specificity（特异性），Sensitivity（灵敏度）。</p>\n<p>  对于二分类问题，有如下关系：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>样例总数</mtext><mo>=</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>N</mi><mtext>。</mtext></mrow><annotation encoding=\"application/x-tex\">样例总数 = TP + FP + TN + FN。\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord cjk_fallback\">样</span><span class=\"mord cjk_fallback\">例</span><span class=\"mord cjk_fallback\">总</span><span class=\"mord cjk_fallback\">数</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mord cjk_fallback\">。</span></span></span></span></span></p>\n<h2 id=\"21-准确率accuracy\"><a class=\"markdownIt-Anchor\" href=\"#21-准确率accuracy\">#</a> 2.1 准确率（Accuracy）</h2>\n<p>  准确率是最常用的评价指标，表示模型正确预测的样本占所有样本的比例。计算公式为：</p>\n<p>公式：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>准确率</mtext><mo>=</mo><mfrac><mtext>分类正确的样本数</mtext><mtext>总样本数</mtext></mfrac></mrow><annotation encoding=\"application/x-tex\">准确率=\\frac{分类正确的样本数}{总样本数}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord cjk_fallback\">准</span><span class=\"mord cjk_fallback\">确</span><span class=\"mord cjk_fallback\">率</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.04633em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.36033em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord cjk_fallback\">总</span><span class=\"mord cjk_fallback\">样</span><span class=\"mord cjk_fallback\">本</span><span class=\"mord cjk_fallback\">数</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord cjk_fallback\">分</span><span class=\"mord cjk_fallback\">类</span><span class=\"mord cjk_fallback\">正</span><span class=\"mord cjk_fallback\">确</span><span class=\"mord cjk_fallback\">的</span><span class=\"mord cjk_fallback\">样</span><span class=\"mord cjk_fallback\">本</span><span class=\"mord cjk_fallback\">数</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>A</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>y</mi><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.1296600000000003em;vertical-align:-0.7693300000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.36033em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693300000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>优点：</p>\n<ul>\n<li>简单易懂，适用于数据平衡的情况。</li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li>当数据不平衡时，准确率可能会受到极大影响。例如，在样本类别严重不均的情况下，准确率可能看起来很好，但模型的性能却不理想。</li>\n</ul>\n<h2 id=\"22-精确率precision\"><a class=\"markdownIt-Anchor\" href=\"#22-精确率precision\">#</a> 2.2 精确率（Precision）</h2>\n<p>  精确率又称为查准率，表示在所有被模型预测为正类的样本中，真正为正类的比例。精确率可以帮助我们理解模型在预测正类时的准确度。</p>\n<p>公式：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>精确率</mtext><mo>=</mo><mfrac><mrow><mtext>真正类</mtext><mo stretchy=\"false\">(</mo><mi>T</mi><mi>P</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mtext>真正类</mtext><mo stretchy=\"false\">(</mo><mi>T</mi><mi>P</mi><mo stretchy=\"false\">)</mo><mo>+</mo><mtext>假正类</mtext><mo stretchy=\"false\">(</mo><mi>F</mi><mi>P</mi><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">精确率=\\frac{真正类(TP)}{真正类(TP)+假正类(FP)}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord cjk_fallback\">精</span><span class=\"mord cjk_fallback\">确</span><span class=\"mord cjk_fallback\">率</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord cjk_fallback\">真</span><span class=\"mord cjk_fallback\">正</span><span class=\"mord cjk_fallback\">类</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord cjk_fallback\">假</span><span class=\"mord cjk_fallback\">正</span><span class=\"mord cjk_fallback\">类</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord cjk_fallback\">真</span><span class=\"mord cjk_fallback\">正</span><span class=\"mord cjk_fallback\">类</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.936em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">Precision = \\frac{TP}{TP + FP}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.1296600000000003em;vertical-align:-0.7693300000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.36033em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693300000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>优点：</p>\n<ul>\n<li>精确率较高说明模型对正类预测的可信度高。</li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li>精确率并不关心模型是否漏掉了正类样本。</li>\n</ul>\n<h2 id=\"23-召回率recall\"><a class=\"markdownIt-Anchor\" href=\"#23-召回率recall\">#</a> 2.3 召回率（Recall）</h2>\n<p>  召回率又称为查全率，表示在所有实际为正类的样本中，模型预测为正类的比例。召回率衡量模型对正类的识别能力。</p>\n<p>公式：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>召回率</mtext><mo>=</mo><mfrac><mrow><mtext>真正类</mtext><mo stretchy=\"false\">(</mo><mi>T</mi><mi>P</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mtext>真正类</mtext><mo stretchy=\"false\">(</mo><mi>T</mi><mi>P</mi><mo stretchy=\"false\">)</mo><mo>+</mo><mtext>假负类</mtext><mo stretchy=\"false\">(</mo><mi>F</mi><mi>N</mi><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">召回率=\\frac{真正类(TP)}{真正类(TP)+假负类(FN)}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord cjk_fallback\">召</span><span class=\"mord cjk_fallback\">回</span><span class=\"mord cjk_fallback\">率</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord cjk_fallback\">真</span><span class=\"mord cjk_fallback\">正</span><span class=\"mord cjk_fallback\">类</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord cjk_fallback\">假</span><span class=\"mord cjk_fallback\">负</span><span class=\"mord cjk_fallback\">类</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord cjk_fallback\">真</span><span class=\"mord cjk_fallback\">正</span><span class=\"mord cjk_fallback\">类</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.936em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">Recall = \\frac{TP}{TP + FN}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.1296600000000003em;vertical-align:-0.7693300000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.36033em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693300000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>优点：</p>\n<ul>\n<li>召回率较高说明模型能够识别大部分的正类样本。</li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li>召回率较高可能意味着更多的假正例，导致精确率较低。</li>\n</ul>\n<h2 id=\"24-精确率和召回率的关系\"><a class=\"markdownIt-Anchor\" href=\"#24-精确率和召回率的关系\">#</a> 2.4 精确率和召回率的关系</h2>\n<p>  精确率和召回率是一对矛盾的指标。一般来说，精确率高时，召回率旺旺偏低；召回率高时，精确率往往偏低。作为两大常用的指标，根据不同的任务，具有不同的重要程度。一半来说具有如下规律：</p>\n<ul>\n<li><strong>精确率更重要</strong>的任务：通常是那些<strong>误报代价较高</strong>的任务，如垃圾邮件过滤、广告推荐和信息检索。通俗理解：<strong>不能多预测，保证模型预测的都是对的（高亮任务需要保证的是精确率，即不能高亮的太多了，要保证高亮的都是对的）</strong></li>\n<li><strong>召回率更重要</strong>的任务：通常是那些<strong>漏掉关键信息会有严重后果</strong>的任务，如医疗诊断、欺诈检测和安全监控。通俗理解：<strong>可以多预测，只要不漏掉就行</strong>。</li>\n</ul>\n<h2 id=\"25-f1-分数f1-score\"><a class=\"markdownIt-Anchor\" href=\"#25-f1-分数f1-score\">#</a> 2.5 F1 分数（F1-Score）</h2>\n<p>  F1 分数是精确率和召回率的调和平均数，结合了精确率和召回率两个指标，能够同时考虑这两者的平衡性。这个指标特别适用于那些<strong>对精确率和召回率同等重视</strong>的情况，在<strong>不均衡数据</strong>的场景下尤其有用。</p>\n<p>公式：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>F</mi><mn>1</mn><mo>=</mo><mn>2</mn><mo>×</mo><mfrac><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>×</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.14077em;vertical-align:-0.7693300000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.37144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693300000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>  F1 分数的取值范围是 0 到 1，1 表示完美的精确率和召回率，0 则表示两者中至少有一个为零。</p>\n<p><strong>优点</strong>：</p>\n<ul>\n<li>F1 分数能够平衡精确率和召回率，适合数据不均衡的情况。</li>\n</ul>\n<p><strong>缺点</strong>：</p>\n<ul>\n<li>F1 分数可能无法准确反映精确率和召回率的单独表现，特别是在某些应用场景下，某一指标比另一个更重要。</li>\n</ul>\n<h2 id=\"25-roc曲线auc得分\"><a class=\"markdownIt-Anchor\" href=\"#25-roc曲线auc得分\">#</a> 2.5 ROC 曲线 AUC 得分</h2>\n<h3 id=\"1roc曲线\"><a class=\"markdownIt-Anchor\" href=\"#1roc曲线\">#</a> （1）ROC 曲线</h3>\n<p>  许多分类器能够通过<strong>输出概率值</strong>来量化他们对答案的不确定性。要<strong>根据概率计算准确性</strong>，您需要一个阈值来决定分类起预测结果是 0 或者 1。AUC 考虑了所有可能的阈值。不同的阈值会导致不同的真正率 (TPR)/ 假正率 (FPR)。随着阈值的降低，分类器会获得更多的真阳性，但也会获得更多的假阳性。它们之间的关系可以绘制出来：</p>\n<p><img data-src=\"/images/AI/PrecisionRecall/1.2.png\" alt=\"\"></p>\n<h1 id=\"2auc得分\"><a class=\"markdownIt-Anchor\" href=\"#2auc得分\">#</a> （2）AUC 得分</h1>\n<p>  AUC 代表 ROC 曲线下的面积。它是一个介于 0 和 1 之间的数，用于衡量模型整体的分类性能。AUC 的值越接近 1，表示模型的性能越好；AUC 的值越接近 0.5，表示模型的性能没有比随机猜测好多少；如果 AUC 小于 0.5，通常意味着模型做出的预测与实际情况相反。</p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/12/11/AI/deepspeed/",
            "url": "http://qianqiu-cell.github.io/2024/12/11/AI/deepspeed/",
            "title": "Deepspeed",
            "date_published": "2024-12-10T16:00:00.000Z",
            "content_html": "<p>参考连接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96ZXJvbG92ZXNlYS5naXRodWIuaW8vMjAyNC8wNS8xMi8lRTUlODglODYlRTUlQjglODMlRTUlQkMlOEYlRTglQUUlQUQlRTclQkIlODMlRUYlQkMlOUElRTQlQkElODYlRTglQTclQTNEZWVwc3BlZWQlRTQlQjglQUQlRTclOUElODRaZVJPMS0yLTMv\">https://zerolovesea.github.io/2024/05/12 / 分布式训练：了解 Deepspeed 中的 ZeRO1-2-3/</span></p>\n<h1 id=\"一-deepspeed介绍\"><a class=\"markdownIt-Anchor\" href=\"#一-deepspeed介绍\">#</a> 一、Deepspeed 介绍</h1>\n<p>  DeepSpeed 是微软推出的大规模模型分布式训练的工具，分布式训练场景目前主要分成三个策略：</p>\n<ul>\n<li>数据并行</li>\n<li>模型并行</li>\n<li>流水线并行</li>\n</ul>\n<p>  在数据并行的策略下，每个模型都需要跑一个完整的模型，这时就需要考虑训练模型占用的参数量。ZeRO 就是为了解决这个问题而诞生的。</p>\n<p>  ZeRO 的全称是 Zero Redundancy Optimizer，意为去除冗余的优化器。在分布式训练中，主要占用的参数主要分为了三个部分：<strong>模型参数（Parameters）</strong>，<strong>优化器状态（Optimizer States）</strong>，<strong>梯度 (Gradients)</strong>，他们三个简称为 <code>OPG</code> 。其中<strong>优化器状态</strong>会占据大约 2 倍参数量的显存空间，这取决于选择的优化器，也是整个训练中占据最大空间的部分。为了解决这个问题，ZeRO 提供了另一种思路：使用切片来达到时间换空间的效果。</p>\n<h1 id=\"二-zero的三个级别\"><a class=\"markdownIt-Anchor\" href=\"#二-zero的三个级别\">#</a> 二、ZeRO 的三个级别</h1>\n<p>  ZeRO 被分为了四个级别：</p>\n<ul>\n<li>ZeRO-0：不进行任何形式的状态分片，只把 DeepSpeed 当成数据并行分布式（DDP, Distributed Data Parallel）来用。</li>\n<li>ZeRO-1：<strong>对优化器状态进行拆分</strong>。显存消耗减少 4 倍，通信量与数据并行相同。</li>\n<li>ZeRO-2：在 ZeRO-1 的基础上，<strong>对梯度进行拆分</strong>。显存消耗减少 8 倍，通信量与数据并行相同。</li>\n<li>ZeRO-3：在 ZeRO-2 的基础上，<strong>对模型参数进行拆分</strong>。模型占用的显存被平均分配到每个 GPU 中，显存消耗量与数据并行的并行度成线性反比关系，但通信量会有些许增加。</li>\n</ul>\n<p>  论文中给出了三个阶段的显存消耗分布情况：</p>\n<p><img data-src=\"/images/AI/deepspeed/2.1.jpg\" alt=\"\"></p>\n<h2 id=\"21-zero-1\"><a class=\"markdownIt-Anchor\" href=\"#21-zero-1\">#</a> 2.1 ZeRO-1</h2>\n<p>  模型训练中，正向传播和反向传播并不会用到优化器状态，只有在梯度更新的时候才会使用梯度和优化器状态计算新参数。因此每个进程单独使用一段优化器状态，对各自进程的参数更新完之后，再把各个进程的模型参数合并形成完整的模型。</p>\n<p>  假设我们有 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>𝑁</mi><mi>𝑑</mi></msub></mrow><annotation encoding=\"application/x-tex\">𝑁_𝑑</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">d</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 个并行的进程，<strong>ZeRO-1 会将完整优化器的状态等分成 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>𝑁</mi><mi>𝑑</mi></msub></mrow><annotation encoding=\"application/x-tex\">𝑁_𝑑</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">d</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 份并储存在各个进程中</strong>。当反向传播完成之后，每个进程的优化器会对自己储存的优化器状态（包括 Momentum、Variance 与 FP32 Master Parameters）进行计算与更新。更新过后的 Partitioned FP32 Master Parameters 会通过 All-gather 传回到各个进程中。完成一次完整的参数更新。</p>\n<p>  通过 ZeRO-1 对优化器状态的分段化储存，7.5B 参数量的模型内存占用将由原始数据并行下的 120GB 缩减到 31.4GB。</p>\n<h2 id=\"22-zero-2\"><a class=\"markdownIt-Anchor\" href=\"#22-zero-2\">#</a> 2.2 ZeRO-2</h2>\n<p>  <strong>第二阶段中对梯度进行了拆分</strong>，在一个 Layer 的梯度都被计算出来后： 梯度通过 All-reduce 进行聚合， 聚合后的梯度只会被某一个进程用来更新参数，因此其它进程上的这段梯度不再被需要，可以立马释放掉。</p>\n<p>  通过 ZeRO-2 对梯度和优化器状态的分段化储存，7.5B 参数量的模型内存占用将由 ZeRO-1 中 31.4GB 进一步下降到 16.6GB。</p>\n<h2 id=\"22-zero-3\"><a class=\"markdownIt-Anchor\" href=\"#22-zero-3\">#</a> 2.2 ZeRO-3</h2>\n<p>  <strong>第三阶段就是对模型参数进行分割</strong>。在 ZeRO3 中，模型的每一层都被切片，每个进程存储权重张量的一部分。在前向和后向传播过程中（每个进程仍然看到不同的微批次数据），不同的进程交换它们所拥有的部分（按需进行参数通信），并计算激活函数和梯度。</p>\n<p>  初始化的时候。ZeRO-3 将一个模型中每个子层中的参数分片放到不同进程中，训练过程中，每个进程进行正常的正向 / 反向传播，然后通过 All-gather 进行汇总，构建成完整的模型。</p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/12/11/AI/else/",
            "url": "http://qianqiu-cell.github.io/2024/12/11/AI/else/",
            "title": "其他未学习的可用工具",
            "date_published": "2024-12-10T16:00:00.000Z",
            "content_html": "<ul>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL2FsbGVuYWkvZG9sbWE=\">dolma</span>: 包含三万亿 Token 的语言模型预训练研究开放语料库</li>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL2hwY2FpdGVjaC9Db2xvc3NhbEFJ\">ColossalAI</span>: 一个旨在使大型 AI 模型更便宜、更快速、更易获得的开源项目</li>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL05WSURJQS9UZW5zb3JSVC1MTE0=\">TensorRT-LLM</span>: 用于优化大型语言模型推理的 TensorRT 工具箱</li>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL2xhbmdjaGFpbi1haS9sYW5nY2hhaW4=\">langchain</span>: LangChain 是一个用于开发由大型语言模型（LLM）驱动的应用程序的框架。</li>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly9jbG91ZC5iYWlkdS5jb20vZG9jL0FJSEMvcy9BbHlvNDc2anI=\">AIAK</span>: AIAK 大模型训推加速套件是百舸推出的大模型 AI 加速能力，用来加速 Megatron、Megatron-Core 等训练框架的大语言模型。</li>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cubGxhbWFpbmRleC5haS8=\">llamaindex</span>: 一个将大语言模型（LLM）和外部数据连接在一起的工具。</li>\n</ul>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/11/01/AI/Qwen2.5-math/",
            "url": "http://qianqiu-cell.github.io/2024/11/01/AI/Qwen2.5-math/",
            "title": "Qwen2.5-Math",
            "date_published": "2024-10-31T16:00:00.000Z",
            "content_html": "<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI3NTkwMjc3L2FydGljbGUvZGV0YWlscy8xNDI0NjY0MTk=\">https://blog.csdn.net/qq_27590277/article/details/142466419</span></p>\n<p>等待学习的技术：Common Crawl、Fasttext、MinHash+LSH、MuggleMath、DotaMath、拒绝微调（RFT）、GRPO、13-gram matching、ChatLearn5</p>\n<h1 id=\"一-引言\"><a class=\"markdownIt-Anchor\" href=\"#一-引言\">#</a> 一、引言</h1>\n<p>  从 Qwen2.5-Math 的技术报告副标题：“Toward Mathematical Expert Model via Self-Improvement”，可以看出，Self-Improvement 是一个贯穿整个 Qwen2.5-Math 训练流程的重要方法。具体来说，在 Qwen2.5-Math 的训练中，从三个方面进行 Self-Improvement。</p>\n<ul>\n<li>\n<p>Pre-training: 用 Qwen2-Math-Instruct 来合成扩充预训练数据；</p>\n</li>\n<li>\n<p>Post-training: SFT 模型和奖励模型之间的交互迭代</p>\n</li>\n<li>\n<p>Inference：奖励模型用于指导采样</p>\n</li>\n</ul>\n<p>  整体开发 Qwen2-Math 和 Qwen2.5-Math 的流程如下：</p>\n<p><img data-src=\"/images/AI/Qwen2.5-math/1.1.png\" alt=\"\"></p>\n<ul>\n<li>\n<p>首先，Qwen2-Math base 模型在一个名为 <em>Qwen Math Corpus v1</em> 的高质量数学预训练数据集上进行训练，该数据集包含大约 7000 亿个 token。</p>\n</li>\n<li>\n<p>其次，训练了一个特定于数学的奖励模型 Qwen2-Math-RM，该模型来源于 Qwen2-Math-72B，以创建 Qwen2-Math-Instruct 模型。该奖励模型用于通过拒绝抽样构建监督微调 (SFT) 数据。此外，奖励模型在强化学习阶段起着关键作用，我们在 SFT 之后采用了群体相对策略优化 (GRPO) 。</p>\n</li>\n<li>\n<p>第三，利用 Qwen2-Math-72B-Instruct 模型，合成了额外的高质量数学预训练数据，为 <em>Qwen Math Corpus v2</em> 提供了基础。这个更新的语料库包含超过 1 万亿个令牌，并用于预训练 Qwen2.5-Math 模型。</p>\n</li>\n<li>\n<p>最后，与 Qwen2-Math-Instruct 模型的过程类似，构建了 Qwen2.5-Math-RM 和 Qwen2.5-Math-Instruct 模型。这个阶段的一个重要区别是，在训练 Qwen2.5-Math-Instruct 模型时，包含了英语和汉语的思维链 (CoT) 推理数据，以及工具集成推理 (TIR) 数据，而不是像 Qwen2-Math-Instruct 模型那样只使用英语的思维链 (CoT) 数据。</p>\n</li>\n</ul>\n<h1 id=\"二-qwen25-math-预训练\"><a class=\"markdownIt-Anchor\" href=\"#二-qwen25-math-预训练\">#</a> 二、Qwen2.5-Math 预训练</h1>\n<h2 id=\"21-qwen2-math-预训练流程\"><a class=\"markdownIt-Anchor\" href=\"#21-qwen2-math-预训练流程\">#</a> 2.1 Qwen2-Math 预训练流程</h2>\n<p>  在数学预训练中，主要关注的是构建一个富含数学内容的高质量数据集。该数据集包含各种各样的来源，包括<strong>与数学相关的网络文本、代码片段、百科全书、考试问题和 Qwen2 生成的合成数学数据</strong>。组装这个预训练数据集的过程包括几个关键步骤：<strong>数据召回、重复数据删除、过滤、数据合成的和数据混合的优化</strong>。最终整理的数据集构成了预训练的基础，被称为<em> Qwen Math Corpus v1</em>。使用 Qwen2-1.5B/7B/72B 初始化的 Qwen2-Math 基础模型，使用 Qwen2-1.5B/7B/72B 进行连续预训练。</p>\n<h2 id=\"22-v1-数据集的扩充\"><a class=\"markdownIt-Anchor\" href=\"#22-v1-数据集的扩充\">#</a> 2.2 v1 数据集的扩充</h2>\n<p>  一般语言模型在数学推理中的次优性能源于预训练过程中数学数据的不足。Qwen2-Math 的策略包括从 web 来源 (如<strong> Common Crawl</strong>) 中召回数学数据，以增加数据量。具体而言，使用高质量的数学种子数据和一般文本数据训练<strong> FastText 分类器</strong>。我们利用迭代训练与更多的数学数据，每个 epoch 不断提高分类器的性能。随后，<strong>重复数据删除技术，包括 MinHash</strong>，被用来过滤掉类似的数学文档。</p>\n<h2 id=\"23-v1-数据质量的提高\"><a class=\"markdownIt-Anchor\" href=\"#23-v1-数据质量的提高\">#</a> 2.3 v1 数据质量的提高</h2>\n<p>  在收集大量数学数据后，重点转向提高其质量。利用 Qwen2-0.5B-Instruct 模型，辅以 prompt engineering，来评估数据的质量。根据语言模型，<strong>获得更高分数的数据表明质量更高，将优先包含在最终数据集中</strong>。除了过滤掉低质量的数据之外，以已有的参考数据为基础，采用 Qwen2-72B-Instruct 模型来合成大量的数学预训练语料库，包括：(1) 从这些参考数据中提取已有的数学问答数据，(2) 直接生成新的数学问答对。</p>\n<h2 id=\"24-qwen25-math-预训练流程\"><a class=\"markdownIt-Anchor\" href=\"#24-qwen25-math-预训练流程\">#</a> 2.4 Qwen2.5-Math 预训练流程</h2>\n<p>  在 Qwen2-Math 基础模型训练之后，通过三个主要途径将其升级为 Qwen2.5-Math 模型:</p>\n<ul>\n<li>\n<p>(1) 利用 Qwen2-Math-72B-Instruct 模型，通过第 3 节描述的步骤进行进一步的后训练，合成额外的高质量数学预训练数据。</p>\n</li>\n<li>\n<p>(2) 收集了更多高质量的数学数据，特别是中文数据，这些数据来自多个召回周期的网络文档、书籍和代码库。通过这些努力，获得了用于对 Qwen2.5-Math-1.5B/7B/72B 进行预训练的数学语料库 <em>Qwen Math Corpus v2</em>。与 <em>Qwen Math Corpus v1</em> 相比，<em>Qwen Math Corpus v2</em> 的总令牌计数从 700B 上升到 1T 以上。</p>\n</li>\n<li>\n<p>(3) 利用 Qwen2.5 系列基本模型进行参数初始化，因为它们在语言理解、代码生成和文本推理方面表现出增强的能力。</p>\n</li>\n</ul>\n<h1 id=\"3-qwen25-math-后训练\"><a class=\"markdownIt-Anchor\" href=\"#3-qwen25-math-后训练\">#</a> 3 Qwen2.5-Math 后训练</h1>\n<p>  在完成广泛的数学预训练后，需要继续进行后训练，以进一步增强 Qwen-Math 的数学逻辑推理能力，<strong>特别是专注于思维链 (CoT) 和工具集成推理 (TIR)</strong>。其中包含两个关键挑战:</p>\n<ul>\n<li>\n<p>(1) 如何自动生成大量高质量和可靠的 CoT 和 TIR 数据</p>\n</li>\n<li>\n<p>(2) 如何有效地利用这些注释进行 SFT 和 RL</p>\n</li>\n</ul>\n<h2 id=\"31-监督微调sft\"><a class=\"markdownIt-Anchor\" href=\"#31-监督微调sft\">#</a> 3.1 监督微调（SFT）</h2>\n<p>  Qwen2.5-Math 构建了思维链 (CoT) 和工具集成推理 (TIR) 的专用数据集，并将这些数据集结合起来共同对模型进行监督微调。</p>\n<h3 id=\"311-思维链cot数据合成\"><a class=\"markdownIt-Anchor\" href=\"#311-思维链cot数据合成\">#</a> 3.1.1 思维链（CoT）数据合成</h3>\n<h4 id=\"1输入构造\"><a class=\"markdownIt-Anchor\" href=\"#1输入构造\">#</a> （1）输入构造</h4>\n<p>  思维链数据集包含了 58 万个英文和 50 万个中文数学问题的广泛集合，包括标注项和合成项。<strong>标注问题源自一些知名来源</strong>，例如 GSM8K、MATH 和 NuminaMath。同时增加了 K-12 问题集合的中文数学问题。<strong>合成问题是通过 MuggleMath 方法从标注问题演变而来的</strong>。为了在不同难度水平的问题复杂性上保持均衡分布，我们有效地利用了<strong>难度评分模型</strong>对问题集进行分类。</p>\n<h4 id=\"2输出构造\"><a class=\"markdownIt-Anchor\" href=\"#2输出构造\">#</a> （2）输出构造</h4>\n<p>  采用了一种迭代方法，利用拒绝采样，并结合奖励模型和标注答案，逐步提高响应的质量。<strong>在每次迭代中，当前最佳模型被用于为给定问题生成多个推理路径，从而扩展候选解决方案池。</strong></p>\n<ul>\n<li>\n<p>对于有标注答案的问题，从候选池中选择最终答案正确的前 k 个推理路径。</p>\n</li>\n<li>\n<p>对于缺乏明确答案的合成问题，实施加权多数投票机制，以推导出最合理的正确推理路径。从中选择获得最高奖励分数的前 k 个路径。</p>\n</li>\n</ul>\n<h3 id=\"312-工具集成推理tir数据合成\"><a class=\"markdownIt-Anchor\" href=\"#312-工具集成推理tir数据合成\">#</a> 3.1.2 工具集成推理（TIR）数据合成</h3>\n<p>  虽然 CoT 提示在提高大型语言模型的推理技能方面起着至关重要的作用，但它在<strong>实现计算准确性和处理复杂的数学或算法问题方面面临挑战</strong>。例如求二次方程的根或计算矩阵的特征值。为了克服这些限制并提高模型在精确计算、符号操作和算法推理方面的熟练程度，Qwen2.5-Math 开发了一个包含工具集成推理格式的数据集。<strong>这种格式的数据使模型能够在推理任务中利用 Python 解释器作为辅助资源</strong>。</p>\n<h4 id=\"1输入构造-2\"><a class=\"markdownIt-Anchor\" href=\"#1输入构造-2\">#</a> （1）输入构造</h4>\n<p>  工具集成推理数据集由 19 万个标注问题和 20.5 万个合成问题组成。<strong>标注问题来源于一些知名基准的训练集，包括 GSM8K、MATH、CollegeMath 和 NuminaMath</strong>。<strong>合成问题是通过采用 MuggleMath 和 DotaMath 中的技术生成的</strong>。此外，选择了 75 万个标注问题，使用 Qwen2-72B 模型翻译成中文，以增强模型在中文中的推理能力。</p>\n<h4 id=\"2输出构造-2\"><a class=\"markdownIt-Anchor\" href=\"#2输出构造-2\">#</a> （2）输出构造</h4>\n<p>  对于标注问题，<strong>采用在线拒绝微调（RFT）方法迭代生成工具集成推理路径，使其最终答案与参考答案一致</strong>。在每次 RFT 迭代中，<strong>使用当前最佳模型进行多次核采样，并在不同温度下增加样本数量</strong>。每次迭代后，为了增强数据多样性，我们<strong>对响应进行去重处理</strong>，得到的清理数据集将用于微调模型以进行下一次迭代。</p>\n<p>  对于合成问题，采用从在线 RFT 过程中得到的<strong>最佳模型生成推理样本</strong>。我们<strong>使用多数投票法选择最可能正确的推理路径</strong>，这些路径随后被纳入整体数据集。</p>\n<h2 id=\"32-奖励模型训练\"><a class=\"markdownIt-Anchor\" href=\"#32-奖励模型训练\">#</a> 3.2 奖励模型训练</h2>\n<p>  为了在选择监督微调数据和随后的强化学习训练阶段提供超出最终答案的监督信号，为 Qwen2-Math 和 Qwen2.5-Math 开发了一个数学奖励模型，分别称为 Qwen2-Math-RM 和 Qwen2.5-Math-RM。<strong>这些奖励模型专门设计用于在整个训练过程中指导模型，通过提供更细致的推理质量和中间步骤的反馈，最终促进更稳健的模型改进</strong>。</p>\n<h3 id=\"321-数据合成\"><a class=\"markdownIt-Anchor\" href=\"#321-数据合成\">#</a> 3.2.1 数据合成</h3>\n<p>  在 Qwen2-Math-RM 的开发过程中，使用了 206K 的英文数学问题，每个问题都搭配了从 Qwen2-Math 中抽取的 6 个答案。对于 Qwen2.5-Math-RM，进一步增强了其对中文和 TIR 模式的支持，使用了一个更加多样化的数据集对其进行训练，该数据集包含 361K 的英文数学问题和 257K 的中文数学问题，每个问题都附有从 Qwen2.5-Math 中抽取的 6 个答案。这一扩展确保了 Qwen2.5-Math-RM 能够充分胜任在更广泛的问题类型和语言范围内提供监督反馈的任务。</p>\n<p>  为了在答案之间建立偏好信号，检查了每个答案的正确性。正确答案的回答被标记为积极的，而错误答案的回答被标记为消极的，从而自然地在答案之间创建了一个排名关系。然后，过滤掉所有答案要么完全正确，要么完全错误的情况。为了避免只保留过于简单的数据的潜在缺点，使用来自各种中间版本和不同大小模型的响应来丰富数据集。该策略确保了输入数据难度的更均衡分布，并保持了正响应与负响应的均匀比例。</p>\n<h3 id=\"322-训练策略\"><a class=\"markdownIt-Anchor\" href=\"#322-训练策略\">#</a> 3.2.2 训练策略</h3>\n<p>  从监督微调模型初始化奖励模型。在架构方面，将最初用于下一个 token 预测的语言建模头替换为由两个线性层组成的标量值头。奖励模型训练数据集中的每个输入都与 6 个输出配对。如果有 k 个正样本，则其余 6 - k 个为负样本。奖励模型的损失函数可以表示为:</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi mathvariant=\"script\">L</mi><mrow><mi>r</mi><mi>m</mi></mrow></msub><mo stretchy=\"false\">(</mo><mi>θ</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mo>−</mo><mfrac><mn>1</mn><mrow><mi>k</mi><mo>×</mo><mo stretchy=\"false\">(</mo><mn>6</mn><mo>−</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mfrac><msub><mi>E</mi><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><msub><mi>y</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub><mo separator=\"true\">,</mo><msub><mi>y</mi><mrow><mi>n</mi><mi>e</mi><mi>g</mi></mrow></msub><mo stretchy=\"false\">)</mo><mo>∼</mo><mi>D</mi></mrow></msub><mrow><mo fence=\"true\">[</mo><mi>log</mi><mo>⁡</mo><mrow><mo fence=\"true\">(</mo><mi>σ</mi><mrow><mo fence=\"true\">(</mo><msub><mi>r</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><msub><mi>y</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub><mo stretchy=\"false\">)</mo><mo>−</mo><msub><mi>r</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><msub><mi>y</mi><mrow><mi>n</mi><mi>e</mi><mi>g</mi></mrow></msub><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo fence=\"true\">)</mo></mrow><mo fence=\"true\">)</mo></mrow><mo fence=\"true\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{L}_{rm}(\\theta)=-\\frac1{k\\times(6-k)}E_{(x,y_{pos},y_{neg})\\thicksim D}\\left[\\log\\left(\\sigma\\left(r_\\theta(x,y_{pos})-r_\\theta(x,y_{neg}))\\right)\\right)\\right]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathcal\">L</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal mtight\">m</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.25744em;vertical-align:-0.936em;\"></span><span class=\"mord\">−</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">6</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\">1</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.936em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34479999999999994em;\"><span style=\"top:-2.5198em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">x</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.16454285714285716em;\"><span style=\"top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">p</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2818857142857143em;\"><span></span></span></span></span></span></span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.16454285714285716em;\"><span style=\"top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2818857142857143em;\"><span></span></span></span></span></span></span><span class=\"mclose mtight\">)</span><span class=\"mrel amsrm mtight\">∼</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">D</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3775199999999999em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">[</span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">p</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">]</span></span></span></span></span></span></p>\n<p>其中，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>r</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">r_\\theta(x,y)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span> 表示奖励模型的输出，其中<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span> 表示问题输入，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span></span> 表示相应的输出。该损失函数没有将它们分解成多个单独的对并以成对的方式计算损失，而是采用列表方法直接计算有效对上的排名损失。该方法提高了培训的效率和效果。</p>\n<h2 id=\"33-增强学习\"><a class=\"markdownIt-Anchor\" href=\"#33-增强学习\">#</a> 3.3 增强学习</h2>\n<h3 id=\"331-输入选择\"><a class=\"markdownIt-Anchor\" href=\"#331-输入选择\">#</a> 3.3.1 输入选择</h3>\n<p>  用于强化学习训练的输入从奖励模型的训练集中选择。利用不同规模的监督微调模型为每个查询重新采样 8 个响应，并通过与标准答案进行比较，将每个响应分类为正确或不正确。保留 8 个响应中有 2 到 5 个正确答案的查询。少于 2 个正确答案的查询会被排除，因为这表明当前的数学模型缺乏从中学习的基本能力。同样，超过 5 个正确响应的查询也会被排除，因为模型在这些情况下已经表现出能力，无需进一步训练。最终，保留了 66K 个查询用于训练。</p>\n<h3 id=\"332-分组相对策略优化grpo\"><a class=\"markdownIt-Anchor\" href=\"#332-分组相对策略优化grpo\">#</a> 3.3.2 分组相对策略优化（GRPO）</h3>\n<p>  GRPO 是一种专门为大型语言模型设计的强化学习方法，避免了像 PPO 那样<strong>需要额外的值函数近似</strong>。GRPO 使用一组抽样输出的平均奖励作为基准来计算每个输出的优势。GRPO 的目标定义为:</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mtable rowspacing=\"0.24999999999999992em\" columnalign=\"right left\" columnspacing=\"0em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><msub><mi mathvariant=\"script\">J</mi><mrow><mi>G</mi><mi>R</mi><mi>P</mi><mi>O</mi></mrow></msub><mo stretchy=\"false\">(</mo><mi>θ</mi><mo stretchy=\"false\">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><msub><mi mathvariant=\"double-struck\">E</mi><mrow><mo stretchy=\"false\">[</mo><mi>q</mi><mo>∼</mo><mi>P</mi><mo stretchy=\"false\">(</mo><mi>Q</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mo stretchy=\"false\">{</mo><msub><mi>o</mi><mi>i</mi></msub><msubsup><mo stretchy=\"false\">}</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>G</mi></msubsup><mo>∼</mo><msub><mi>π</mi><msub><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msub></msub><mo stretchy=\"false\">(</mo><mi>O</mi><mi mathvariant=\"normal\">∣</mi><mi>q</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo></mrow></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mfrac><mn>1</mn><mi>G</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>G</mi></munderover><mfrac><mn>1</mn><mrow><mi mathvariant=\"normal\">∣</mi><msub><mi>o</mi><mi>i</mi></msub><mi mathvariant=\"normal\">∣</mi></mrow></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi mathvariant=\"normal\">∣</mi><msub><mi>o</mi><mi>i</mi></msub><mi mathvariant=\"normal\">∣</mi></mrow></munderover><mo stretchy=\"false\">{</mo><mi>min</mi><mo>⁡</mo><mo stretchy=\"false\">[</mo><mfrac><msubsup><mi>π</mi><mi>θ</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>t</mi></mrow></msubsup><msubsup><mi>π</mi><msub><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msub><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>t</mi></mrow></msubsup></mfrac><msub><mover accent=\"true\"><mi>A</mi><mo>^</mo></mover><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>t</mi></mrow></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">clip</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mfrac><msubsup><mi>π</mi><mi>θ</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>t</mi></mrow></msubsup><msubsup><mi>π</mi><msub><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msub><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>t</mi></mrow></msubsup></mfrac><mo separator=\"true\">,</mo><mn>1</mn><mo>−</mo><mi>ϵ</mi><mo separator=\"true\">,</mo><mn>1</mn><mo>+</mo><mi>ϵ</mi><mo stretchy=\"false\">)</mo><msub><mover accent=\"true\"><mi>A</mi><mo>^</mo></mover><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>t</mi></mrow></msub><mo stretchy=\"false\">]</mo><mo>−</mo><mi>β</mi><msub><mi mathvariant=\"double-struck\">D</mi><mrow><mi>K</mi><mi>L</mi></mrow></msub><mo stretchy=\"false\">[</mo><msub><mi>π</mi><mi>θ</mi></msub><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><msub><mi>π</mi><mi mathvariant=\"normal\">ref</mi><mo>⁡</mo></msub><mo stretchy=\"false\">]</mo><mo stretchy=\"false\">}</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding=\"application/x-tex\">\\begin{aligned}\\mathcal{J}_{GRPO}(\\theta)&amp;=\\mathbb{E}_{[q\\sim P(Q),\\{o_i\\}_{i=1}^G\\sim\\pi_{\\theta_{old}}(O|q)]}\\\\&amp;\\frac1G\\sum_{i=1}^G\\frac1{|o_i|}\\sum_{t=1}^{|o_i|}\\{\\min[\\frac{\\pi_\\theta^{i,t}}{\\pi_{\\theta_{old}}^{i,t}}\\hat{A}_{i,t},\\operatorname{clip}(\\frac{\\pi_\\theta^{i,t}}{\\pi_{\\theta_{old}}^{i,t}},1-\\epsilon,1+\\epsilon)\\hat{A}_{i,t}]-\\beta\\mathbb{D}_{KL}[\\pi_\\theta||\\pi_{\\operatorname{ref}}]\\}\\end{aligned}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:5.197578999999999em;vertical-align:-2.3487894999999996em;\"></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-r\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.8487894999999996em;\"><span style=\"top:-5.9697945em;\"><span class=\"pstrut\" style=\"height:3.961005em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.18472em;\">J</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">G</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">O</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.1898845000000007em;\"><span class=\"pstrut\" style=\"height:3.961005em;\"></span><span class=\"mord\"></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.3487894999999996em;\"><span></span></span></span></span></span><span class=\"col-align-l\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.8487894999999996em;\"><span style=\"top:-5.9697945em;\"><span class=\"pstrut\" style=\"height:3.961005em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.4617750000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">[</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span><span class=\"mrel mtight\">∼</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">Q</span><span class=\"mclose mtight\">)</span><span class=\"mpunct mtight\">,</span><span class=\"mopen mtight\">{</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">o</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mclose mtight\"><span class=\"mclose mtight\">}</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8328928571428571em;\"><span style=\"top:-2.177714285714286em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-2.8448em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">G</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3222857142857143em;\"><span></span></span></span></span></span></span><span class=\"mrel mtight\">∼</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">π</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.3487714285714287em;margin-left:-0.03588em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3448em;margin-left:-0.02778em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.69444em;\"></span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal mtight\">d</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34963999999999995em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4009714285714285em;\"><span></span></span></span></span></span></span><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">O</span><span class=\"mord mtight\">∣</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span><span class=\"mclose mtight\">)</span><span class=\"mclose mtight\">]</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5189049999999998em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.1898845000000007em;\"><span class=\"pstrut\" style=\"height:3.961005em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\">G</span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\">1</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.8283360000000002em;\"><span style=\"top:-1.872331em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3000050000000005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">G</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.277669em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\">o</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\">1</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.936em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.9610050000000003em;\"><span style=\"top:-1.882887em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.386005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">∣</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">o</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mord mtight\">∣</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.267113em;\"><span></span></span></span></span></span><span class=\"mopen\">{</span><span class=\"mop\">min</span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.63388em;\"><span style=\"top:-2.167428em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.942572em;\"><span style=\"top:-2.398692em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-left:-0.02778em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal mtight\">d</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.1809080000000005em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.40716799999999986em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.6913080000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.942572em;\"><span style=\"top:-2.3986920000000005em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span><span style=\"top:-3.1809080000000005em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3013079999999999em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2397399999999998em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9467699999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">A</span></span></span><span style=\"top:-3.25233em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.11110999999999999em;\"><span class=\"mord\">^</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mord mathrm\">c</span><span class=\"mord mathrm\">l</span><span class=\"mord mathrm\">i</span><span class=\"mord mathrm\">p</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.63388em;\"><span style=\"top:-2.167428em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.942572em;\"><span style=\"top:-2.398692em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-left:-0.02778em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal mtight\">d</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.1809080000000005em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.40716799999999986em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.6913080000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.942572em;\"><span style=\"top:-2.3986920000000005em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span><span style=\"top:-3.1809080000000005em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3013079999999999em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2397399999999998em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\">ϵ</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\">ϵ</span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9467699999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">A</span></span></span><span style=\"top:-3.25233em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.11110999999999999em;\"><span class=\"mord\">^</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">D</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span><span class=\"mord mathnormal mtight\">L</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mop mtight\"><span class=\"mord mathrm mtight\">r</span><span class=\"mord mathrm mtight\">e</span><span class=\"mord mathrm mtight\" style=\"margin-right:0.07778em;\">f</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span><span class=\"mclose\">}</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.3487894999999996em;\"><span></span></span></span></span></span></span></span></span></span></span></span></p>\n<h3 id=\"333-奖励构造\"><a class=\"markdownIt-Anchor\" href=\"#333-奖励构造\">#</a> 3.3.3 奖励构造</h3>\n<p>  将基于规则的验证者和奖励模型的奖励结合起来，形成整体的奖励信号。基于规则的验证器从每个响应中提取潜在答案，并将其与标准答案进行比较。</p>\n<p>  将奖励模型的输出记为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>r</mi><mi>m</mi></msub><mo>∈</mo><mi mathvariant=\"double-struck\">R</mi></mrow><annotation encoding=\"application/x-tex\">r_{m}∈\\mathbb{R}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6891em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68889em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">R</span></span></span></span></span>，基于规则的验证器的稀疏奖励记为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>r</mi><mi>v</mi></msub><mo>∈</mo><mrow><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn></mrow></mrow><annotation encoding=\"application/x-tex\">r_{v}\\in{0,1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6891em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8388800000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span></span></span></span></span>，则总体奖励计算如下:</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mtable rowspacing=\"0.24999999999999992em\" columnalign=\"right\" columnspacing=\"\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mi>r</mi><mo>=</mo><mi>σ</mi><mo stretchy=\"false\">(</mo><mi>α</mi><mo>⋅</mo><msub><mi>r</mi><mi>m</mi></msub><mo stretchy=\"false\">)</mo><mo>+</mo><mo stretchy=\"false\">(</mo><msub><mi>r</mi><mi>v</mi></msub><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding=\"application/x-tex\">\\begin{aligned}r=\\sigma(\\alpha\\cdot r_m)+(r_v-1)\\end{aligned}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.5000000000000002em;vertical-align:-0.5000000000000002em;\"></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-r\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1em;\"><span style=\"top:-3.16em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5000000000000002em;\"><span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p>  这种形成机制确保正确的反应始终比错误的反应获得更高的总体奖励。在每个正确和不正确的组中，根据奖励模型的分数对回答进行排名。特别是在复杂问题中。</p>\n<h3 id=\"334-实现\"><a class=\"markdownIt-Anchor\" href=\"#334-实现\">#</a> 3.3.4 实现</h3>\n<p>  实验是基于开源 RLHF 框架 ChatLearn5 实现的。所有不同参数大小的策略模型都使用相同的奖励模型进行训练。为每个查询采样 32 个响应。所有模型都使用 512 全局批大小进行训练。7B 和 72B 的学习率分别为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1</mn><mo>×</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>5</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">1\\times10^{-5}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">5</span></span></span></span></span></span></span></span></span></span></span></span> 和<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>5</mn><mo>×</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>6</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">5\\times10^{-6}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">5</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">6</span></span></span></span></span></span></span></span></span></span></span></span>。所有训练的 KL 系数为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1</mn><mo>×</mo><mn>10</mn><mrow><mtext>−</mtext><mn>3</mn></mrow></mrow><annotation encoding=\"application/x-tex\">1\\times10{−3}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">1</span><span class=\"mord\">0</span><span class=\"mord\"><span class=\"mord\">−</span><span class=\"mord\">3</span></span></span></span></span>。屏蔽了 Python 执行器在工具集成推理的强化学习中提供的所有输出令牌。</p>\n<h1 id=\"4-去污\"><a class=\"markdownIt-Anchor\" href=\"#4-去污\">#</a> 4、去污</h1>\n<p>  去污是确保模型性能评估无偏的关键。Qwen2.5-math 使用 13-gram matching 排除了可能受污染的训练样本。为了提高匹配过程的准确性，执行文本规范化，删除不相关的标点和符号。为了进一步减少假阴性，特别是对于常见的数学表达式，引入了一个额外的标准：</p>\n<ul>\n<li>最长公共子序列的比率必须超过 0.6，才能认为样本被污染。对于预训练数据，针对 GSM8K 和 MATH 等数据集过滤可能受污染的样本。</li>\n</ul>\n<p>  在处理后训练数据时，包括 SFT 数据、RM 训练数据和 RL 查询集，在所有报告的评估数据集中排除任何潜在的污染问题或解决方案。这些评估数据集包括 GSM8K 、MATH 、Minerva MATH 、Gaokao 2023 En、Olympiad Bench、College Math、MMLU STEM 、Gaokao、CMATH、CN Middle School 24，AIME 24 和 AMC 23。在对污染样本的分析过程中，发现一些现有的训练数据集 (例如，MATH 训练数据集) 包含了与测试数据集中发现的问题具有高度相似的概念或结构的显著比例。虽然这些变化不是完全重复的，但它们可能会损害评估的完整性。因此，需要从训练语料库中排除这样的样本。</p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/10/21/AI/vllm/",
            "url": "http://qianqiu-cell.github.io/2024/10/21/AI/vllm/",
            "title": "vLLM",
            "date_published": "2024-10-20T16:00:00.000Z",
            "content_html": "<p>参考连接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL3ZsbG0tcHJvamVjdC92bGxt\">https://github.com/vllm-project/vllm</span></p>\n<h1 id=\"一-vllm介绍\"><a class=\"markdownIt-Anchor\" href=\"#一-vllm介绍\">#</a> 一、vLLM 介绍</h1>\n<p>  大型语言模型（LLMs）承诺将彻底改变我们在所有行业中使用人工智能的方式。然而，实际上部署这些模型是具有挑战性的，并且即使在昂贵的硬件上也可能出人意料地慢。</p>\n<p>  <strong>vLLM</strong> 是一个用于快速大型语言<strong>模型推理</strong>和服务的开源库。vLLM 利用了新注意力算法<strong> PagedAttention</strong>，它有效地管理注意力键和值（KV cache）。</p>\n<p>  配备 PagedAttention 的 vLLM 重新定义了大型语言模型服务的新标准：它提供的吞吐量比 HuggingFace Transformers 高出多达 24 倍，而无需对模型架构进行任何更改。</p>\n<h1 id=\"二-pagedattention原理\"><a class=\"markdownIt-Anchor\" href=\"#二-pagedattention原理\">#</a> 二、PagedAttention 原理</h1>\n<p>  在 vLLM 中，LLM 的性能受到内存的限制。在自回归解码过程中，所有输入到 LLM 的 token 都会生成它们的<strong>注意力键 (attention key)<strong> 和</strong>值张量 (value tensors)</strong>，而这些张量被保存在 GPU 内存中以生成下一个 token。这些缓存的键和值张量通常被称为<strong> KV cache</strong>。KV cache 的特点为：</p>\n<ul>\n<li><strong>大型</strong>：在 LLaMA-13B 中，单个序列可能占用高达 1.7GB。</li>\n<li><strong>动态</strong>：其大小取决于序列长度，这是高度可变且不可预测的。因此，有效管理 KV 缓存是一个重大挑战。由于碎片化和过度预留，现有系统浪费了 60% 至 80% 的内存。</li>\n</ul>\n<p>  为了解决这个问题，vLLM 引入了一种名为<strong> PagedAttention</strong> 的注意力算法，它受到了操作系统中虚拟内存和分页这一经典思想的启发。与传统的注意力算法不同，PagedAttention<strong> 允许在非连续的内存空间中存储连续的键和值</strong>。具体来说，PagedAttention<strong> 将每个序列的键值（KV）缓存划分为多个块，每个块包含固定数量的 token 的 keys 和 values</strong>。在注意力计算过程中，PagedAttention 内核能够高效地识别并获取这些块。</p>\n<p><img data-src=\"/images/AI/vLLM/2.1.gif\" alt=\"\" title=\"PagedAttention：KV cache 被划分成多个块。这些块在内存空间中不需要是连续的\"></p>\n<p>  因为块在内存中不需要是连续的，可以像操作系统的虚拟内存那样以更灵活的方式管理 keys 和 values：可以将块看作是分页，tokens 看作是字节，sequences 看作是进程。sequence 的连续逻辑块通过块表映射到不连续的物理块。随着新 token 的生成，物理块按需分配。</p>\n<p><img data-src=\"/images/AI/vLLM/2.2.gif\" alt=\"\" title=\"PagedAttention对一条request的生成过程示例\"></p>\n<p>  在 PagedAttention 中，<strong>内存浪费仅发生在序列的最后一个区块中</strong>。在实践中，这导致接近最优的内存使用，仅有不到 4% 的微小浪费。这种内存效率的提升被证明是非常有益的：它允许系统将更多的序列一起批处理，提高 GPU 利用率，从而显著提高吞吐量。</p>\n<p>  PagedAttention 还有另一个关键优势：高效的内存共享。例如，在<strong>并行采样</strong>中，可以从同一个 prompt 生成多个输出序列。在这种情况下，对该 prompt 的计算和内存可以在输出序列之间共享。</p>\n<p><img data-src=\"/images/AI/vLLM/2.3.gif\" alt=\"\" title=\"并行计算示例\"></p>\n<p>  PagedAttention 通过其块表自然地实现了内存共享。类似于进程共享物理页面的方式，不同序列在 PagedAttention 中可以通过将它们的逻辑块映射到同一个物理块来共享块。为了确保安全的共享，PagedAttention 会跟踪物理块的引用计数，并实现了写时复制（Copy-on-Write）机制。</p>\n<p><img data-src=\"/images/AI/vLLM/2.4.gif\" alt=\"\" title=\"对一条request生成多条输出的示例\"></p>\n<p>  PageAttention 的内存共享大大减少了复杂采样算法的内存开销，如并行采样和束搜索，将它们的内存使用量减少了高达 55%。这可以转化为吞吐量高达 2.2 倍的提升。这使得这些采样方法在 LLM 服务中变得实用。</p>\n<p>  PagedAttention 是 vLLM 背后的核心技术，vLLM 是我们的大型语言模型（LLM）推理和服务引擎，它支持多种模型，具有高性能和易于使用的界面。</p>\n<h1 id=\"三-开始使用vllm\"><a class=\"markdownIt-Anchor\" href=\"#三-开始使用vllm\">#</a> 三、开始使用 vLLM</h1>\n<p>  使用如下命令安装 vLLM：</p>\n<figure class=\"highlight sh\"><figcaption data-lang=\"sh\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>pip <span class=\"token function\">install</span> vllm</pre></td></tr></table></figure><p>  vLLM 可以用于离线推理和在线服务。要使用 vLLM 进行离线推理，可以在 Python 脚本中导入 vLLM 并使用 LLM 类：</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">from</span> vllm <span class=\"token keyword\">import</span> LLM<span class=\"token punctuation\">,</span> SamplingParams</pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>prompts <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token string\">\"Hello, my name is\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token string\">\"The president of the United States is\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token string\">\"The capital of France is\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token string\">\"The future of AI is\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>sampling_params <span class=\"token operator\">=</span> SamplingParams<span class=\"token punctuation\">(</span>temperature<span class=\"token operator\">=</span><span class=\"token number\">0.8</span><span class=\"token punctuation\">,</span> top_p<span class=\"token operator\">=</span><span class=\"token number\">0.95</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>llm <span class=\"token operator\">=</span> LLM<span class=\"token punctuation\">(</span>model<span class=\"token operator\">=</span><span class=\"token string\">\"facebook/opt-125m\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>outputs <span class=\"token operator\">=</span> llm<span class=\"token punctuation\">.</span>generate<span class=\"token punctuation\">(</span>prompts<span class=\"token punctuation\">,</span> sampling_params<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre></pre></td></tr><tr><td data-num=\"16\"></td><td><pre><span class=\"token keyword\">for</span> output <span class=\"token keyword\">in</span> outputs<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>    prompt <span class=\"token operator\">=</span> output<span class=\"token punctuation\">.</span>prompt</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    generated_text <span class=\"token operator\">=</span> output<span class=\"token punctuation\">.</span>outputs<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>text</pre></td></tr><tr><td data-num=\"19\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Prompt: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>prompt<span class=\"token conversion-option punctuation\">!r</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">, Generated text: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>generated_text<span class=\"token conversion-option punctuation\">!r</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>  运行结果如下：</p>\n<figure class=\"highlight sh\"><figcaption data-lang=\"sh\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token punctuation\">(</span>vllm<span class=\"token punctuation\">)</span> ember@ember-Victus-by-HP-Laptop:~/project/python/1_vllm$ python main.py </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>INFO <span class=\"token number\">10</span>-30 <span class=\"token number\">17</span>:14:44 llm_engine.py:237<span class=\"token punctuation\">]</span> Initializing an LLM engine <span class=\"token punctuation\">(</span>v0.6.3.post1<span class=\"token punctuation\">)</span> with config: <span class=\"token assign-left variable\">model</span><span class=\"token operator\">=</span><span class=\"token string\">'facebook/opt-125m'</span>, <span class=\"token assign-left variable\">speculative_config</span><span class=\"token operator\">=</span>None, <span class=\"token assign-left variable\">tokenizer</span><span class=\"token operator\">=</span><span class=\"token string\">'facebook/opt-125m'</span>, <span class=\"token assign-left variable\">skip_tokenizer_init</span><span class=\"token operator\">=</span>False, <span class=\"token assign-left variable\">tokenizer_mode</span><span class=\"token operator\">=</span>auto, <span class=\"token assign-left variable\">revision</span><span class=\"token operator\">=</span>None, <span class=\"token assign-left variable\">override_neuron_config</span><span class=\"token operator\">=</span>None, <span class=\"token assign-left variable\">rope_scaling</span><span class=\"token operator\">=</span>None, <span class=\"token assign-left variable\">rope_theta</span><span class=\"token operator\">=</span>None, <span class=\"token assign-left variable\">tokenizer_revision</span><span class=\"token operator\">=</span>None, <span class=\"token assign-left variable\">trust_remote_code</span><span class=\"token operator\">=</span>False, <span class=\"token assign-left variable\">dtype</span><span class=\"token operator\">=</span>torch.float16, <span class=\"token assign-left variable\">max_seq_len</span><span class=\"token operator\">=</span><span class=\"token number\">2048</span>, <span class=\"token assign-left variable\">download_dir</span><span class=\"token operator\">=</span>None, <span class=\"token assign-left variable\">load_format</span><span class=\"token operator\">=</span>LoadFormat.AUTO, <span class=\"token assign-left variable\">tensor_parallel_size</span><span class=\"token operator\">=</span><span class=\"token number\">1</span>, <span class=\"token assign-left variable\">pipeline_parallel_size</span><span class=\"token operator\">=</span><span class=\"token number\">1</span>, <span class=\"token assign-left variable\">disable_custom_all_reduce</span><span class=\"token operator\">=</span>False, <span class=\"token assign-left variable\">quantization</span><span class=\"token operator\">=</span>None, <span class=\"token assign-left variable\">enforce_eager</span><span class=\"token operator\">=</span>False, <span class=\"token assign-left variable\">kv_cache_dtype</span><span class=\"token operator\">=</span>auto, <span class=\"token assign-left variable\">quantization_param_path</span><span class=\"token operator\">=</span>None, <span class=\"token assign-left variable\">device_config</span><span class=\"token operator\">=</span>cuda, <span class=\"token assign-left variable\">decoding_config</span><span class=\"token operator\">=</span>DecodingConfig<span class=\"token punctuation\">(</span>guided_decoding_backend<span class=\"token operator\">=</span><span class=\"token string\">'outlines'</span><span class=\"token punctuation\">)</span>, <span class=\"token assign-left variable\">observability_config</span><span class=\"token operator\">=</span>ObservabilityConfig<span class=\"token punctuation\">(</span>otlp_traces_endpoint<span class=\"token operator\">=</span>None, <span class=\"token assign-left variable\">collect_model_forward_time</span><span class=\"token operator\">=</span>False, <span class=\"token assign-left variable\">collect_model_execute_time</span><span class=\"token operator\">=</span>False<span class=\"token punctuation\">)</span>, <span class=\"token assign-left variable\">seed</span><span class=\"token operator\">=</span><span class=\"token number\">0</span>, <span class=\"token assign-left variable\">served_model_name</span><span class=\"token operator\">=</span>facebook/opt-125m, <span class=\"token assign-left variable\">num_scheduler_steps</span><span class=\"token operator\">=</span><span class=\"token number\">1</span>, <span class=\"token assign-left variable\">chunked_prefill_enabled</span><span class=\"token operator\">=</span>False <span class=\"token assign-left variable\">multi_step_stream_outputs</span><span class=\"token operator\">=</span>True, <span class=\"token assign-left variable\">enable_prefix_caching</span><span class=\"token operator\">=</span>False, <span class=\"token assign-left variable\">use_async_output_proc</span><span class=\"token operator\">=</span>True, <span class=\"token assign-left variable\">use_cached_outputs</span><span class=\"token operator\">=</span>False, <span class=\"token assign-left variable\">mm_processor_kwargs</span><span class=\"token operator\">=</span>None<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>INFO <span class=\"token number\">10</span>-30 <span class=\"token number\">17</span>:14:45 model_runner.py:1056<span class=\"token punctuation\">]</span> Starting to load model facebook/opt-125m<span class=\"token punctuation\">..</span>.</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>INFO <span class=\"token number\">10</span>-30 <span class=\"token number\">17</span>:14:45 weight_utils.py:243<span class=\"token punctuation\">]</span> Using model weights <span class=\"token function\">format</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'*.bin'</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>Loading pt checkpoint shards:   <span class=\"token number\">0</span>% Completed <span class=\"token operator\">|</span> <span class=\"token number\">0</span>/1 <span class=\"token punctuation\">[</span>00:0<span class=\"token operator\"><span class=\"token file-descriptor important\">0</span>&lt;</span>?, ?it/s<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>/home/ember/anaconda3/envs/vllm/lib/python3.10/site-packages/vllm/model_executor/model_loader/weight_utils.py:425: FutureWarning: You are using <span class=\"token variable\"><span class=\"token variable\">`</span>torch.load<span class=\"token variable\">`</span></span> with <span class=\"token variable\"><span class=\"token variable\">`</span><span class=\"token assign-left variable\">weights_only</span><span class=\"token operator\">=</span>False<span class=\"token variable\">`</span></span> <span class=\"token punctuation\">(</span>the current default value<span class=\"token punctuation\">)</span>, <span class=\"token function\">which</span> uses the default pickle module implicitly. It is possible to construct malicious pickle data <span class=\"token function\">which</span> will execute arbitrary code during unpickling <span class=\"token punctuation\">(</span>See https://github.com/pytorch/pytorch/blob/main/SECURITY.md<span class=\"token comment\">#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>  state <span class=\"token operator\">=</span> torch.load<span class=\"token punctuation\">(</span>bin_file, <span class=\"token assign-left variable\">map_location</span><span class=\"token operator\">=</span><span class=\"token string\">\"cpu\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>Loading pt checkpoint shards: <span class=\"token number\">100</span>% Completed <span class=\"token operator\">|</span> <span class=\"token number\">1</span>/1 <span class=\"token punctuation\">[</span>00:0<span class=\"token operator\"><span class=\"token file-descriptor important\">0</span>&lt;</span>00:00,  <span class=\"token number\">2</span>.61it/s<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>Loading pt checkpoint shards: <span class=\"token number\">100</span>% Completed <span class=\"token operator\">|</span> <span class=\"token number\">1</span>/1 <span class=\"token punctuation\">[</span>00:0<span class=\"token operator\"><span class=\"token file-descriptor important\">0</span>&lt;</span>00:00,  <span class=\"token number\">2</span>.61it/s<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>INFO <span class=\"token number\">10</span>-30 <span class=\"token number\">17</span>:14:46 model_runner.py:1067<span class=\"token punctuation\">]</span> Loading model weights took <span class=\"token number\">0.2389</span> GB</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>INFO <span class=\"token number\">10</span>-30 <span class=\"token number\">17</span>:14:46 gpu_executor.py:122<span class=\"token punctuation\">]</span> <span class=\"token comment\"># GPU blocks: 4774, # CPU blocks: 7281</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>INFO <span class=\"token number\">10</span>-30 <span class=\"token number\">17</span>:14:46 gpu_executor.py:126<span class=\"token punctuation\">]</span> Maximum concurrency <span class=\"token keyword\">for</span> <span class=\"token number\">2048</span> tokens per request: <span class=\"token number\">37</span>.30x</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>INFO <span class=\"token number\">10</span>-30 <span class=\"token number\">17</span>:14:48 model_runner.py:1395<span class=\"token punctuation\">]</span> Capturing the model <span class=\"token keyword\">for</span> CUDA graphs. This may lead to unexpected consequences <span class=\"token keyword\">if</span> the model is not static. To run the model <span class=\"token keyword\">in</span> eager mode, <span class=\"token builtin class-name\">set</span> <span class=\"token string\">'enforce_eager=True'</span> or use <span class=\"token string\">'--enforce-eager'</span> <span class=\"token keyword\">in</span> the CLI.</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>INFO <span class=\"token number\">10</span>-30 <span class=\"token number\">17</span>:14:48 model_runner.py:1399<span class=\"token punctuation\">]</span> CUDA graphs can take additional <span class=\"token number\">1</span>~3 GiB memory per GPU. If you are running out of memory, consider decreasing <span class=\"token variable\"><span class=\"token variable\">`</span>gpu_memory_utilization<span class=\"token variable\">`</span></span> or enforcing eager mode. You can also reduce the <span class=\"token variable\"><span class=\"token variable\">`</span>max_num_seqs<span class=\"token variable\">`</span></span> as needed to decrease memory usage.</pre></td></tr><tr><td data-num=\"16\"></td><td><pre>INFO <span class=\"token number\">10</span>-30 <span class=\"token number\">17</span>:14:58 model_runner.py:1523<span class=\"token punctuation\">]</span> Graph capturing finished <span class=\"token keyword\">in</span> <span class=\"token number\">10</span> secs.</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>Processed prompts: <span class=\"token number\">100</span>%<span class=\"token operator\">|</span>████<span class=\"token operator\">|</span> <span class=\"token number\">4</span>/4 <span class=\"token punctuation\">[</span>00:0<span class=\"token operator\"><span class=\"token file-descriptor important\">0</span>&lt;</span>00:00, <span class=\"token number\">29</span>.75it/s, est. speed input: <span class=\"token number\">193.42</span> toks/s, output: <span class=\"token number\">476.10</span> toks/s<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>Prompt: <span class=\"token string\">'Hello, my name is'</span>, Generated text: <span class=\"token string\">\" Joel. I'm a 24 year old software developer and I'm looking for a\"</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>Prompt: <span class=\"token string\">'The president of the United States is'</span>, Generated text: <span class=\"token string\">', in my opinion, the worst person ever to be president.\\n> In'</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>Prompt: <span class=\"token string\">'The capital of France is'</span>, Generated text: <span class=\"token string\">' wrong because a country is full of self-doubts about its own future'</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>Prompt: <span class=\"token string\">'The future of AI is'</span>, Generated text: <span class=\"token string\">' in AI and a lot of it is just making sure everyone has an AI that'</span></pre></td></tr></table></figure>",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/10/05/AI/MAE/",
            "url": "http://qianqiu-cell.github.io/2024/10/05/AI/MAE/",
            "title": "MAE",
            "date_published": "2024-10-04T16:00:00.000Z",
            "content_html": "<h1 id=\"一-mae概述\"><a class=\"markdownIt-Anchor\" href=\"#一-mae概述\">#</a> 一、MAE 概述</h1>\n<p>  深度学习在计算机视觉领域取得了显著进展，但随着模型规模的增长，对数据的需求也在增加。在自然语言处理（ <code>NLP</code> ）领域，通过自监督预训练的方法（如 <code>BERT</code>  和 <code>GPT</code> ）成功解决了数据需求问题，这些方法通过预测数据中被 <code>masked</code>  的部分来训练模型。然而，在计算机视觉领域，尽管存在相关研究，自监督学习方法的发展仍然滞后于 <code>NLP</code> 。</p>\n<p>  这篇论文使用掩码自编码器 ( <code>masked autoencoders (MAE)</code> ) 进行自监督学习。这种类型自监督学习的另一个著名的例子就是 <code>BERT</code> 。</p>\n<p>  对于 <code>BERT</code>  模型而言，一个 <code>sentence</code>  中间盖住一些 <code>tokens</code> ，让模型去预测，令得到的预测结果与真实的 <code>tokens</code>  之间的误差作为损失。它告诉了我们直接 <code>reconstruct sentence</code>  也可以做到很 <code>work</code> 。</p>\n<p>  对于 <code>MAE</code>  模型而言，一个 <code>image</code>  中间盖住一些  <code>patches</code> ，让模型去预测，令得到的预测结果与真实的 <code>image patches</code>  之间的误差作为损失。它告诉了我们直接 <code>reconstruct image</code>  原图也可以做到很 <code>work</code> 。</p>\n<p>  为什么 <code>BERT (2018)</code>  提出这么久以后，直到 <code>BEIT (2021.6)</code>  和 <code>MAE (2021.11)</code>  之前，一直在 <code>CV</code>  领域都没有一个很类似的 <code>CV BERT</code>  出现？这里 <code>Kaiming</code>  提出了 3 条看法：</p>\n<ul>\n<li><strong>CV 和 NLP 主流架构不同</strong>：直到 <code>ViT (2020.12)</code>  出现之前， <code>CV</code>  的主流架构一直是以<strong>卷积神经网络</strong>为主， <code>NLP</code>  的主流架构一直是以 <code>Transformer</code>  为主。卷积核作用在一个个的 <code>grid</code>  上面，直观来讲没法产生像 <code>Transformer</code>  一样的 <code>token</code>  的概念，也就是说如果我们只使用卷积网络，那么 <code>image token</code>  概念的建立就不那么直观。所以，像 <code>Transformer</code>  那样在 <code>token</code>  的基础上进行自监督学习就不太适用，这是第一个难点。</li>\n<li><strong>语言和图片 (视频) 的信息密度不同</strong>：语言是人类造就的信号，它 <code>highly semantic</code> ， <code>information-dense</code> 。而图片 (视频) 是自然产生的信号，它 <code>heavy spatial redundancy</code> 。即挡住图片的一部分 <code>patches</code> ，可以很容易地通过看它周围的 <code>patches</code>  而想象出它的样子来。所以，语言和图像，一个信息密度高，一个信息密度低，这是第二个难点。解决的办法是什么呢？作者提出了一个简单的策略：<strong>即挡住图片的 patches 的比例高一些</strong>。比如之前你挡住一张图片的 <code>30%</code>  的 <code>patches</code> ，能够轻松通过周围的 <code>patches</code>  预测出来；那现在如果<strong>挡住图片的 90% 的 patches</strong>，还能够轻松通过周围的 <code>patches</code>  预测出来吗？</li>\n<li><strong>AutoEncoder 里面的 Decoder 部分在 CV 和 NLP 中充当的角色不同</strong>：在 <code>CV</code>  领域， <code>Decoder</code>  的作用是重建 <code>image pixels</code> ，所以 <code>Decoder</code>  的输出语义级别很低。在 <code>NLP</code>  领域， <code>Decoder</code>  的作用是重建 <code>sentence words</code> ，所以 <code>Decoder</code>  的输出语义级别很丰富。</li>\n</ul>\n<p><img data-src=\"/images/AI/MAE/0.0.png\" alt=\"\"></p>\n<p>  基于以上分析，作者提出了 <code>MAE</code>  方法，其架构如上图所示。 <code>MAE</code>  的方法很简单： <code>Mask</code>  掉输入图像的随机的 <code>patches</code>  并重建它们。它基于两个核心理念：</p>\n<ul>\n<li>作者开发了一个非对称 <code>Encoder-Decoder</code>  架构，其中一个 <code>Encoder</code>  只对可见的 <code>patch</code>  子集进行操作 (<strong>即没有被 mask 掉的 token</strong>)，另一个简单轻量化的 <code>Decoder</code>  可以<strong>从潜在表征和被 masked 掉的 token 重建原始图像</strong>。</li>\n<li>研究人员进一步发现，<strong>Mask 掉大部分输入图像</strong> (例如 <code>75%</code> ) 会产生重要且有意义的自监督任务。</li>\n</ul>\n<p>  结合这两种设计，就能高效地训练大型模型：提升训练速度至 3 倍或更多，并提高准确性。</p>\n<p>   <code>MAE</code>  方法严格来讲属于一种去噪自编码器 ( <code>Denoising Auto-Encoders (DAE)</code> )， <code>DAE</code>  是一类自动编码器，它破坏输入信号，并学会重构原始的、未被破坏的信号。 <code>MAE</code>  的  <code>Encoder</code>  和 <code>Decoder</code>  结构不同，是非对称式的。 <code>Encoder</code>  将输入编码为 <code>latent representation</code> ，而 <code>Decoder</code>  将从 <code>latent representation</code>  重建原始信号。</p>\n<p>   <code>MAE</code>  和 <code>ViT</code>  的做法一致，将图像划分成规则的，不重叠的 <code>patches</code> 。然后按照均匀分布不重复地选择一些 <code>patches</code>  并且 <code>mask</code>  掉剩余的 <code>patches</code> 。作者采用的 <code>mask ratio</code>  足够高，因此大大减小了 <code>patches</code>  的冗余信息，使得在这种情况下重建 <code>images</code>  不那么容易。</p>\n<h1 id=\"二-mae方法\"><a class=\"markdownIt-Anchor\" href=\"#二-mae方法\">#</a> 二、MAE 方法</h1>\n<h2 id=\"21-mask\"><a class=\"markdownIt-Anchor\" href=\"#21-mask\">#</a> 2.1 Mask</h2>\n<p>  根据 <code>ViT</code> ， <code>MAE</code>  将图像划分为规则的不重叠的 <code>patch</code> 。然后对 <code>patch</code>  的子集进行采样，并 <code>mask</code>  (即删除) 剩余的 <code>patch</code> 。 <code>MAE</code>  的采样策略很简单：对随机 <code>patch</code>  进行采样，遵循均匀分布。简单地称之为 “随机抽样”。</p>\n<p>   <code>具有高</code>  mask ratio`(即去除斑块的比例) 的随机采样在很大程度上消除了冗余，从而创建了一个不能通过从可见的邻近斑块外推轻松解决的任务。均匀分布防止了潜在的中心偏差 (即在图像中心附近有更多的掩蔽斑块)。最后，高度稀疏的输入为设计高效的编码器创造了机会。</p>\n<h2 id=\"22-mae-encoder\"><a class=\"markdownIt-Anchor\" href=\"#22-mae-encoder\">#</a> 2.2 MAE encoder</h2>\n<p>   <code>MAE</code>  的编码器是 <code>ViT</code> ，但只应用于可见的，未 <code>mask</code>  的 <code>patches</code> 。就像在标准 <code>ViT</code>  中一样， <code>MAE</code>  的编码器通过添加 <code>positional embedding</code>  的线性投影获得每个 <code>patch</code>  的 <code>embedding</code> ，然后通过一系列 <code>transformer</code>  块处理结果集。 <code>MAE</code>  的编码器只在完整 <code>patches</code>  的一小部分 (例如，25%) 上运行。 <code>masked patches</code>  被移除；且不使用掩码令牌。这允许 <code>MAE</code>  只用一小部分的计算和内存<strong>训练非常大的编码器</strong>。完整的 <code>patches</code>  由一个轻量级解码器处理。</p>\n<h2 id=\"23-mae-decoder\"><a class=\"markdownIt-Anchor\" href=\"#23-mae-decoder\">#</a> 2.3 MAE decoder</h2>\n<p>   <code>MAE</code>  解码器的输入是一个完整的 <code>tokens</code> ，由 (i) 编码的 <code>visible patches</code>  和 (ii) <code>masked tokens</code>  组成。每个 <code>masked tokens</code>  是一个共享的、可学习的向量，表示待预测的 <code>missing patch</code> 。为这个完整 <code>tokens</code>  中的所有 <code>token</code>  添加 <code>position embedding</code> ；解码器有另一系列的 <code>transformer</code>  块。</p>\n<p>   <code>MAE</code>  解码器<strong>仅在预训练期间用于执行图像重建任务 (仅编码器用于生成用于识别的图像表示)</strong>。因此，<strong>解码器架构可以以一种独立于编码器设计的方式灵活设计</strong>。 <code>MAE</code>  用非常小的解码器做实验，比编码器更窄更浅。例如，与编码器相比，我们的默认解码器每个令牌的计算量 &lt; 10%。通过这种不对称设计，整个标记集只由轻量级解码器处理，<strong>这大大减少了预训练时间</strong>。</p>\n<h2 id=\"24-reconstruction-target\"><a class=\"markdownIt-Anchor\" href=\"#24-reconstruction-target\">#</a> 2.4 Reconstruction target</h2>\n<p>   <code>MAE</code>  通过预测每个 <code>masked patch</code>  的像素值来重构输入。解码器输出中的每个元素都是表示一个 <code>patch</code>  的像素值向量。解码器的最后一层是线性投影，<strong>其输出通道的数量等于 <code>patch</code>  中的像素值的数量</strong>。 <code>MAE</code>  的<strong>损失函数在像素空间中计算重建图像和原始图像之间的均方误差</strong>（ <code>MSE</code> ）。 <code>MAE</code>  只计算 <code>masked patches</code>  上的损失，类似于 <code>BERT</code> 。</p>\n<p>   <code>MAE</code>  还研究了一种变体，其重建目标是每个 <code>masked patch</code>  的归一化像素值。具体地说， <code>MAE</code>  计算一个 <code>patch</code>  中所有像素的平均值和标准差，并使用它们来归一化该 <code>patch</code> 。在 <code>MAE</code>  的实验中，使用归一化像素作为重建目标改善了表示质量。</p>\n<h2 id=\"25-simple-implementation\"><a class=\"markdownIt-Anchor\" href=\"#25-simple-implementation\">#</a> 2.5 Simple implementation</h2>\n<p>   <code>MAE</code>  的预训练可以有效地实现，并且重要的是，不需要任何专门的稀疏操作。</p>\n<ul>\n<li>首先，我们为每个输入 <code>patch</code>  生成一个 <code>token</code> （通过添加 <code>position embedding</code>  的线性投影）。</li>\n<li>接下来，我们随机打乱 <code>token</code>  列表，并根据 <code>mask ratio</code>  删除列表的最后一部分。此过程为编码器生成一个小的 <code>token</code>  子集。</li>\n<li>在编码之后，我们将 <code>mask token</code>  的列表添加至编码的 <code>token</code>  列表，并还原此完整的列表（反转随机打乱操作），以将所有 <code>token</code>  与其目的对齐。</li>\n<li>解码器应用于该完整列表（添加了位置嵌入）。</li>\n</ul>\n<p>  如上所述，不需要稀疏操作。由于打乱和还原操作是快速的，因此这种简单的实现引入了可忽略的开销。</p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/09/21/AI/ViT/",
            "url": "http://qianqiu-cell.github.io/2024/09/21/AI/ViT/",
            "title": "ViT",
            "date_published": "2024-09-20T16:00:00.000Z",
            "content_html": "<h1 id=\"一-引言\"><a class=\"markdownIt-Anchor\" href=\"#一-引言\">#</a> 一、引言</h1>\n<p>  虽然  <code>Transformer</code>  架构已成为  <code>NLP</code>  任务的首选模型，但它在  <code>CV</code>  中的应用仍然有限。在视觉上，注意力要么与卷积网络结合使用，要么用于替换卷积网络的某些组件，同时保持其整体结构。而这种对  <code>CNNs</code>  的依赖是不必要的，直接应用于图像块序列  ( <code>sequences of image patches</code> ) 的纯  <code>Transformer</code>  可以很好地执行图像分类任务。当对大量数据进行预训练并迁移到多个中小型图像识别基准时 ( <code>ImageNet</code> 、 <code>CIFAR-100</code> 、 <code>VTAB</code>  等)，与  <code>SOTA</code>  的  <code>CNN</code>  相比， <code>Vision Transformer (ViT)</code>  可获得更优异的结果，同时仅需更少的训练资源。</p>\n<h1 id=\"二-方法\"><a class=\"markdownIt-Anchor\" href=\"#二-方法\">#</a> 二、方法</h1>\n<p>  在模型设计中， <code>ViT</code>  尽可能地遵循原始  <code>Transformer</code> 。 这种有意简单设置的优势在于，可扩展的 <code>NLP Transformer</code>  架构及其高效实现几乎可以开箱即用。</p>\n<p><img data-src=\"/images/AI/ViT/2.1.png\" alt=\"\"></p>\n<h2 id=\"21-图像块嵌入patch-embeddings\"><a class=\"markdownIt-Anchor\" href=\"#21-图像块嵌入patch-embeddings\">#</a> 2.1 图像块嵌入 (Patch Embeddings)</h2>\n<p>  模型概述如图 1 所示。标准 <code>Transformer</code>  使用一维标记嵌入序列 ( <code>Sequence of token embeddings</code> ) 作为输入。为了处理 <code>2D</code>  图像，将图像<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mi>H</mi><mo>×</mo><mi>W</mi><mo>×</mo><mi>C</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">x\\in \\mathbb{R}^{H\\times W\\times C}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.08125em;\">H</span><span class=\"mbin mtight\">×</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">W</span><span class=\"mbin mtight\">×</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">C</span></span></span></span></span></span></span></span></span></span></span></span>  <code>reshape</code>  为一个展平的 <code>2D patches</code>  序列</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>x</mi><mi>p</mi></msub><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mi>N</mi><mo>×</mo><mo stretchy=\"false\">(</mo><msup><mi>P</mi><mn>2</mn></msup><mo separator=\"true\">⋅</mo><mi>C</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">x_p \\in \\mathbb{R}^{N\\times (P^2·C)}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8252079999999999em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">p</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0369199999999998em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0369199999999998em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">×</span><span class=\"mopen mtight\">(</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913142857142857em;\"><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mpunct mtight\">⋅</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">C</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p>  其中 (H，W) 是原始图像的分辨率，C 是通道的数目，（P，P）是每个图像片的分辨率，并且<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><mo>=</mo><mi>H</mi><mi>W</mi><mi mathvariant=\"normal\">/</mi><msup><mi>P</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">N = HW/P^2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.064108em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord\">/</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span> 是得到图像 patch 的数，也是 <code>Transformer</code>  的有效输入序列长度。 <code>Transformer</code>  在其所有层中使用恒定的潜在向量大小 <code>D</code> ，因此 <code>ViT</code>  将 pathches 展平，并使用 ** 可训练的线性投影 (FC 层)** 将<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>P</mi><mn>2</mn></msup><mo separator=\"true\">⋅</mo><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">P^2·C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span></span> 映射到 <code>D</code>  维，同时保持图像 <code>patches</code>  数 <code>N</code>  不变。该投影的输出被称为 <code>patch embeddings</code> 。</p>\n<p>  上述投影输出即为图像块嵌入 (Patch Embeddings)，本质就是对每一个展平后的 <code>patch vector</code>  <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>p</mi></msub><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mi>N</mi><mo>×</mo><mo stretchy=\"false\">(</mo><msup><mi>P</mi><mn>2</mn></msup><mo separator=\"true\">⋅</mo><mi>C</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">x_p\\in \\mathbb{R}^{N\\times (P^2·C)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8252079999999999em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">p</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.9869199999999998em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9869199999999998em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">×</span><span class=\"mopen mtight\">(</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913142857142857em;\"><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mpunct mtight\">⋅</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">C</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span> 做一个线性变换 / 全连接层 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>P</mi><mn>2</mn></msup><mo separator=\"true\">⋅</mo><mi>C</mi><mo stretchy=\"false\">)</mo><mo>×</mo><mi>D</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">E\\in \\mathbb{R}^{(P^2·C)\\times D}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72243em;vertical-align:-0.0391em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.9869199999999998em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9869199999999998em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913142857142857em;\"><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mpunct mtight\">⋅</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">C</span><span class=\"mclose mtight\">)</span><span class=\"mbin mtight\">×</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">D</span></span></span></span></span></span></span></span></span></span></span></span>，由<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>P</mi><mn>2</mn></msup><mo>×</mo><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">P^2\\times C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.897438em;vertical-align:-0.08333em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span></span> 降维至<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>D</mi></mrow><annotation encoding=\"application/x-tex\">D</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span></span></span></span> 维，得到<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>p</mi></msub><mi>E</mi><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mi>N</mi><mo>×</mo><mi>N</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">x_pE\\in \\mathbb{R}^{N\\times N}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">p</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">×</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span></span></span></span></span></span></span></span></span>。类似于 NLP 中的词嵌入（Word Embeddings）。</p>\n<p>图像块嵌入的参考程序为：</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">PatchEmbed</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\" Image to Patch Embedding \"\"\"</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre> </pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> img_size<span class=\"token operator\">=</span><span class=\"token number\">224</span><span class=\"token punctuation\">,</span> patch_size<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> in_chans<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> embed_dim<span class=\"token operator\">=</span><span class=\"token number\">768</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>        <span class=\"token comment\"># (H, W)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        img_size <span class=\"token operator\">=</span> to_2tuple<span class=\"token punctuation\">(</span>img_size<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        <span class=\"token comment\"># (P, P)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        patch_size <span class=\"token operator\">=</span> to_2tuple<span class=\"token punctuation\">(</span>patch_size<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        <span class=\"token comment\"># N = (H // P) * (W // P)</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        num_patches <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>img_size<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">//</span> patch_size<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span>img_size<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">//</span> patch_size<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"13\"></td><td><pre>        self<span class=\"token punctuation\">.</span>img_size <span class=\"token operator\">=</span> img_size</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>        self<span class=\"token punctuation\">.</span>patch_size <span class=\"token operator\">=</span> patch_size</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>        self<span class=\"token punctuation\">.</span>num_patches <span class=\"token operator\">=</span> num_patches</pre></td></tr><tr><td data-num=\"16\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"17\"></td><td><pre>        <span class=\"token comment\"># 可训练的线性投影 - 获取输入嵌入</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>        self<span class=\"token punctuation\">.</span>proj <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_chans<span class=\"token punctuation\">,</span> embed_dim<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span>patch_size<span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span>patch_size<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre> </pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>        B<span class=\"token punctuation\">,</span> C<span class=\"token punctuation\">,</span> H<span class=\"token punctuation\">,</span> W <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>shape</pre></td></tr><tr><td data-num=\"22\"></td><td><pre>        <span class=\"token comment\"># (B, C, H, W) -> (B, D, (H//P), (W//P)) -> (B, D, N) -> (B, N, D)</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>        <span class=\"token comment\">#   D=embed_dim=768, N=num_patches=(H//P)*(W//P)</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>        <span class=\"token comment\">#   torch.flatten (input, start_dim=0, end_dim=-1)  # 形参：展平的起始维度和结束维度    </span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>        <span class=\"token comment\"># 可见 Patch Embedding 操作 1 行代码 3 步到位</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>proj<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>flatten<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>        <span class=\"token keyword\">return</span> x</pre></td></tr></table></figure><h2 id=\"22-可学习的嵌入learnable-embedding\"><a class=\"markdownIt-Anchor\" href=\"#22-可学习的嵌入learnable-embedding\">#</a> 2.2 可学习的嵌入（Learnable Embedding）</h2>\n<p>  类似于 BERT 的 [class] token， <code>ViT</code>  为图像 patch 嵌入序列预设一个可学习的嵌入<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mn>0</mn></msub><mo>=</mo><msub><mi>x</mi><mrow><mi>c</mi><mi>l</mi><mi>a</mi><mi>s</mi><mi>s</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">z_0=x_{class}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">c</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal mtight\">a</span><span class=\"mord mathnormal mtight\">s</span><span class=\"mord mathnormal mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，其在 Transformer 编码器输出的状态 / 特征<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>z</mi><mi>L</mi><mn>0</mn></msubsup></mrow><annotation encoding=\"application/x-tex\">z^0_L</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.089439em;vertical-align:-0.275331em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.424669em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">L</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.275331em;\"><span></span></span></span></span></span></span></span></span></span> 用作图像表示。在预训练和微调期间，将分类头附加到<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>z</mi><mi>L</mi><mn>0</mn></msubsup></mrow><annotation encoding=\"application/x-tex\">z^0_L</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.089439em;vertical-align:-0.275331em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.424669em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">L</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.275331em;\"><span></span></span></span></span></span></span></span></span></span> 之后，从而用于图像分类。分类头在预训练时由具有一个隐藏层的 <code>MLP</code>  实现，在微调时由单个线性层实现。</p>\n<p>  更明确地，假设将图像分为 N 个图像块，输入到 Transformer 编码器中就有 N 个向量，但是这些向量都不适合用来作为分类预测。一个合理的做法是手动添加一个可学习的嵌入向量作为用于分类的类别向量同时与其他图像块嵌入向量一起输入到 Transformer 编码器中，最后取追加的首个可学习的嵌入向量作为类别预测结果。所以，追加的首个类别向量可理解为其他 N 个图像块寻找的类别信息。从而，最终输入 Transformer 的嵌入向量总长度为 N+1。可学习嵌入 在训练时随机初始化，然后通过训练得到，其具体实现为：</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\">### 随机初始化</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>self<span class=\"token punctuation\">.</span>cls_token <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Parameter<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> embed_dim<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># shape = (1, 1, D)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre> </pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 按通道拼接 获取 N+1 维 Embeddings</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>x <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>cls_tokens<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># shape = (B, N+1, D)</span></pre></td></tr></table></figure><h2 id=\"23-位置嵌入-position-embeddings\"><a class=\"markdownIt-Anchor\" href=\"#23-位置嵌入-position-embeddings\">#</a> 2.3 位置嵌入 (Position Embeddings)</h2>\n<p>  位置嵌入<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>E</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mo stretchy=\"false\">(</mo><mi>N</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>×</mo><mi>D</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">E_{pos}\\in \\mathbb{R}^{(N+1)\\times D}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">p</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span><span class=\"mbin mtight\">×</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">D</span></span></span></span></span></span></span></span></span></span></span></span> 也被加入图像块嵌入，以保留输入图像块之间的空间位置信息。若不给模型提供图像块的位置信息，那么模型就需要通过图像块的语义来学习拼图，这就额外增加了学习成本。ViT 论文中对比了几种不同的位置编码方案：</p>\n<ul>\n<li>位置嵌入</li>\n<li>1-D 位置嵌入 (1D-PE)：考虑把 2-D 图像块视为 1-D 序列</li>\n<li>2-D 位置嵌入 (2D-PE)：考虑图像块的 2-D 位置 (x, y)</li>\n<li>相对位置嵌入 (RPE)：考虑图像块的相对位置</li>\n</ul>\n<p>  最后发现如果 不提供位置编码效果会差，但其它各种类型的编码效果效果都接近，这主要是因为 ViT 的输入是相对较大的图像块而非像素，所以学习位置信息相对容易很多。</p>\n<p>  Transformer 原文中默认采用 固定位置编码，ViT 则采用 标准可学习 / 训练的 1-D 位置编码嵌入，因为尚未观察到使用更高级的 2-D-aware 位置嵌入 (附录 D.4) 能够带来显著的性能提升 (当然，后续的很多 ViT 变体也使用了 2-D 位置嵌入)。在输入 Transformer 编码器之前直接 将图像块嵌入和位置嵌入按元素相加：</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 多 +1 是为了加入上述的 class token</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\"># embed_dim 即 patch embed_dim</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>self<span class=\"token punctuation\">.</span>pos_embed <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Parameter<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> num_patches <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> embed_dim<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> </pre></td></tr><tr><td data-num=\"4\"></td><td><pre> </pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\"># patch emded + pos_embed ：图像块嵌入 + 位置嵌入</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>x <span class=\"token operator\">=</span> x <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>pos_embed</pre></td></tr></table></figure>",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/09/19/AI/SimCLR/",
            "url": "http://qianqiu-cell.github.io/2024/09/19/AI/SimCLR/",
            "title": "SimCLR",
            "date_published": "2024-09-18T16:00:00.000Z",
            "content_html": "<h1 id=\"一-引言\"><a class=\"markdownIt-Anchor\" href=\"#一-引言\">#</a> 一、引言</h1>\n<p>  在没有人类监督的情况下学习有效的视觉表征是一个长期存在的问题。大多数主流方法可分为两类：生成式或判别式。生成式方法学习在输入空间中生成或以其他方式建模像素。然而，像素级生成在计算上是昂贵的，并且对于表示学习可能不是必需的。判别方法使用类似于用于监督学习的目标函数来学习表征，但训练网络执行借口任务，其中输入和标签都来自未标记的数据集。许多这样的方法都依赖于启发式来设计借口任务，这可能会限制学习表征的一般性。基于潜在空间中对比学习的判别方法最近显示出很大的前景，取得了最先进的结果。</p>\n<p>  其中 <code>SimCLR</code>  为视觉表征的对比学习引入了一个简单的框架。 <code>SimCLR</code>  不仅优于以前的工作，而且更简单，不需要专门的架构，也不是记忆库。通过系统地研究 <code>SimCLR</code>  框架，表明了以下促成了良好对比表征学习的主要原因:</p>\n<ul>\n<li><strong>多个数据增强操作的组合</strong>对于定义产生<strong>有效表示的对比预测任务</strong>至关重要。此外，与有监督学习相比，<strong>无监督对比学习受益于更强的数据增强</strong>。</li>\n<li><strong>在表示和对比损失之间引入可学习的非线性变换</strong>，大大提高了学习到的表示的质量。</li>\n<li>具有<strong>对比交叉熵损失的表征学习</strong>得益于<strong>归一化嵌入和适当调整的温度参数</strong>。</li>\n<li>对比学习与监督学习相比，<strong>得益于更大的批处理规模和更长的训练时间</strong>。与监督式学习一样，<strong>对比式学习也受益于更深入、更广泛的网络</strong>。</li>\n</ul>\n<h1 id=\"二-对比学习框架\"><a class=\"markdownIt-Anchor\" href=\"#二-对比学习框架\">#</a> 二、对比学习框架</h1>\n<p>  受最近的对比学习算法的启发， <code>SimCLR</code>  通过潜在空间中的对比损失来最大化相同数据示例的不同增强视图之间的一致性来学习表示。如下图所示，该框架由以下四个主要组件组成：</p>\n<p><img data-src=\"/images/AI/SimCLR/2.1.png\" alt=\"\"></p>\n<ul>\n<li><strong>一种随机数据增强模块<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi><mo stretchy=\"false\">(</mo><msup><mi>t</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo stretchy=\"false\">)</mo><mo>∼</mo><mi>τ</mi></mrow><annotation encoding=\"application/x-tex\">t(t&#x27;)\\sim \\tau</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.001892em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">t</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∼</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.1132em;\">τ</span></span></span></span></strong>，<strong>它将任意给定的数据示例<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span> 通过数据增强随机转换为同一示例的两个相关视图</strong>，表示为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mover accent=\"true\"><mi>x</mi><mo>~</mo></mover><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\tilde{x}_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mover accent=\"true\"><mi>x</mi><mo>~</mo></mover><mi>j</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\tilde{x}_j</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9539679999999999em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>，我们将其视为正样本对。在 <code>SimCLR</code>  中，依次应用三种简单的增强：随机裁剪，然后将大小调整回原始大小，随机颜色失真和随机高斯模糊。随机裁剪和颜色失真的结合对于获得良好的性能至关重要。</li>\n<li><strong>一种神经网络基础编码器<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mo separator=\"true\">⋅</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(·)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mclose\">)</span></span></span></span></strong>，<strong>从增强的数据示例中提取表示向量</strong>。 <code>SimCLR</code>  允许在没有任何限制的情况下选择各种网络架构。为了简单起见，采用常用的 ResNet 得到<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub><mo>=</mo><mi>f</mi><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi>x</mi><mo>~</mo></mover><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mtext>ResNet</mtext><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi>x</mi><mo>~</mo></mover><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h_i=f(\\tilde{x}_i)=\\text{ResNet}(\\tilde{x}_i)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">ResNet</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>，其中<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub><mo>∈</mo><msub><mi mathvariant=\"double-struck\">R</mi><mi>d</mi></msub></mrow><annotation encoding=\"application/x-tex\">h_i\\in \\mathbb{R}_d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83889em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">d</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 是平均池化层后的输出。</li>\n<li><strong>一个小的神经网络投影头<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>g</mi><mo stretchy=\"false\">(</mo><mo separator=\"true\">⋅</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">g(·)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mclose\">)</span></span></span></span></strong>，<strong>它表示映射到应用对比损失的空间</strong>。 <code>SimCLR</code>  使用具有一个隐藏层的 <code>MLP</code>  得到<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>=</mo><mi>g</mi><mo stretchy=\"false\">(</mo><msub><mi>h</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>=</mo><msup><mi>W</mi><mrow><mo stretchy=\"false\">(</mo><mn>2</mn><mo stretchy=\"false\">)</mo></mrow></msup><mi>σ</mi><mo stretchy=\"false\">(</mo><msup><mi>W</mi><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msup><msub><mi>h</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">z_i = g(h_i) = W^{(2)}\\sigma(W^{(1)}h_i)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.138em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">2</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>，其中<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>σ</mi></mrow><annotation encoding=\"application/x-tex\">\\sigma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span></span></span></span> 是一个 <code>ReLU</code>  非线性。将对比损失定义在<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">z_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 上而不是<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">h_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 上是有益的。</li>\n<li><strong>为对比预测任务定义的对比损失函数</strong>。给定一个集合<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mover accent=\"true\"><mi>x</mi><mo>~</mo></mover><mi>k</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\tilde{x}_k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，其中包含一对正的例子<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mover accent=\"true\"><mi>x</mi><mo>~</mo></mover><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\tilde{x}_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mover accent=\"true\"><mi>x</mi><mo>~</mo></mover><mi>j</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\tilde{x}_j</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9539679999999999em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>，对比预测任务旨在识别给定<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mover accent=\"true\"><mi>x</mi><mo>~</mo></mover><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\tilde{x}_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8178599999999999em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，在<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mrow><mo fence=\"true\">{</mo><msub><mover accent=\"true\"><mi>x</mi><mo>~</mo></mover><mi>k</mi></msub><mo fence=\"true\">}</mo></mrow><mrow><mi>k</mi><mo mathvariant=\"normal\">≠</mo><mi>i</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\left \\{ \\tilde{x}_k \\right \\} _{k\\ne i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.185808em;vertical-align:-0.435808em;\"></span><span class=\"minner\"><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">{</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">}</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1864079999999999em;\"><span style=\"top:-2.4003000000000005em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mrel mtight\"><span class=\"mrel mtight\"><span class=\"mord vbox mtight\"><span class=\"thinbox mtight\"><span class=\"rlap mtight\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"inner\"><span class=\"mrel mtight\"></span></span><span class=\"fix\"></span></span></span></span></span><span class=\"mrel mtight\">=</span></span><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.435808em;\"><span></span></span></span></span></span></span></span></span></span> 中的<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mover accent=\"true\"><mi>x</mi><mo>~</mo></mover><mi>j</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\tilde{x}_j</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9539679999999999em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>。</li>\n</ul>\n<p>  通过随机抽取一个由 <code>n</code>  个样本组成的小批量样本，对该小批量样本进行数据增强，得到 <code>2N</code>  个数据点。对于每一个增强后的数据，都对应一个正样本，将增强后数据中的其他 2 (N−1) 个增强示例视为负示例。设<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mtext>sim</mtext><mo stretchy=\"false\">(</mo><mi>u</mi><mo separator=\"true\">,</mo><mi>v</mi><mo stretchy=\"false\">)</mo><mo>=</mo><msup><mi>u</mi><mtext>T</mtext></msup><mi>v</mi><mi mathvariant=\"normal\">/</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>u</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>v</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi></mrow><annotation encoding=\"application/x-tex\">\\text{sim}(u, v)=u^{\\textrm{T}}v/||u||||v||</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">sim</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">u</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0913309999999998em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">u</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord textrm mtight\">T</span></span></span></span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord\">/</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">u</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span></span></span></span> 表示归一化<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>u</mi></mrow><annotation encoding=\"application/x-tex\">u</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">u</span></span></span></span> 与<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>v</mi></mrow><annotation encoding=\"application/x-tex\">v</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span></span></span></span> 之间的点积 (即余弦相似度)。则一对正样本<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo separator=\"true\">,</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(i, j)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">i</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05724em;\">j</span><span class=\"mclose\">)</span></span></span></span> 的损失函数定义为</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi mathvariant=\"normal\">ℓ</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>j</mi></mrow></msub><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi>sin</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"bold-italic\">z</mi><mi>i</mi></msub><mo separator=\"true\">,</mo><msub><mi mathvariant=\"bold-italic\">z</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">/</mi><mi>τ</mi><mo stretchy=\"false\">)</mo></mrow><mrow><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mn>2</mn><mi>N</mi></mrow></munderover><msub><mn mathvariant=\"double-struck\">1</mn><mrow><mo stretchy=\"false\">[</mo><mi>k</mi><mo mathvariant=\"normal\">≠</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></msub><mi>exp</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi>sin</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"bold-italic\">z</mi><mi>i</mi></msub><mo separator=\"true\">,</mo><msub><mi mathvariant=\"bold-italic\">z</mi><mi>k</mi></msub><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">/</mi><mi>τ</mi><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\ell_{i,j}=-\\log\\frac{\\exp(\\sin(\\boldsymbol{z}_i,\\boldsymbol{z}_j)/\\tau)}{\\sum_{k=1}^{2N}\\mathbb{1}_{[k\\neq i]}\\exp(\\sin(\\boldsymbol{z}_i,\\boldsymbol{z}_k)/\\tau)}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\">ℓ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.653431em;vertical-align:-1.2264309999999998em;\"></span><span class=\"mord\">−</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.128769em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.981231em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\">1</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.5198em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">[</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mrel mtight\"><span class=\"mrel mtight\"><span class=\"mord vbox mtight\"><span class=\"thinbox mtight\"><span class=\"rlap mtight\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"inner\"><span class=\"mrel mtight\"></span></span><span class=\"fix\"></span></span></span></span></span><span class=\"mrel mtight\">=</span></span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">]</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3551999999999999em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\">exp</span><span class=\"mopen\">(</span><span class=\"mop\">sin</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.04213em;\">z</span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.04213em;\">z</span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\">/</span><span class=\"mord mathnormal\" style=\"margin-right:0.1132em;\">τ</span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mop\">exp</span><span class=\"mopen\">(</span><span class=\"mop\">sin</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.04213em;\">z</span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.04213em;\">z</span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\">/</span><span class=\"mord mathnormal\" style=\"margin-right:0.1132em;\">τ</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2264309999999998em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>  其中<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mn mathvariant=\"double-struck\">1</mn><mrow><mo stretchy=\"false\">[</mo><mi>k</mi><mo mathvariant=\"normal\">≠</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\mathbb{1}_{[k\\neq i]}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9996399999999999em;vertical-align:-0.3551999999999999em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\">1</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.5198em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">[</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mrel mtight\"><span class=\"mrel mtight\"><span class=\"mord vbox mtight\"><span class=\"thinbox mtight\"><span class=\"rlap mtight\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"inner\"><span class=\"mrel mtight\"></span></span><span class=\"fix\"></span></span></span></span></span><span class=\"mrel mtight\">=</span></span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">]</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3551999999999999em;\"><span></span></span></span></span></span></span></span></span></span> 是当<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi><mo mathvariant=\"normal\">≠</mo><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">k\\ne i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\"><span class=\"mrel\"><span class=\"mord vbox\"><span class=\"thinbox\"><span class=\"rlap\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"inner\"><span class=\"mrel\"></span></span><span class=\"fix\"></span></span></span></span></span><span class=\"mrel\">=</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">i</span></span></span></span> 时取值为 1 的指标函数，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>τ</mi></mrow><annotation encoding=\"application/x-tex\">\\tau</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.1132em;\">τ</span></span></span></span> 表示温度参数。为了方便起见，称其为 <code>NT-Xent</code> （the normalized temperature-scaled cross entropy loss，归一化温度标度交叉熵损失）。</p>\n<p>  如下的流程图总结了 SimCLR 的算法流程：</p>\n<p><img data-src=\"/images/AI/SimCLR/2.2.png\" alt=\"\"></p>\n<h1 id=\"三-对比表征学习的数据增强\"><a class=\"markdownIt-Anchor\" href=\"#三-对比表征学习的数据增强\">#</a> 三、对比表征学习的数据增强</h1>\n<p>  为了系统地研究数据扩充的影响， <code>SimCLR</code>  这里考虑几个常见的扩充。一种类型的增强涉及数据的空间 / 几何变换，例如裁剪和调整大小 (水平翻转)，旋转和切出。另一种类型的增强涉及外观转换，如颜色失真 (包括颜色下降，亮度，对比度，饱和度，色调)，高斯模糊和索贝尔滤波。下图显示了 <code>SimCLR</code>  中学习的增强。</p>\n<p><img data-src=\"/images/AI/SimCLR/3.1.png\" alt=\"\"></p>\n<p>  下图显示了单独和组合转换下的线性评估结果。可以观察到，即使模型几乎可以完美地识别对比任务中的正对，也没有一个单一的变换足以学习到良好的表示。在组合增强时，对比预测任务变得更加困难，但表示质量显著提高。</p>\n<p><img data-src=\"/images/AI/SimCLR/3.2.png\" alt=\"\"></p>\n<p>  增强的一个组成突出：<strong>随机裁剪和随机颜色失真</strong>。可以推测，当只使用随机裁剪作为数据增强时，一个严重的问题是来自图像的大多数补丁共享相似的颜色分布。下图显示，颜色直方图本身就足以区分图像。神经网络可以利用这一捷径来解决预测任务。因此，为了学习可推广的特征，将裁剪与颜色失真组合是至关重要的。</p>\n<p><img data-src=\"/images/AI/SimCLR/3.3.png\" alt=\"\"></p>\n<h1 id=\"四-编码器和投影头的架构\"><a class=\"markdownIt-Anchor\" href=\"#四-编码器和投影头的架构\">#</a> 四、编码器和投影头的架构</h1>\n<p>  下图显示，<strong>增加深度和宽度都会提高性能</strong>，这也许并不令人惊讶。虽然类似的发现适用于监督学习，我们发现监督模型和在无监督模型上训练的线性分类器之间的差距随着模型大小的增加而缩小，这表明无监督学习比监督学习更受益于更大的模型。</p>\n<p><img data-src=\"/images/AI/SimCLR/4.1.png\" alt=\"\"></p>\n<p>  然后， <code>SimCLR</code>  研究包括投影头的重要性，即<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>g</mi><mo stretchy=\"false\">(</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">g(h)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">h</span><span class=\"mclose\">)</span></span></span></span>。下图示出了使用头部的三种不同架构的线性评估结果：（1）无投影；（2）线性投影；（3）默认的非线性投影与一个额外的隐藏层（ReLU 激活）。可以观察到<strong>非线性投影</strong>比线性投影好（+3%），并且比没有投影好得多（&gt;10%）。当使用投影头时，<strong>无论输出尺寸如何，都观察到类似的结果</strong>。</p>\n<p><img data-src=\"/images/AI/SimCLR/4.2.png\" alt=\"\"></p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/09/14/AI/BERT/",
            "url": "http://qianqiu-cell.github.io/2024/09/14/AI/BERT/",
            "title": "BERT",
            "date_published": "2024-09-13T16:00:00.000Z",
            "content_html": "<h1 id=\"一-引言\"><a class=\"markdownIt-Anchor\" href=\"#一-引言\">#</a> 一、引言</h1>\n<p>   <code>BERT</code> （ <code>Bidirectional Encoder Representations from Transformers</code> ）是一种基于深度学习的自然语言处理（ <code>NLP</code> ）模型。它是由 <code>Google</code>  在 <code>2018</code>  年提出的，采用了 <code>Transformer</code>  架构，并在大规模语料库上进行了预训练。 <code>BERT</code>  的特点之一是其双向（ <code>Bidirectional</code> ）处理能力，它能够同时考虑到句子中所有单词的上下文，而不仅仅是单词之前或之后的部分。这种双向性使得 <code>BERT</code>  在许多 <code>NLP</code>  任务中表现出色，例如文本分类、问答和命名实体识别等。</p>\n<h1 id=\"二-bert\"><a class=\"markdownIt-Anchor\" href=\"#二-bert\">#</a> 二、BERT</h1>\n<p>   <code>BERT</code>  的框架中有两个步骤：预训练和微调。在预训练过程中，模型在<strong>不同的预训练任务上对未标记数据</strong>进行训练。对于微调，首先使用预训练的参数初始化 <code>BERT</code>  模型，然后使用<strong>来自下游任务的标记数据</strong>对<strong>所有参数</strong>进行<strong>微调</strong>。每个下游任务都有单独的微调模型，即使它们是用相同的预训练参数初始化的。</p>\n<p><img data-src=\"/images/AI/BERT/2.1.png\" alt=\"\"></p>\n<p>   <code>BERT</code>  的一个显著特征是其跨不同任务的统一架构。预训练的体系结构和最终的下游体系结构之间的差别很小。除了输出层，在预训练和微调中使用了相同的架构。使用相同的预训练模型参数来初始化不同下游任务的模型。在微调期间，对所有参数进行微调。[CLS] 是添加在每个输入示例前面的特殊符号，[SEP] 是一个特殊的分隔符号 (例如，分隔问题 / 答案)。</p>\n<h2 id=\"21-模型结构\"><a class=\"markdownIt-Anchor\" href=\"#21-模型结构\">#</a> 2.1 模型结构</h2>\n<p>   <code>BERT</code>  的模型架构是一个多层双向 <code>transformer</code>  编码器，使用<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>L</mi></mrow><annotation encoding=\"application/x-tex\">L</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">L</span></span></span></span> 表示层数 (即 <code>transformer</code>  块)，隐藏大小为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>H</mi></mrow><annotation encoding=\"application/x-tex\">H</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span></span></span></span>，自注意头的数量为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">A</span></span></span></span>。 <code>BERT</code>  主要有两种模型大小： <code>BERT BASE</code>  (L=12, H=768, A=12, Total Parameters=110M) 和 <code>BERT LARGE</code> (L=24, H=1024, A=16, Total Parameters=340M)。</p>\n<p>  为了进行比较，选择 <code>BERT BASE</code>  与 <code>OpenAI GPT</code>  具有相同的模型大小。然而，关键的是， <code>BERT Transformer</code>  使用双向自关注，而 <code>GPT Transformer</code>  使用约束自关注，其中每个 <code>token</code>  只能关注其左侧的上下文。</p>\n<h2 id=\"22-输入输出表示\"><a class=\"markdownIt-Anchor\" href=\"#22-输入输出表示\">#</a> 2.2 输入 / 输出表示</h2>\n<p>  为了使 <code>BERT</code>  处理各种下游任务，我们的输入表示能够在一个 <code>token</code>  序列中明确地表示单个句子和一对句子 (例如，&lt;Question, Answer&gt;)。在整个工作中，一个 “句子” 可以是一个连续文本的任意跨度，而不是一个实际的语言句子。“序列” 指的是 <code>BERT</code>  的输入 <code>token</code>  序列，它可以是一个句子或两个句子组合在一起。</p>\n<p>   <code>BERT</code>  使用具有 <code>30,000</code>  个词汇的 <code>WordPiece embeddings</code> 。每个序列的第一个标记总是一个特殊的分类标记 ([CLS])。 <code>BERT</code>  用两种方法区分句子。首先，用一个特殊的 <code>token</code>  ([SEP]) 将它们分开。其次，为每一个 <code>token</code>  添加一个可学习 <code>embedding</code> ，表明它属于句子 <code>A</code>  还是句子 <code>B</code> 。如图 1 所示，将输入 <code>embedding</code>  表示为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi></mrow><annotation encoding=\"application/x-tex\">E</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span></span></span></span>，特殊 [CLS] 标记的最终隐藏向量表示为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mi>H</mi></msup></mrow><annotation encoding=\"application/x-tex\">C\\in \\mathbb{R}^H</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72243em;vertical-align:-0.0391em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.08125em;\">H</span></span></span></span></span></span></span></span></span></span></span>，第 i 个输入标记的最终隐藏向量表示为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mi>H</mi></msup></mrow><annotation encoding=\"application/x-tex\">T_i\\in \\mathbb{R}^H</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.08125em;\">H</span></span></span></span></span></span></span></span></span></span></span>。</p>\n<p>  对于给定的 <code>token</code> ， <code>BERT</code>  输入表示是通过将相应的 <code>token</code> 、 <code>segment</code>  (段) 和 <code>position</code>  (位置) <code>embedding</code>  相加来构建的。图 2 显示了该结构的可视化。</p>\n<p><img data-src=\"/images/AI/BERT/2.2.png\" alt=\"\"></p>\n<h2 id=\"23-预训练bert\"><a class=\"markdownIt-Anchor\" href=\"#23-预训练bert\">#</a> 2.3 预训练 BERT</h2>\n<p>  使用两个无监督任务对 <code>BERT</code>  进行预训练。</p>\n<h3 id=\"1-任务-1掩码语言模型masked-lm-mlm\"><a class=\"markdownIt-Anchor\" href=\"#1-任务-1掩码语言模型masked-lm-mlm\">#</a> (1) 任务 1：掩码语言模型（Masked LM, MLM）</h3>\n<p>  为了训练深度双向表示， <code>BERT</code>  随机屏蔽一定比例的输入 <code>token</code> ，然后预测这些被屏蔽的 <code>token</code> 。这一过程称为 <code>Masked LM</code> ( <code>MLM</code> )，在文献中它通常被称为完形填空任务。</p>\n<p>  训练数据生成器随机选择 15% 的 <code>token</code>  位置进行预测。如果选择了第<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">i</span></span></span></span> 个 <code>token</code> ，那么 80% 的概率使用 [MASK] <code>token</code> ，10% 的概率使用随机 <code>token</code> ，10% 的概率使用未更改的第<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">i</span></span></span></span> 个 <code>token</code>  来替换第<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">i</span></span></span></span> 个 <code>token</code> 。然后，利用<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">T_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 来预测具有交叉熵损失的原始 <code>token</code> 。</p>\n<h3 id=\"2任务-2下一个句子预测next-sentence-prediction-nsp\"><a class=\"markdownIt-Anchor\" href=\"#2任务-2下一个句子预测next-sentence-prediction-nsp\">#</a> （2）任务 2：下一个句子预测（Next Sentence Prediction, NSP）</h3>\n<p>  许多重要的下游任务，如问答 ( <code>QA</code> ) 和自然语言推理 ( <code>NLI</code> )，都是基于理解两个句子之间的关系，这是语言建模无法直接捕获的。为了训练一个理解句子关系的模型， <code>BERT</code>  对一下一个句子预测任务进行了预训练，该任务可以从任何单语语料库中轻松生成。具体来说，当为每个预训练示例选择句子 <code>A</code>  和 <code>B时</code> ， <code>50%</code>  的时间 <code>B</code>  是 <code>A</code>  之后的下一个句子 (标记为 <code>IsNext</code> )，  <code>50%</code>  的时间 <code>B</code>  是语料库中的随机句子 (标记为 <code>NotNext</code> )。如图 1 所示，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span></span> 用于下一个句子预测。</p>\n<h3 id=\"预训练的数据\"><a class=\"markdownIt-Anchor\" href=\"#预训练的数据\">#</a> 预训练的数据</h3>\n<p>  预训练过程在很大程度上遵循现有的文献语言模型预训练。对于预训练语料库， <code>BERT</code>  使用 <code>BooksCorpus</code> （8 亿单词）和英语维基百科（2,500 万字）。对于维基百科， <code>BERT</code>  只提取文本段落，忽略列表，表格和标题。使用文档级语料库而不是诸如十亿字基准，以便提取长的连续序列。</p>\n<h2 id=\"23-微调bert\"><a class=\"markdownIt-Anchor\" href=\"#23-微调bert\">#</a> 2.3 微调 BERT</h2>\n<p>  在海量的语料上训练完 BERT 之后，便可以将其应用到 NLP 的各个任务中了。 微调 (Fine-Tuning) 的任务包括：基于句子对的分类任务，基于单个句子的分类任务，问答任务，命名实体识别等。</p>\n<h1 id=\"三-参考程序\"><a class=\"markdownIt-Anchor\" href=\"#三-参考程序\">#</a> 三、参考程序</h1>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL2NvZGVydGltby9CRVJULXB5dG9yY2g=\">https://github.com/codertimo/BERT-pytorch</span></p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/09/14/AI/BLIP/",
            "url": "http://qianqiu-cell.github.io/2024/09/14/AI/BLIP/",
            "title": "BLIP",
            "date_published": "2024-09-13T16:00:00.000Z",
            "content_html": "<h1 id=\"一-引言\"><a class=\"markdownIt-Anchor\" href=\"#一-引言\">#</a> 一、引言</h1>\n<p>  自从 <code>CLIP</code>  横空出世，各种 视觉语言预训练 ( <code>Vision-Language Pre-training, VLP</code> ) 模型逐渐涌现，显著提高了各种视觉语言任务的性能。然而，现有的 <code>VLP</code>  方法主要存在以下两个问题：</p>\n<ul>\n<li>\n<p><strong>模型角度</strong>：大多数方法都是基于 编码器模型 ( <code>encoder-based model</code> ) 或编码器 - 解码器模型 ( <code>encoder-decoder models</code> )，前者难以完成文本生成任务，后者无法完成图像文本检索任务，这两项任务无法兼顾；</p>\n</li>\n<li>\n<p><strong>数据角度</strong>：以 <code>CLIP</code>  为代表的方法都是从互联网上收集海量图像 - 文本对作为样本进行预训练，这些带噪声的文本作为视觉语言学习的监督信号显然不是最优解；</p>\n</li>\n</ul>\n<p>  为此， <code>Salesforce</code>  的研究者们提出了 <code>BLIP (Bootstrapping language - image Pre-training)</code> ，用于统一的视觉语言理解和生成。 <code>BLIP</code>  是一种新的 <code>VLP</code>  框架，比现有方法能够实现更广泛的下游任务。它分别从模型和数据的角度介绍了两个贡献:</p>\n<ul>\n<li>\n<p><strong>编码器 - 解码器的多模态混合</strong> ( <code>MED, Multimodal mixture of Encoder-Decoder</code> ): 一种有效的多任务预训练和灵活迁移学习的新模型架构。 <code>MED</code>  可以作为单模编码器、基于图像的文本编码器或基于图像的文本解码器操作。该模型采用图像文本对比学习、图像文本匹配和图像条件化语言建模三个视觉语言目标进行联合预训练。</p>\n</li>\n<li>\n<p><strong>字幕和过滤</strong> ( <code>CapFilt, Captioning and Filtering</code> ): 一种新的数据集 <code>bootstrap</code>  方法，用于从噪声图像 - 文本对中学习。 <code>BLIP</code>  将预训练的 <code>MED</code>  调整为两个模块：一个 <code>captioner</code>  用于生成给定 web 图像的合成字幕，一个 <code>filter</code>  用于从原始 <code>web</code>  文本和合成文本中去除嘈杂的字幕。</p>\n</li>\n</ul>\n<h1 id=\"二-相关工作\"><a class=\"markdownIt-Anchor\" href=\"#二-相关工作\">#</a> 二、相关工作</h1>\n<h2 id=\"21-视觉语言预训练\"><a class=\"markdownIt-Anchor\" href=\"#21-视觉语言预训练\">#</a> 2.1 视觉语言预训练</h2>\n<p>  视觉语言预训练 ( <code>VLP</code> ) 旨在通过对大规模图像 - 文本对模型进行预训练来提高下游视觉和语言任务的性能。由于获取人工注释文本的费用过高，大多数方法使用从网络抓取的图像和替代文本对。尽管使用了简单的基于规则的过滤器，噪声在网络文本中仍然普遍存在。然而，噪声的负面影响在很大程度上被忽略了，被通过扩大数据集获得的性能增益所掩盖。 <code>BLIP</code>  的论文表明，噪声网络文本对于视觉语言学习是次优的，并提出 <code>CapFilt</code>  以更有效的方式利用网络数据集的。</p>\n<p>  已经有很多尝试将各种视觉和语言任务统一到一个框架中。最大的挑战是设计既能执行基于理解的任务 (如图像文本检索) 又能执行基于生成的任务 (如图像字幕) 的模型架构。两者都不是基于编码器的模型和编码器 - 解码器模型可以在这两种类型的任务中表现出色，而单一的统一编码器 - 解码器也限制了模型的能力。 <code>BLIP</code>  提出的多模态编码器 - 解码器混合模型在广泛的下游任务上提供了更大的灵活性和更好的性能，同时保持了预训练的简单和高效。</p>\n<h2 id=\"22-知识蒸馏\"><a class=\"markdownIt-Anchor\" href=\"#22-知识蒸馏\">#</a> 2.2 知识蒸馏</h2>\n<p>  知识蒸馏（ <code>KD, Knowledge Distillation</code> ）旨在通过从教师模型中提取知识来提高学生模型的性能。自我蒸馏是 <code>KD</code>  的一个特例，其中教师和学生的规模相等。已经证明只是蒸馏对于图像分类，以及 <code>VLP</code>  是有效的。与大多数现有的 <code>KD</code>  方法只是简单地强制学生具有与教师相同的类预测不同， <code>BLIP</code>  提出的 <code>CapFilt</code>  可以被解释为在 <code>VLP</code>  环境下执行 <code>KD</code>  的一种更有效的方法，其中字幕器通过语义丰富的合成字幕提取其知识，而过滤器通过去除噪声字幕提取其知识。</p>\n<h2 id=\"23-数据增强\"><a class=\"markdownIt-Anchor\" href=\"#23-数据增强\">#</a> 2.3 数据增强</h2>\n<p>  虽然数据增强（ <code>DA, Data Augmentation</code> ）已被广泛应用于计算机视觉，但用于语言任务的 <code>DA</code>  并不那么直接。近年来，生成语言模型已被用于合成各种 <code>NLP</code>  任务的示例。不同于这些方法只关注低资源的语言任务， <code>BLIP</code>  的方法展示了合成字幕在大规模视觉语言预训练中的优势。</p>\n<h1 id=\"三-方法\"><a class=\"markdownIt-Anchor\" href=\"#三-方法\">#</a> 三、方法</h1>\n<h2 id=\"31-模型架构\"><a class=\"markdownIt-Anchor\" href=\"#31-模型架构\">#</a> 3.1 模型架构</h2>\n<p><img data-src=\"/images/AI/BLIP/3.1.png\" alt=\"\"></p>\n<p>   <code>BLIP</code>  采用了编码器 - 解码器的多模态混合结构 ( <code>MED</code> )，包括两个单模态编码器、一个以图像为基础的文本编码器和一个以图像为基础的文本解码器：</p>\n<ul>\n<li>\n<p><strong>单模态编码器</strong>  <code>lmage Encoder</code> ：基于 <code>transformer</code>  的 <code>ViT</code>  的架构，将输入图像分割为多个的 <code>patch</code>  并将它们编码为一系列 <code>Image Embedding</code> ，并使用 [CLS] token 来表示全局的图像特征。 <code>lmage Encoder</code>  用来提取图像特征做对比学习，相当于 <code>CLIP</code>  中的  <code>Image Encoder</code> ；</p>\n</li>\n<li>\n<p><strong>单模态编码器</strong>  <code>Text Encoder</code> ：基于 <code>BERT</code>  的架构，将 [CLS] token 加到输入文本的开头以总结句子。 <code>Text Encoder</code>  用来提取文本特征做对比学习，相当于 <code>CLIP</code>  中的 <code>Text Encoder</code> ；</p>\n</li>\n<li>\n<p><strong>以图像为基础的编码器</strong>  <code>Image-grounded text encoder</code> ：对 <code>Text Encoder</code>  的每一个 <code>transformer</code>  块，在 自注意力 ( <code>self-attention, SA</code> ) 层和前馈网络之间添加一个交叉注意 ( <code>cross-attention, CA</code> ) 层用来注入视觉信息，还将 [Encode] token 加到输入文本的开头以标识特定任务。 <code>Image-grounded text encoder</code>  用来提取文本特征并将其和图像特征对齐，相当于 <code>CLIP</code>  中更精细化的 <code>Text-Image</code>  对齐；</p>\n</li>\n<li>\n<p><strong>以图像为基础的解码器</strong>  <code>Image-grounded text decoder</code> ：将 <code>Image-grounded text encoder</code>  的 <code>self-attention</code>  层换成 <code>causal self-attention</code>  层，还将 [Decode] token 和 [EOS] token 加到输入文本的开头和结尾以标识序列的开始和结束。 <code>Image-grounded text decoder</code>  用来生成符合图像和文本特征的文本描述，这是 <code>CLIP</code>  中所没有的；</p>\n</li>\n</ul>\n<div class=\"note primary no-icon\">\n<p>  注意， <code>Image-grounded text decoder</code>  生成的文本描述不同于输入的图像 - 文本对中的文本，图像 - 文本对中的文本是互联网上找到的图片的上下文，拥有大量的噪音；而 <code>Image-grounded text decoder</code>  生成的文本描述是针对图像特征和文本特征的特定描述，更加精炼。这里其实就已经是 <code>Captioner</code>  的雏形了，下文的 <code>Captioner</code>  也是基于训练完成的 <code>Image-grounded text decoder</code>  再进行的优化和微调。</p>\n</div>\n<h2 id=\"32-预训练目标\"><a class=\"markdownIt-Anchor\" href=\"#32-预训练目标\">#</a> 3.2 预训练目标</h2>\n<p>   <code>BLIP</code>  在预训练期间联合优化三个目标，其中两个基于理解的目标和一个基于生成的目标。每个图像 - 文本对仅需要通过计算量较大的视觉 <code>Transformer</code>  的一次正向传递，以及通过文本 <code>Transformer</code>  的三次正向传递，其中不同的功能被激活以计算如下所述的三个损失。</p>\n<ul>\n<li>\n<p><strong>图文对比损失</strong> ( <code>Image-Text Contrastive Loss, ITC</code> )： <code>ITC</code>  用于训练 <code>lmage Encoder</code>  和 <code>Text Encoder</code> ，通过对比学习对齐图像和文本的特征空间。具体方法是最大化正样本图像 - 文本对的相似度且最小化负样本图像 - 文本对的相似度。 <code>BLIP</code>  还使用了 <code>ALBEF</code>  中的动量编码器来生成特征，并从动量编码器创建软标签作为训练目标，以解释负样本对中的潜在正样本；</p>\n</li>\n<li>\n<p><strong>图文匹配损失</strong> ( <code>Image-Text Matching Loss, ITM</code> )： <code>ITM</code>  用于训练 <code>Image-grounded text encoder</code> ，通过学习图像 - 文本对的联合表征实现视觉和语言之间的细粒度对齐。具体方法是通过一个二分类任务，预测图像文本对是正样本还是负样本。这里还使用了 <code>ALBEF</code>  中的 <code>hard negative mining</code>  技术以更好地捕捉负样本信息；</p>\n</li>\n</ul>\n<div class=\"note primary no-icon\">\n<p>   <code>ITM</code>  与 <code>ITC</code>  并不一样， <code>ITC</code>  虽然也对齐了图像和文本的特征空间，但并没有显式地区分正负样本，主要是用于评价图像和文本的匹配情况，给出任意输入图像 - 文本对的相似度。而 <code>ITM</code>  则是通过计算样本的损失达到区分正负样本的目的，激励正样本的图像和文本使其更加匹配。</p>\n</div>\n<ul>\n<li><strong>语言建模损失</strong> ( <code>Language Modeling Loss, LM</code> )： <code>LM</code>  用于训练 <code>Image-grounded text decoder</code> ，实现生成图像的文本描述任务。具体方法是通过优化交叉熵损失函数，训练模型以自回归的方式最大化文本的概率。在计算损失时， <code>BLIP</code>  应用 0.1 的标签平滑。与 <code>VLP</code>  中广泛使用的 <code>MLM</code>  损失相比， <code>LM</code>  使该模型具有泛化能力，能够将视觉信息转换为连贯的字幕。</li>\n</ul>\n<div class=\"note primary no-icon\">\n<p>  为了在利用多任务学习的同时执行有效的预训练，文本编码器和文本解码器共享除了 <code>SA</code>  层之外的所有参数。原因是编码和解码任务之间的差异最好由 <code>SA</code>  层来捕获。具体地，编码器采用双向自注意来构建当前输入标记的表示，而解码器采用因果自注意来预测下一个标记。另一方面，在编码和解码任务之间，嵌入层、 <code>CA</code>  层和 <code>FFN</code>  的功能类似，因此共享这些层可以提高训练效率，同时受益于多任务学习。</p>\n</div>\n<h2 id=\"33-capfilt机制\"><a class=\"markdownIt-Anchor\" href=\"#33-capfilt机制\">#</a> 3.3 CapFilt 机制</h2>\n<p>   <code>COCO</code>  数据集的高质量人工注释图像 - 文本对<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>I</mi><mi>h</mi></msub><mo separator=\"true\">,</mo><msub><mi>T</mi><mi>h</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">{(I_h,T_h)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">h</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">h</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span> 数量有限，因此 <code>CLIP</code> 、 <code>BLIP</code>  等 <code>VLP</code>  都是从网络中收集大量图像 - 文本对<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>I</mi><mi>w</mi></msub><mo separator=\"true\">,</mo><msub><mi>T</mi><mi>w</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">{(I_w,T_w)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span> 作为训练集。但这些网络图像 - 文本对的文本来自图像上下文，难以精准地描述图像内容，存在大量噪声。于是， <code>BLIP</code>  提出了字幕和过滤 ( <code>Captioning and Filtering, CapFilt</code> ) 机制，下图给出了 <code>CapFilt</code>  的说明。</p>\n<p><img data-src=\"/images/AI/BLIP/3.2.png\" alt=\"\"></p>\n<p>  上图给出了 <code>CapFilt</code>  的图示，包含字幕器和过滤器两个模块：</p>\n<ul>\n<li><strong>字幕器</strong>  <code>Captioner</code> ：一个视觉文本解码器，基于 <code>Image-grounded text decoder</code> ，用于生成给定图像的字幕，使用 <code>LM</code>  损失函数在 <code>COCO</code>  数据集上进行微调。给定网络图片<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>I</mi><mi>w</mi></msub></mrow><annotation encoding=\"application/x-tex\">I_w</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，Captioner 生成字幕<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>T</mi><mi>w</mi></msub></mrow><annotation encoding=\"application/x-tex\">T_w</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>。<br>\n​</li>\n<li><strong>过滤器</strong>  <code>Filter</code> ：一个视觉文本编码器，基于 <code>Image-grounded text encoder</code> ，用于去除文本噪声，使用 <code>ITC</code>  和 <code>ITM</code>  损失函数在 <code>COCO</code>  数据集上进行微调。 <code>Filter</code>  通过比对文本和图像的匹配情况，删除原始 <code>Web</code>  文本<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>T</mi><mi>w</mi></msub></mrow><annotation encoding=\"application/x-tex\">T_w</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和合成文本<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>T</mi><mi>s</mi></msub></mrow><annotation encoding=\"application/x-tex\">T_s</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 中的噪声。</li>\n</ul>\n<div class=\"note primary no-icon\">\n<p><code>Captioner</code>  和 <code>Filter</code>  都是在预训练完成后的 <code>MED</code>  模型上初始化的，并各自在人工注释的图像 - 文本对数据集 <code>COCO</code>  上进行微调 ( <code>finetune</code> )。最后，将过滤后的图像 - 文本对与人工注释对相结合，形成一个新的数据集（这也是 <code>Bootstrapping</code>  的由来），最后再用它来训练一遍模型。</p>\n</div>\n<h2 id=\"34-整体思路整理\"><a class=\"markdownIt-Anchor\" href=\"#34-整体思路整理\">#</a> 3.4 整体思路整理</h2>\n<ul>\n<li>先使用含有噪声的网络数据训练一遍 <code>BLIP</code> ；</li>\n<li>再在 <code>COCO</code>  数据集上进行微调以训练 <code>Captioner</code>  和 <code>Filter</code> ；</li>\n<li>然后使用 <code>Filter</code>  从原始网络文本和 <code>Captioner</code>  合成的文本中删除嘈杂的字幕，得到干净的数据；</li>\n<li>最后再使用干净的数据训练一遍得到高性能的 <code>BLIP</code> 。</li>\n</ul>\n<h1 id=\"四-参考程序\"><a class=\"markdownIt-Anchor\" href=\"#四-参考程序\">#</a> 四、参考程序</h1>\n<p>参考：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9TYWxlc2ZvcmNlL2JsaXAtaW1hZ2UtY2FwdGlvbmluZy1sYXJnZQ==\">https://huggingface.co/Salesforce/blip-image-captioning-large</span></p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">from</span> PIL <span class=\"token keyword\">import</span> Image</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> transformers <span class=\"token keyword\">import</span> BlipProcessor<span class=\"token punctuation\">,</span> BlipForConditionalGeneration</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>processor <span class=\"token operator\">=</span> BlipProcessor<span class=\"token punctuation\">.</span>from_pretrained<span class=\"token punctuation\">(</span><span class=\"token string\">\"E:/python/else/LLM_learn/5_BLIP/model\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>model <span class=\"token operator\">=</span> BlipForConditionalGeneration<span class=\"token punctuation\">.</span>from_pretrained<span class=\"token punctuation\">(</span><span class=\"token string\">\"E:/python/else/LLM_learn/5_BLIP/model\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span><span class=\"token string\">\"cuda\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>raw_image <span class=\"token operator\">=</span> Image<span class=\"token punctuation\">.</span><span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'1.jpg'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>convert<span class=\"token punctuation\">(</span><span class=\"token string\">'RGB'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token comment\"># conditional image captioning</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>text <span class=\"token operator\">=</span> <span class=\"token string\">\"a photography of\"</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>inputs <span class=\"token operator\">=</span> processor<span class=\"token punctuation\">(</span>raw_image<span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">,</span> return_tensors<span class=\"token operator\">=</span><span class=\"token string\">\"pt\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span><span class=\"token string\">\"cuda\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>out <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>generate<span class=\"token punctuation\">(</span><span class=\"token operator\">**</span>inputs<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>processor<span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> skip_special_tokens<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre></pre></td></tr><tr><td data-num=\"16\"></td><td><pre><span class=\"token comment\"># unconditional image captioning</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>inputs <span class=\"token operator\">=</span> processor<span class=\"token punctuation\">(</span>raw_image<span class=\"token punctuation\">,</span> return_tensors<span class=\"token operator\">=</span><span class=\"token string\">\"pt\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span><span class=\"token string\">\"cuda\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>out <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>generate<span class=\"token punctuation\">(</span><span class=\"token operator\">**</span>inputs<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>processor<span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> skip_special_tokens<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure>",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/09/12/AI/CLIP/",
            "url": "http://qianqiu-cell.github.io/2024/09/12/AI/CLIP/",
            "title": "CLIP",
            "date_published": "2024-09-11T16:00:00.000Z",
            "content_html": "<h1 id=\"一-简介\"><a class=\"markdownIt-Anchor\" href=\"#一-简介\">#</a> 一、简介</h1>\n<h2 id=\"11-前言\"><a class=\"markdownIt-Anchor\" href=\"#11-前言\">#</a> 1.1 前言</h2>\n<p>   <code>CLIP</code>  是 <code>OpenAI</code>  在 <code>2021</code>  年 <code>2</code>  月发表的一篇文章，其全称为 <code>Contrastive Language-Image Pre-training</code> ，即一种基于对比文本 - 图像对的预训练方法。 <code>CLIP</code>  用文本作为监督信号来训练可迁移的视觉模型，使得最终模型的 <code>zero-shot</code>  效果堪比 <code>ResNet50</code> ，泛化性非常好。</p>\n<p>   <code>zero-shot</code>  就是直接推理，用见过的图片特征去判断没见过的图片的类别，而完全不用下游任务训练集进行微调。（相当于把模型用作特征提取，但是没有分类头）</p>\n<p>  作者在 30 多个不同的计算机视觉数据集上进行基准测试，（这些数据集涵盖了 <code>OCR</code> ( <code>Optical Character Recognition</code> , 光学字符识别)、视频中的动作识别、地理定位和许多类型的细粒度对象分类等任务）， <code>CLIP</code>  通常都能够与监督模型的 <code>baseline</code>  效果相媲美。</p>\n<p>  例如在 <code>ImageNet</code>  数据集上， <code>CLIP</code>  模型在不使用 <code>ImageNet</code>  数据集的任何一张图片进行训练的的情况下，最终模型精度能跟一个有监督的训练好的 <code>ResNet-50</code>  打成平手（在 <code>ImageNet</code>  上 <code>zero-shot</code>  精度为 <code>76.2%</code> ，这在之前一度被认为是不可能的）。</p>\n<h2 id=\"12-自然语言监督的优势\"><a class=\"markdownIt-Anchor\" href=\"#12-自然语言监督的优势\">#</a> 1.2 自然语言监督的优势</h2>\n<p>  使用自然语言监督信号来训练视觉模型，有两个最重要的优势：</p>\n<ul>\n<li>\n<p><strong>不需要采用特别的标注数据</strong>，扩展性更强。比如 <code>ImageNet</code>  需要先定义好 <code>1000</code>  个类，然后根据这些类去下载图片，清理数据集，再去标注所有图片，过程很复杂。而 CLIP 不要求这种经典的 &quot;机器学习兼容&quot; 的标注格式，只需要下载文字 - 图片对；且没有 n 选 1 的标签之后，模型的输入输出自由度大了很多。</p>\n</li>\n<li>\n<p><code>CLIP</code>  学习到的是图像结合文字的多模态特征，从而<strong>实现灵活的 zero-shot 迁移</strong>。如果只是单模态的特征，无论是类似 <code>MOCO</code>  还是 <code>MAE</code> ，都很难做到这一点（ <code>zero-shot</code>  必须要加入文字特征才能做到）。</p>\n</li>\n</ul>\n<h1 id=\"13-总结\"><a class=\"markdownIt-Anchor\" href=\"#13-总结\">#</a> 1.3 总结</h1>\n<p>  现有的 <code>CV</code>  模型基本都是基于人工标注的数据集进行训练的，然后用来预测一组提前定义好的物体类别。这种提前定义好的标签集合，会大大简化问题本身（比如 <code>ImageNet</code>  固定的 <code>1000</code>  个类， <code>COCO</code>  数据集固定 <code>80</code>  个类等等）。但正因如此，这种受限的监督信号限制了模型的泛化性和可用性。比如大多数模型都只能预测已知的图像类别。对于没有见过的图像类别，需要额外的信息才能识别。这样<strong>每次新增一些类别，都需要重新收集数据，训练一个新的模型</strong>。</p>\n<p>  作者认为，直接从自然语言中得到监督信息是一个很有前途的选择，因为其涵盖的范围更广（只要是语言描述过的物体，都有可能让视觉模型去识别）。 <code>CLIP</code>  利用多模态的对比学习，使得自然语言可以引导模型学习到视觉概念，从而实现非常灵活的 <code>zero-shot</code>  迁移（把分类问题转化为了跨模态检索问题）。</p>\n<p>  之前使用自然语言监督进行图像表示学习的工作很少，并且效果往往不如有监督模型，主要有两个原因：</p>\n<ul>\n<li><strong>早期 nlp 模型不太好学</strong>。比如早期的 <code>n-gram</code>  模型非常复杂，不好跨模态训练。但是随着 <code>transformer</code>  的兴起，像 <code>BERT</code>  和 <code>GPT</code>  这种具有上下文表示的自监督训练模型做的越来越好， <code>nlp</code>  模型也终于有了取之不尽的文本监督信号，而且使用简单，泛化性好，为多模态训练铺平了道路。</li>\n<li>数据集或模型的规模不够。比如 <code>VirTex</code>  和 <code>ICMLM</code>  都只训练了<strong>十几万的图片</strong>； <code>ConVIRT</code>  非常类似 <code>CLIP</code> ，但<strong>只在医疗图像上做了预训练</strong>。从本质上来讲， <code>CLIP</code>  其实并没有太大的创新，它只是<strong>将 ConVIRT 方法进行简化，并采用更大规模的文本 - 图像对数据集来训练</strong>。也可以说，相对于之前的对比学习， <code>CLIP</code>  只是将单模态的样本，换成了多模态的样本。</li>\n</ul>\n<h1 id=\"二-方法\"><a class=\"markdownIt-Anchor\" href=\"#二-方法\">#</a> 二、方法</h1>\n<h2 id=\"21-模型结构\"><a class=\"markdownIt-Anchor\" href=\"#21-模型结构\">#</a> 2.1 模型结构</h2>\n<p>  如下图所示， <code>CLIP</code>  的输入是一对对配对好的的<strong>图片 - 文本对</strong>（比如输入是一张狗的图片，对应文本也表示这是一只狗）。这些文本和图片分别通过 <code>Text Encoder</code>  和 <code>Image Encoder</code>  输出对应的特征。然后在这些输出的文字特征和图片特征上进行<strong>对比学习</strong>。</p>\n<p><img data-src=\"/images/AI/CLIP/2.1.png\" alt=\"\"></p>\n<p>  假如模型输入的是<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span> 对图片 - 文本对，那么这<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span> 对互相配对的图像–文本对是<strong>正样本</strong>（下图输出特征矩阵对角线上标识蓝色的部位），其它<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>n</mi><mn>2</mn></msup><mo>−</mo><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n^2 - n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.897438em;vertical-align:-0.08333em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span> 对样本都是<strong>负样本</strong>。这样模型的训练过程就是最大化<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span> 个正样本的相似度，同时最小化<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>n</mi><mn>2</mn></msup><mo>−</mo><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n^2 - n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.897438em;vertical-align:-0.08333em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span> 个负样本的相似度。</p>\n<p>其中：</p>\n<ul>\n<li>\n<p><code>Text Encoder</code>  可以采用 <code>NLP</code>  中常用的 <code>text transformer</code>  模型；而 <code>Image Encoder</code>  可以采用常用 <code>CNN</code>  模型或者 <code>vision transformer</code>  等模型</p>\n</li>\n<li>\n<p>相似度是计算文本特征和图像特征的余弦相似性 <code>cosine similarity</code></p>\n</li>\n<li>\n<p>为了训练 <code>CLIP</code> ， <code>OpenAI</code>  从互联网收集了共<strong> 4 个亿的文本 - 图像对</strong>，论文称之为 <code>WIT(Web Image Text)</code> 。 <code>WIT</code>  质量很高，而且清理的非常好，其规模相当于 <code>JFT-300M</code> ，这也是 <code>CLIP</code>  如此强大的原因之一（后续在 <code>WIT</code>  上还孕育出了 <code>DALL-E</code>  模型）</p>\n</li>\n</ul>\n<p><strong>分类</strong></p>\n<p>   <code>CLIP</code>  可以直接实现 <code>zero-shot</code>  的图像分类，即不需要任何训练和微调，这也是 <code>CLIP</code>  亮点和强大之处。用 <code>CLIP</code>  实现 <code>zero-shot</code>  分类只需要简单的两步：</p>\n<ul>\n<li>\n<p><strong>根据任务的分类标签构建每个类别的描述文本</strong>： <code>A photo of &#123;label&#125;</code> ，然后将这些文本送入 <code>Text Encoder</code>  得到对应的文本特征。如果类别数目为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span>，那么将得到<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span> 个文本特征；</p>\n</li>\n<li>\n<p>将要预测的图像送入 <code>Image Encoder</code>  得到图像特征，然后与<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span> 个文本特征计算缩放的余弦相似度（和训练过程保持一致），然后<strong>选择相似度最大的文本对应的类别作为图像分类预测结果</strong>。进一步地，可以将这些相似度看成 <code>logits</code> ，送入 <code>softmax</code>  后可以到每个类别的预测概率。</p>\n</li>\n</ul>\n<p>  我们不再需要预先定义好的标签（类别）列表，直接将图片喂给不同的文本句子，就可以知道图片中是否有我们感兴趣的物体。即， <code>CLIP</code>  的多模态特性（利用文本监督信号）为具体的任务构建了动态的分类器，<strong>使得模型不再受限于预先定义好的类别，更加具有通用性和可用性</strong>。</p>\n<h2 id=\"22-预训练方法\"><a class=\"markdownIt-Anchor\" href=\"#22-预训练方法\">#</a> 2.2 预训练方法</h2>\n<p>   <code>CV</code>  领域的模型都很大，训练起来也很贵。比如 <code>noise student</code>  之前在 <code>ImageNet</code>  一直霸榜，但是这个模型需要在一个 <code>TPUv3</code>  上训练 <code>33</code>  年，这还只是在包含 <code>1000</code>  类的 <code>ImageNet</code>  上预训练的，而且只训练视觉特征。</p>\n<p>  由于训练数据量和模型计算量都很大，训练效率成为一个至关重要的因素。作者做了很多尝试，最终选择了对比学习：</p>\n<ul>\n<li>\n<p><code>VirTex</code>  模型：预测文本，对应下图蓝色线 <code>Transformer Language Model</code> ： <code>Image Encoder</code>  使用 <code>CNN</code>  模型， <code>Text Encoder</code>  使用 <code>transformer</code>  模型，两个模型一起从头训练，任务是预测图片对应的文本（ <code>image caption</code> ）。这种方法的训练效率太慢，因为根据图片进行文本描述，可能性太多了，你可以从各个角度去描述一张图片。</p>\n</li>\n<li>\n<p><code>Bag of Words Prediction</code> （橘色线）：不要求每个词都是按顺序的进行预测，所有词都预测出来就行。这样放宽了约束，训练速度提高了三倍。</p>\n</li>\n<li>\n<p><code>CLIP</code> ：简化版的 <code>ConVIRT</code> ，基于对比学习。只需要判断图文是否配对，进一步简化了训练任务，训练效率一下子提升 <code>4</code>  倍（绿色线）训练任务更加合理。因为训练数据所包含的文本 - 图像对是从互联网收集来的，它们存在一定的噪音，二者并不完全匹配。适当的降低训练目标，反而能取得更好的收敛。</p>\n</li>\n</ul>\n<p><img data-src=\"/images/AI/CLIP/2.2.png\" alt=\"\"></p>\n<p>(1)  <code>Text Encoder</code>  架构</p>\n<p>最终 <code>Text Encoder</code>  固定选择一个包含 <code>63M</code>  参数的 <code>text transformer</code>  模型，</p>\n<p>(2)  <code>Image Encoder</code>  架构</p>\n<ul>\n<li>\n<p><code>ResNet</code> ： <code>ResNet50</code> ， <code>ResNet101</code> ， <code>RN50x4</code> ， <code>RN50x16</code>  和 <code>RNx64</code> （后面三个模型是按照 <code>EfficientNet</code>  缩放规则对 <code>ResNet</code>  分别增大 <code>4x</code> ， <code>16x</code>  和 <code>64x</code>  得到）</p>\n</li>\n<li>\n<p><code>ViT</code> ： <code>ViT-B/32</code> ， <code>ViT-B/16</code>  和 <code>ViT-L/14</code> 。</p>\n</li>\n</ul>\n<p>(3) 所有的模型都训练 32 个 epochs，采用 AdamW 优化器，batch size=32768</p>\n<p>(4) 只在 ResNet50 上训练一个 epoch 进行超参搜索，没有进行进一步的调参</p>\n<p>(5) <strong>数据集非常大，几乎不会出现过拟合，所以 Image Encoder 和 Text Encoder 不需要提前进行预训练</strong>。</p>\n<p>(6) 只使用线性投射层（线性非线性影响不大）</p>\n<p>(7) 数据增强只使用图片的随机剪裁，这是因为数据集非常大</p>\n<p>(8) 对比学习目标函数中的超参数 τ，设置成可学习的标量，在训练中自动优化，而不用慢慢调参（还是因为数据集太大，训练很贵）。</p>\n<h2 id=\"23-伪代码\"><a class=\"markdownIt-Anchor\" href=\"#23-伪代码\">#</a> 2.3 伪代码</h2>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># image_encoder - ResNet or Vision Transformer</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\"># text_encoder - CBOW or Text Transformer</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\"># I [n, h, w, c] - 输入图片维度</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># T [n, l] - 输入文本维度，l 表示序列长度</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\"># W_i[d_i, d_e] - learned proj of image to embed</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token comment\"># W_t[d_t, d_e] - learned proj of text to embed</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token comment\"># t - learned temperature parameter</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\">#  分别提取图像特征和文本特征</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>I_f <span class=\"token operator\">=</span> image_encoder<span class=\"token punctuation\">(</span>I<span class=\"token punctuation\">)</span> <span class=\"token comment\">#[n, d_i]</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>T_f <span class=\"token operator\">=</span> text_encoder<span class=\"token punctuation\">(</span>T<span class=\"token punctuation\">)</span> <span class=\"token comment\">#[n, d_t]</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token comment\"># 对两个特征进行线性投射，得到相同维度的特征 d_e，并进行 l2 归一化，保持数据尺度的一致性</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre><span class=\"token comment\"># 多模态 embedding [n, d_e]</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>I_e <span class=\"token operator\">=</span> l2_normalize<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>I_f<span class=\"token punctuation\">,</span> W_i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>T_e <span class=\"token operator\">=</span> l2_normalize<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>T_f<span class=\"token punctuation\">,</span> W_t<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre></pre></td></tr><tr><td data-num=\"19\"></td><td><pre><span class=\"token comment\"># 计算缩放的余弦相似度：[n, n]</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>logits <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>I_e<span class=\"token punctuation\">,</span> T_e<span class=\"token punctuation\">.</span>T<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> np<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>t<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre></pre></td></tr><tr><td data-num=\"22\"></td><td><pre><span class=\"token comment\"># symmetric loss function</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>labels <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">)</span> <span class=\"token comment\">#  对角线元素的 labels</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>loss_i <span class=\"token operator\">=</span> cross_entropy_loss<span class=\"token punctuation\">(</span>logits<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># image loss</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>loss_t <span class=\"token operator\">=</span> cross_entropy_loss<span class=\"token punctuation\">(</span>logits<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># text loss</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>loss <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>loss_i <span class=\"token operator\">+</span> loss_t<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token number\">2</span> <span class=\"token comment\"># 对称式的目标函数</span></pre></td></tr></table></figure><p>  在 <code>MOCO</code>  中，真实标签都是 <code>0</code> ，因为其正样本都是放在第一位，所以正样本对应的索引永远是 <code>0</code> ；但是在 <code>CLIP</code>  中，正样本都是在对角线上，即<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>I</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>T</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>I</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><msub><mi>T</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>…</mo></mrow><annotation encoding=\"application/x-tex\">I_1,T_1,I_2,T_2,\\dots</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">…</span></span></span></span>，所以真实标签为 <code>np.arange(n)</code> 。</p>\n<h1 id=\"三-参考程序\"><a class=\"markdownIt-Anchor\" href=\"#三-参考程序\">#</a> 三、参考程序</h1>\n<p>参考：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9vcGVuYWkvY2xpcC12aXQtbGFyZ2UtcGF0Y2gxNA==\">https://huggingface.co/openai/clip-vit-large-patch14</span></p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">from</span> PIL <span class=\"token keyword\">import</span> Image</pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">from</span> transformers <span class=\"token keyword\">import</span> CLIPProcessor<span class=\"token punctuation\">,</span> CLIPModel</pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>model <span class=\"token operator\">=</span> CLIPModel<span class=\"token punctuation\">.</span>from_pretrained<span class=\"token punctuation\">(</span><span class=\"token string\">\"E:/python/else/LLM_learn/4_CLIP/model\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>processor <span class=\"token operator\">=</span> CLIPProcessor<span class=\"token punctuation\">.</span>from_pretrained<span class=\"token punctuation\">(</span><span class=\"token string\">\"E:/python/else/LLM_learn/4_CLIP/model\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>image <span class=\"token operator\">=</span> Image<span class=\"token punctuation\">.</span><span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'1.jpg'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>inputs <span class=\"token operator\">=</span> processor<span class=\"token punctuation\">(</span>text<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"a photo of a cat\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"a photo of a dog\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> images<span class=\"token operator\">=</span>image<span class=\"token punctuation\">,</span> return_tensors<span class=\"token operator\">=</span><span class=\"token string\">\"pt\"</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>outputs <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span><span class=\"token operator\">**</span>inputs<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>logits_per_image <span class=\"token operator\">=</span> outputs<span class=\"token punctuation\">.</span>logits_per_image  <span class=\"token comment\"># this is the image-text similarity score</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>logits_per_image<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>probs <span class=\"token operator\">=</span> logits_per_image<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>dim<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># we can take the softmax to get the label probabilities</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>probs<span class=\"token punctuation\">)</span></pre></td></tr></table></figure>",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/08/26/AI/DiffusionModel/",
            "url": "http://qianqiu-cell.github.io/2024/08/26/AI/DiffusionModel/",
            "title": "扩散模型",
            "date_published": "2024-08-25T16:00:00.000Z",
            "content_html": "<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RGQ0VEL2FydGljbGUvZGV0YWlscy8xMzIzOTQ4OTU=\">https://blog.csdn.net/DFCED/article/details/132394895</span>、<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVFBZXhlaUVaSz9wPTImYW1wO3ZkX3NvdXJjZT1lMDExNzJlYTI5MmMxYzYwNWIzNDYxMDFkNzAwNmM2MQ==\">https://www.bilibili.com/video/BV1QAexeiEZK?p=2&amp;vd_source=e01172ea292c1c605b346101d7006c61</span></p>\n<p>  扩散概率模型（为简洁起见，我们称之为 “扩散模型”）是一种通过参数化的马尔科夫链，并使用变分推断进行训练，以在有限时间后生成与数据相匹配的样本。该链的转换过程旨在学习逆向扩散过程，即一个马尔科夫链，该链逐步向数据中添加噪声，方向与采样相反，直到信号完全被破坏。</p>\n<h1 id=\"一-直观理解\"><a class=\"markdownIt-Anchor\" href=\"#一-直观理解\">#</a> 一、直观理解</h1>\n<p>  从概率分布角度来看，考虑下图瑞士卷形状的二维联合概率分布 P (x,y)，扩散过程 q 非常直观，本来集中有序的样本点，受到噪声的扰动，向外扩散，最终变成一个完全无序的噪声分布。</p>\n<p><img data-src=\"/images/AI/DiffusionModel/1.1.png\" alt=\"\"></p>\n<p>  而 diffusion model 表示上图的逆过程 p，将一个噪声分布 N (0,1) 逐步的去噪以映射到原始图像。有了这样的映射，就可以从噪声分布中采样，最终得到一张想要的图像，也就是完成了生成的任务。</p>\n<p>  Diffusion Models 由正向过程（或扩散过程）和反向过程（或逆扩散过程）组成，其中输入数据逐渐被噪声化，然后噪声被转换回源目标分布的样本。从单个图像样本来看这个过程，扩散过程 q 就是不断向图像上加噪声，直到图像变成一个纯噪声，逆扩散过程 p 就是从纯噪声生成一张图像的过程。下图表示了单个样本图像的变化：</p>\n<p><img data-src=\"/images/AI/DiffusionModel/1.2.png\" alt=\"\"></p>\n<p>  一些相关的概念：</p>\n<ul>\n<li>后验概率：在贝叶斯统计中，一个随机事件或者一个不确定事件的后验概率（Posterior probability）是在考虑和给出相关证据或数据后所得到的条件概率。</li>\n<li>马尔可夫链：为状态空间中经过从一个状态到另一个状态的转换的随机过程。该过程要求具备 “无记忆” 的性质：下一状态的概率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关。这种特定类型的 “无记忆性 “称作马可夫性质。</li>\n</ul>\n<h1 id=\"二-前向过程扩散过程\"><a class=\"markdownIt-Anchor\" href=\"#二-前向过程扩散过程\">#</a> 二、前向过程（扩散过程）</h1>\n<p>  所谓前向过程，即往图片上加噪声的过程。虽然这个步骤无法做到图片生成，但是这是理解 diffusion model 以及构建训练样本至关重要的一步。</p>\n<p>  给定真实图片样本 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub><mo>∼</mo><mi>q</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">x_{0}\\sim q(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∼</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span>，diffusion 前向过程通过<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span></span></span></span> 次累计对其添加高斯噪声，得到<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>x</mi><mn>2</mn></msub><mtext>，</mtext><mo>…</mo><mo separator=\"true\">,</mo><msub><mi>x</mi><mi>T</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_1, x_2，\\dots, x_T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">，</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">…</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，如下图的 q 过程。每一步的大小是由一系列的高斯分布方差的超参数<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">{</mo><msub><mi>β</mi><mi>t</mi></msub><mo>∈</mo><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo stretchy=\"false\">)</mo><msubsup><mo stretchy=\"false\">}</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">\\{\\beta_t\\in(0,1)\\}_{t=1}^T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">{</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0913309999999998em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mclose\"><span class=\"mclose\">}</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.24810799999999997em;\"><span></span></span></span></span></span></span></span></span></span> 来控制的。前向过程由于每个时刻<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span> 只与<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">t-1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69841em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> 时刻有关，所以也可以看做马尔科夫过程：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>q</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>t</mi></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mi mathvariant=\"script\">N</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo separator=\"true\">;</mo><msqrt><mrow><mn>1</mn><mo>−</mo><msub><mi>β</mi><mi>t</mi></msub></mrow></msqrt><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator=\"true\">,</mo><msub><mi>β</mi><mi>t</mi></msub><mi mathvariant=\"bold\">I</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">q(x_t|x_{t-1})=\\mathcal{N}(x_t;\\sqrt{1-\\beta_t}x_{t-1},\\beta_t\\mathbf{I})\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.24em;vertical-align:-0.25612499999999994em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14736em;\">N</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.983875em;\"><span class=\"svg-align\" style=\"top:-3.2em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.9438750000000002em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.28em;\"><svg width='400em' height='1.28em' viewBox='0 0 400000 1296' preserveAspectRatio='xMinYMin slice'><path d='M263,681c0.7,0,18,39.7,52,119\nc34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120\nc340,-704.7,510.7,-1060.3,512,-1067\nl0 -0\nc4.7,-7.3,11,-11,19,-11\nH40000v40H1012.3\ns-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232\nc-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1\ns-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26\nc-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z\nM1001 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.25612499999999994em;\"><span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathbf\">I</span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>q</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>T</mi></mrow></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>x</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo><mo>=</mo><munderover><mo>∏</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><mi>q</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>t</mi></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">q(x_{1:T}|x_0)=\\prod_{t=1}^Tq(x_t|x_{t-1})\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mrel mtight\">:</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:3.0954490000000003em;vertical-align:-1.267113em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.8283360000000002em;\"><span style=\"top:-1.882887em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∏</span></span></span><span style=\"top:-4.3000050000000005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.267113em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>  这个过程中，随着<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span> 的增大，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 越来越接近纯噪声。当<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mo>⇒</mo><mi mathvariant=\"normal\">∞</mi></mrow><annotation encoding=\"application/x-tex\">T\\Rightarrow \\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">⇒</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord\">∞</span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>T</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 是完全的高斯噪声。</p>\n<p>  前向过程介绍结束前，需要讲述一下 diffusion 在实现和推导过程中要用到的两个重要特性。</p>\n<ul>\n<li>特性 1：重参数 （reparameterization trick）</li>\n</ul>\n<p>  重参数技巧在很多工作（gumbel softmax, VAE）中有所引用。如果我们要从某个分布中随机采样（高斯分布）一个样本，<mark>这个过程是无法反传梯度的</mark>。而这个通过高斯噪声采样得到<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 的过程在 diffusion 中到处都是，因此我们需要通过重参数技巧来使得他可微。最通常的做法是把随机性通过一个独立的随机变量（$\\epsilon <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mtext>）引导过去。即如果要从高斯分布</mtext></mrow><annotation encoding=\"application/x-tex\">）引导过去。即如果要从高斯分布</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord cjk_fallback\">）</span><span class=\"mord cjk_fallback\">引</span><span class=\"mord cjk_fallback\">导</span><span class=\"mord cjk_fallback\">过</span><span class=\"mord cjk_fallback\">去</span><span class=\"mord cjk_fallback\">。</span><span class=\"mord cjk_fallback\">即</span><span class=\"mord cjk_fallback\">如</span><span class=\"mord cjk_fallback\">果</span><span class=\"mord cjk_fallback\">要</span><span class=\"mord cjk_fallback\">从</span><span class=\"mord cjk_fallback\">高</span><span class=\"mord cjk_fallback\">斯</span><span class=\"mord cjk_fallback\">分</span><span class=\"mord cjk_fallback\">布</span></span></span></span> z\\sim\\mathcal<ruby>N}(z;\\mu_\\theta,\\sigma_\\theta<rp>【</rp><rt>2\\mathbf{I</rt><rp>】</rp></ruby>)<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mtext>采样一个</mtext></mrow><annotation encoding=\"application/x-tex\">采样一个</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord cjk_fallback\">采</span><span class=\"mord cjk_fallback\">样</span><span class=\"mord cjk_fallback\">一</span><span class=\"mord cjk_fallback\">个</span></span></span></span> z$，我们可以写成：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>z</mi><mo>=</mo><msub><mi>μ</mi><mi>θ</mi></msub><mo>+</mo><msub><mi>σ</mi><mi>θ</mi></msub><mo>⊙</mo><mi>ϵ</mi><mo separator=\"true\">,</mo><mi>ϵ</mi><mo>∼</mo><mi mathvariant=\"script\">N</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mi mathvariant=\"bold\">I</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">z=\\mu_\\theta+\\sigma_\\theta\\odot\\epsilon,\\epsilon\\sim\\mathcal{N}(0,\\mathbf{I})\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7777700000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">μ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⊙</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">ϵ</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">ϵ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∼</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14736em;\">N</span></span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">I</span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>  上式的<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>z</mi></mrow><annotation encoding=\"application/x-tex\">z</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span></span></span></span> 依旧是有随机性的，且满足均值为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>μ</mi><mi>θ</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\mu_\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">μ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 方差为<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>σ</mi><mi>θ</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\sigma_\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 的高斯分布。这里的<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>μ</mi><mi>θ</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\mu_\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">μ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>σ</mi><mi>θ</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\sigma_\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 可以是由神经网络推断得到的。整个 “采样” 过程依旧梯度可导，随机性被转嫁到了 $\\epsilon $ 上。</p>\n<ul>\n<li>特征 2：任意时刻的<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 可由<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>β</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\beta_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 表示</li>\n</ul>\n<p>  在前向过程中，有一个性质非常棒，就是我们其实可以通过<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>β</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\beta_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 直接得到<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>。首先我们令<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>α</mi><mi>t</mi></msub><mo>=</mo><mn>1</mn><mo>−</mo><msub><mi>β</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\alpha_t=1-\\beta_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，并且<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mover accent=\"true\"><mi>α</mi><mo stretchy=\"true\">‾</mo></mover><mi>t</mi></msub><mo>=</mo><msubsup><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>t</mi></msubsup><msub><mi>α</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\overline{\\alpha}_t=\\prod_{i=1}^t\\alpha_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.78056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord overline\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.63056em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span><span style=\"top:-3.55056em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"overline-line\" style=\"border-bottom-width:0.04em;\"></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.233166em;vertical-align:-0.29971000000000003em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∏</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.933456em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，展开<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 可以得到：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mtable rowspacing=\"0.24999999999999992em\" columnalign=\"right left\" columnspacing=\"0em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><msub><mi mathvariant=\"bold\">x</mi><mi>t</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><msqrt><msub><mi>α</mi><mi>t</mi></msub></msqrt><msub><mi mathvariant=\"bold\">x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msqrt><mrow><mn>1</mn><mo>−</mo><msub><mi>α</mi><mi>t</mi></msub></mrow></msqrt><msub><mi mathvariant=\"bold-italic\">ϵ</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><msqrt><mrow><msub><mi>α</mi><mi>t</mi></msub><msub><mi>α</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></msqrt><msub><mi mathvariant=\"bold\">x</mi><mrow><mi>t</mi><mo>−</mo><mn>2</mn></mrow></msub><mo>+</mo><msqrt><mrow><mn>1</mn><mo>−</mo><msub><mi>α</mi><mi>t</mi></msub><msub><mi>α</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></msqrt><msub><mover accent=\"true\"><mi mathvariant=\"bold-italic\">ϵ</mi><mo>ˉ</mo></mover><mrow><mi>t</mi><mo>−</mo><mn>2</mn></mrow></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mo>…</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><msqrt><msub><mover accent=\"true\"><mi>α</mi><mo>ˉ</mo></mover><mi>t</mi></msub></msqrt><msub><mi mathvariant=\"bold\">x</mi><mn>0</mn></msub><mo>+</mo><msqrt><mrow><mn>1</mn><mo>−</mo><msub><mover accent=\"true\"><mi>α</mi><mo>ˉ</mo></mover><mi>t</mi></msub></mrow></msqrt><mi mathvariant=\"bold-italic\">ϵ</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding=\"application/x-tex\">\\begin{aligned}\n\\mathbf{x}_{t}&amp; =\\sqrt{\\alpha_t}\\mathbf{x}_{t-1}+\\sqrt{1-\\alpha_t}\\boldsymbol{\\epsilon}_{t-1} \\\\\n&amp;=\\sqrt{\\alpha_t\\alpha_{t-1}}\\mathbf{x}_{t-2}+\\sqrt{1-\\alpha_t\\alpha_{t-1}}\\bar{\\boldsymbol{\\epsilon}}_{t-2} \\\\\n&amp;=\\ldots \\\\\n&amp;=\\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0+\\sqrt{1-\\bar{\\alpha}_t}\\boldsymbol{\\epsilon}\n\\end{aligned}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:6.194119500000001em;vertical-align:-2.8470597500000006em;\"></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-r\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.3470597500000006em;\"><span style=\"top:-5.46596475em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.8540352500000004em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"></span></span><span style=\"top:-2.35403525em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"></span></span><span style=\"top:-0.8129402499999996em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.8470597500000006em;\"><span></span></span></span></span></span><span class=\"col-align-l\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.3470597500000006em;\"><span style=\"top:-5.46596475em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.774155em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.734155em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.265845em;\"><span></span></span></span></span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8810950000000001em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.841095em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15890499999999996em;\"><span></span></span></span></span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">ϵ</span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.8540352500000004em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7449895em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.7049895em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2950105em;\"><span></span></span></span></span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9519294999999999em;\"><span class=\"svg-align\" style=\"top:-3.2em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.9119295000000003em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.28em;\"><svg width='400em' height='1.28em' viewBox='0 0 400000 1296' preserveAspectRatio='xMinYMin slice'><path d='M263,681c0.7,0,18,39.7,52,119\nc34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120\nc340,-704.7,510.7,-1060.3,512,-1067\nl0 -0\nc4.7,-7.3,11,-11,19,-11\nH40000v40H1012.3\ns-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232\nc-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1\ns-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26\nc-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z\nM1001 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2880705000000001em;\"><span></span></span></span></span></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.58122em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">ϵ</span></span></span></span></span><span style=\"top:-3.01344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.25em;\"><span class=\"mord\">ˉ</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.35403525em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"minner\">…</span></span></span><span style=\"top:-0.8129402499999996em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.842765em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.56778em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">ˉ</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.802765em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19723500000000005em;\"><span></span></span></span></span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8810950000000001em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.56778em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">ˉ</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.841095em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15890499999999996em;\"><span></span></span></span></span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">ϵ</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.8470597500000006em;\"><span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p>  因此，任意时刻的<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 满足：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>q</mi><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"bold\">x</mi><mi>t</mi></msub><mi mathvariant=\"normal\">∣</mi><msub><mi mathvariant=\"bold\">x</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mi mathvariant=\"script\">N</mi><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"bold\">x</mi><mi>t</mi></msub><mo separator=\"true\">;</mo><msqrt><msub><mover accent=\"true\"><mi>α</mi><mo>ˉ</mo></mover><mi>t</mi></msub></msqrt><msub><mi mathvariant=\"bold\">x</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><msub><mover accent=\"true\"><mi>α</mi><mo>ˉ</mo></mover><mi>t</mi></msub><mo stretchy=\"false\">)</mo><mi mathvariant=\"bold\">I</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">q(\\mathbf{x}_t|\\mathbf{x}_0)=\\mathcal{N}(\\mathbf{x}_t;\\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0,(1-\\bar{\\alpha}_t)\\mathbf{I})\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.092765em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14736em;\">N</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.842765em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.56778em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">ˉ</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.802765em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19723500000000005em;\"><span></span></span></span></span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.56778em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">ˉ</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathbf\">I</span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<h1 id=\"三-反向过程逆扩散过程\"><a class=\"markdownIt-Anchor\" href=\"#三-反向过程逆扩散过程\">#</a> 三、反向过程（逆扩散过程）</h1>\n<p>  如果说前向过程（forward）是加噪的过程，那么逆向过程（reverse） 就是 diffusion 的去噪推断过程。</p>\n<p>  如果我们能够逆转上述过程并从<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>∣</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">q(x_{t-1}\\mid x_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∣</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 采样，就可以从高斯噪声<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>T</mi></msub><mo>∼</mo><mi mathvariant=\"script\">N</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mi mathvariant=\"bold\">I</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">x_{T}\\sim\\mathcal{N}(0,\\mathbf{I})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∼</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14736em;\">N</span></span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">I</span></span><span class=\"mclose\">)</span></span></span></span> 还原出原图分布<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub><mo>∼</mo><mi>q</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">x_0 \\sim q(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∼</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span>。在文献 7 中证明了如果<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo>∣</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">q(x_{t}\\mid x_{t-1})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∣</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 满足高斯分布且<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>β</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\beta_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 足够小，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>∣</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">q(x_{t-1}\\mid x_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∣</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 仍然是一个高斯分布。然而我们无法简单推断<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>∣</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">q(x_{t-1}\\mid x_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∣</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>，因此我们使用深度学习模型（参数力<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span></span></span></span>，目前主流是 U-Net + attention 的结构）去预测这样的一个逆向的分布<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>p</mi><mi>θ</mi></msub></mrow><annotation encoding=\"application/x-tex\">p_{\\theta}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>（类似 VAE）：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mn>0</mn><mo>:</mo><mi>T</mi></mrow></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mi>p</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>T</mi></msub><mo stretchy=\"false\">)</mo><munderover><mo>∏</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo><mo separator=\"true\">;</mo></mrow><annotation encoding=\"application/x-tex\">p_\\theta(x_{0:T})=p(x_T)\\prod_{t=1}^Tp_\\theta(x_{t-1}|x_t);\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span><span class=\"mrel mtight\">:</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:3.0954490000000003em;vertical-align:-1.267113em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.8283360000000002em;\"><span style=\"top:-1.882887em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∏</span></span></span><span style=\"top:-4.3000050000000005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.267113em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mpunct\">;</span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mi mathvariant=\"script\">N</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator=\"true\">;</mo><msub><mi>μ</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo separator=\"true\">,</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msub><mi mathvariant=\"normal\">Σ</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo separator=\"true\">,</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">.</mi></mrow><annotation encoding=\"application/x-tex\">p_\\theta(x_{t-1}|x_t)=\\mathcal{N}(x_{t-1};\\mu_\\theta(x_t,t),\\Sigma_\\theta(x_t,t)).\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14736em;\">N</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">μ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\">Σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mord\">.</span></span></span></span></span></p>\n<p>  由此可以发现其实正向扩散和逆扩散过程都是马尔可夫，然后正态分布，然后一步一步条件概率的框架。唯一的区别就是正向扩散里每一个条件概率的高斯分布的均值和方差都是<br>\n已经确定的（依赖于<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>β</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\beta_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>），而逆扩散过程里面的均值和方差是我们网络要学出来。</p>\n<h2 id=\"逆扩散条件概率推导\"><a class=\"markdownIt-Anchor\" href=\"#逆扩散条件概率推导\">#</a> 逆扩散条件概率推导</h2>\n<p>  虽然我们无法得到逆转过程的概率分布<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>∣</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">q(x_{t-1}\\mid x_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∣</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>，但是如果知道<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>∣</mo><msub><mi>x</mi><mi>t</mi></msub><mo separator=\"true\">,</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">q(x_{t-1}\\mid x_t,x_0)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∣</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 就可以直接写出，大概形式如下：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>q</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>x</mi><mi>t</mi></msub><mo separator=\"true\">,</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mi mathvariant=\"script\">N</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator=\"true\">;</mo><mover accent=\"true\"><mi>μ</mi><mo>~</mo></mover><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo separator=\"true\">,</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msub><mover accent=\"true\"><mi>β</mi><mo>~</mo></mover><mi>t</mi></msub><mi mathvariant=\"bold\">I</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">q(x_{t-1}|x_t,x_0)=\\mathcal{N}(x_{t-1};\\tilde{\\mu}(x_t,x_0),\\tilde{\\beta}_t\\mathbf{I})\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1812999999999998em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14736em;\">N</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">μ</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9312999999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span></span></span><span style=\"top:-3.61344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.16666em;\"><span class=\"mord\">~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathbf\">I</span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>  通过一定的计算可以得到上式中的均值和方差为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mover accent=\"true\"><mi>β</mi><mo>~</mo></mover><mi>t</mi></msub><mo>=</mo><mfrac><mrow><mn>1</mn><mo>−</mo><msub><mover accent=\"true\"><mi>α</mi><mo>ˉ</mo></mover><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><mrow><mn>1</mn><mo>−</mo><msub><mover accent=\"true\"><mi>α</mi><mo>ˉ</mo></mover><mi>t</mi></msub></mrow></mfrac><mo>⋅</mo><msub><mi>β</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\tilde{\\beta}_t=\\frac{1-\\bar{\\alpha}_{t-1}}{1-\\bar{\\alpha}_t}\\cdot\\beta_t\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1257399999999997em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9312999999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span></span></span><span style=\"top:-3.61344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.16666em;\"><span class=\"mord\">~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.1574400000000002em;vertical-align:-0.8360000000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.3139999999999996em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.56778em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">ˉ</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.56778em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">ˉ</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8360000000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mover accent=\"true\"><mi>μ</mi><mo>~</mo></mover><mi>t</mi></msub><mo>=</mo><mfrac><mn>1</mn><msqrt><msub><mi>α</mi><mi>t</mi></msub></msqrt></mfrac><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo>−</mo><mfrac><mrow><mn>1</mn><mo>−</mo><msub><mi>α</mi><mi>t</mi></msub></mrow><msqrt><mrow><mn>1</mn><mo>−</mo><msub><mover accent=\"true\"><mi>α</mi><mo stretchy=\"true\">‾</mo></mover><mi>t</mi></msub></mrow></msqrt></mfrac><msub><mi>ϵ</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\tilde{\\mu}_t=\\frac1{\\sqrt{\\alpha_t}}(x_t-\\frac{1-\\alpha_t}{\\sqrt{1-\\overline{\\alpha}_t}}\\epsilon_t)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8622999999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">μ</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.3221600000000002em;vertical-align:-1.00072em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.72528em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.68528em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31472em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\">1</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.00072em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.25144em;vertical-align:-0.93em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.27778em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8322200000000001em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord overline\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.63056em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span><span style=\"top:-3.55056em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"overline-line\" style=\"border-bottom-width:0.04em;\"></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.79222em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.20777999999999996em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.93em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\"><span class=\"mord mathnormal\">ϵ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>  可以看出，在给定<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 的条件下，后验条件高斯分布的均值只和超参数，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding=\"application/x-tex\">\\epsilon</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">ϵ</span></span></span></span> 有关，方差只与超参数有关。</p>\n<h1 id=\"四-训练损失\"><a class=\"markdownIt-Anchor\" href=\"#四-训练损失\">#</a> 四、训练损失</h1>\n<p>  了解了上述逆扩散过程之后，如何训练 Diffusion Models 以求得后验条件高斯分布的均值<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>μ</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo separator=\"true\">,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\mu_{\\theta}(x_t,t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">μ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span></span></span></span> 和方差<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi mathvariant=\"normal\">Σ</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo separator=\"true\">,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\Sigma_{\\theta}(x_t,t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\">Σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span></span></span></span> 呢？</p>\n<p>  对于真实的训练样本数据已知，要求模型的参数，可以使用极大似然估计。Diffusion Models 通过极大似然估计，来找到逆扩散过程中马尔可夫链转换的概率分布，这就是 Diffusion Models 的训练目的。即最大化模型预测分布的对数似然，从 Loss 下降的角度就是最小化负对数似然：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi mathvariant=\"script\">L</mi><mo>=</mo><msub><mi mathvariant=\"double-struck\">E</mi><mi>q</mi></msub><mo stretchy=\"false\">[</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">\\mathcal{L}=\\mathbb{E}_q[-\\log p_\\theta(x_0)]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathcal\">L</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mopen\">[</span><span class=\"mord\">−</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mclose\">]</span></span></span></span></span></p>\n<p>  通过一定的推导可以得到如下损失函数：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mtable rowspacing=\"0.24999999999999992em\" columnalign=\"right left\" columnspacing=\"0em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><msub><mi>L</mi><mi>t</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><msub><mi mathvariant=\"double-struck\">E</mi><mrow><msub><mi mathvariant=\"bold\">x</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><mi>ϵ</mi></mrow></msub><mrow><mo fence=\"true\">[</mo><msup><mrow><mo fence=\"true\">∥</mo><mfrac><mn>1</mn><msqrt><msub><mi>α</mi><mi>t</mi></msub></msqrt></mfrac><mrow><mo fence=\"true\">(</mo><msub><mi mathvariant=\"bold\">x</mi><mi>t</mi></msub><mo>−</mo><mfrac><msub><mi>β</mi><mi>t</mi></msub><msqrt><mrow><mn>1</mn><mo>−</mo><msub><mover accent=\"true\"><mi>α</mi><mo>ˉ</mo></mover><mi>t</mi></msub></mrow></msqrt></mfrac><mi>ϵ</mi><mo fence=\"true\">)</mo></mrow><mo>−</mo><mfrac><mn>1</mn><msqrt><msub><mi>α</mi><mi>t</mi></msub></msqrt></mfrac><mrow><mo fence=\"true\">(</mo><msub><mi mathvariant=\"bold\">x</mi><mi>t</mi></msub><mo>−</mo><mfrac><msub><mi>β</mi><mi>t</mi></msub><msqrt><mrow><mn>1</mn><mo>−</mo><msub><mover accent=\"true\"><mi>α</mi><mo>ˉ</mo></mover><mi>t</mi></msub></mrow></msqrt></mfrac><msub><mi>ϵ</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"bold\">x</mi><mi>t</mi></msub><mo separator=\"true\">,</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo fence=\"true\">)</mo></mrow><mo fence=\"true\">∥</mo></mrow><mn>2</mn></msup><mo fence=\"true\">]</mo></mrow><mspace width=\"1em\"/><mi>ϵ</mi><mo>∼</mo><mi mathvariant=\"script\">N</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><msub><mi mathvariant=\"double-struck\">E</mi><mrow><msub><mi mathvariant=\"bold\">x</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><mi>ϵ</mi></mrow></msub><mrow><mo fence=\"true\">[</mo><msup><mrow><mo fence=\"true\">∥</mo><mi>ϵ</mi><mo>−</mo><msub><mi>ϵ</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"bold\">x</mi><mi>t</mi></msub><mo separator=\"true\">,</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo fence=\"true\">∥</mo></mrow><mn>2</mn></msup><mo fence=\"true\">]</mo></mrow><mspace width=\"1em\"/><mi>ϵ</mi><mo>∼</mo><mi mathvariant=\"script\">N</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><msub><mi mathvariant=\"double-struck\">E</mi><mrow><msub><mi mathvariant=\"bold\">x</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><mi>ϵ</mi></mrow></msub><mrow><mo fence=\"true\">[</mo><msup><mrow><mo fence=\"true\">∥</mo><mi>ϵ</mi><mo>−</mo><msub><mi>ϵ</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><msqrt><msub><mover accent=\"true\"><mi>α</mi><mo stretchy=\"true\">‾</mo></mover><mi>t</mi></msub></msqrt><msub><mi mathvariant=\"bold\">x</mi><mn>0</mn></msub><mo>+</mo><msqrt><mrow><mn>1</mn><mo>−</mo><msub><mover accent=\"true\"><mi>α</mi><mo stretchy=\"true\">‾</mo></mover><mi>t</mi></msub></mrow></msqrt><mi>ϵ</mi><mo separator=\"true\">,</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo fence=\"true\">∥</mo></mrow><mn>2</mn></msup><mo fence=\"true\">]</mo></mrow><mo separator=\"true\">,</mo><mspace width=\"1em\"/><mi>ϵ</mi><mo>∼</mo><mi mathvariant=\"script\">N</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding=\"application/x-tex\">\\begin{aligned}\nL_{t}&amp; =\\mathbb{E}_{\\mathbf{x}_{0},\\epsilon}\\left[\\left\\|\\frac{1}{\\sqrt{\\alpha_{t}}}\\left(\\mathbf{x}_{t}-\\frac{\\beta_{t}}{\\sqrt{1-\\bar{\\alpha}_{t}}}\\epsilon\\right)-\\frac{1}{\\sqrt{\\alpha_{t}}}\\left(\\mathbf{x}_{t}-\\frac{\\beta_{t}}{\\sqrt{1-\\bar{\\alpha}_{t}}}\\epsilon_{\\theta}(\\mathbf{x}_{t},t)\\right)\\right\\|^{2}\\right]\\quad\\epsilon\\sim\\mathcal{N}(0,1) \\\\\n&amp;=\\mathbb{E}_{\\mathbf{x}_0,\\epsilon}\\left[\\left\\|\\epsilon-\\epsilon_\\theta(\\mathbf{x}_t,t)\\right\\|^2\\right]\\quad\\epsilon\\sim\\mathcal{N}(0,1) \\\\\n&amp;=\\mathbb{E}_{\\mathbf{x}_0,\\epsilon}\\left[\\left\\|\\epsilon-\\epsilon_\\theta(\\sqrt{\\overline{\\alpha}_t}\\mathbf{x}_0+\\sqrt{1-\\overline{\\alpha}_t}\\epsilon,t)\\right\\|^2\\right],\\quad\\epsilon\\sim\\mathcal{N}(0,1)\n\\end{aligned}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:7.500070000000001em;vertical-align:-3.5000350000000005em;\"></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-r\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:4.0000350000000005em;\"><span style=\"top:-6.0000350000000005em;\"><span class=\"pstrut\" style=\"height:3.75em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.3000050000000005em;\"><span class=\"pstrut\" style=\"height:3.75em;\"></span><span class=\"mord\"></span></span><span style=\"top:-1.1999849999999996em;\"><span class=\"pstrut\" style=\"height:3.75em;\"></span><span class=\"mord\"></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.5000350000000005em;\"><span></span></span></span></span></span><span class=\"col-align-l\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:4.0000350000000005em;\"><span style=\"top:-6.0000350000000005em;\"><span class=\"pstrut\" style=\"height:3.75em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.16110799999999997em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathbf mtight\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31731428571428577em;\"><span style=\"top:-2.357em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\">ϵ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size4\">[</span></span><span class=\"minner\"><span class=\"minner\"><span class=\"mopen\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.4799700000000002em;\"><span style=\"top:-1.65598em;\"><span class=\"pstrut\" style=\"height:2.606em;\"></span><span class=\"delimsizinginner delim-size1\"><span>∥</span></span></span><span style=\"top:-2.25698em;\"><span class=\"pstrut\" style=\"height:2.606em;\"></span><span class=\"delimsizinginner delim-size1\"><span>∥</span></span></span><span style=\"top:-2.85798em;\"><span class=\"pstrut\" style=\"height:2.606em;\"></span><span class=\"delimsizinginner delim-size1\"><span>∥</span></span></span><span style=\"top:-2.87897em;\"><span class=\"pstrut\" style=\"height:2.606em;\"></span><span class=\"delimsizinginner delim-size1\"><span>∥</span></span></span><span style=\"top:-3.47997em;\"><span class=\"pstrut\" style=\"height:2.606em;\"></span><span class=\"delimsizinginner delim-size1\"><span>∥</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500199999999999em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.72528em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.68528em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31472em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.00072em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">(</span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3714399999999998em;\"><span style=\"top:-2.27778em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8322200000000001em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.56778em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">ˉ</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.79222em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.20777999999999996em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.93em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord mathnormal\">ϵ</span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">)</span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.72528em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.68528em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31472em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.00072em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">(</span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3714399999999998em;\"><span style=\"top:-2.27778em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8322200000000001em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.56778em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">ˉ</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.79222em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.20777999999999996em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.93em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\"><span class=\"mord mathnormal\">ϵ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">)</span></span></span><span class=\"mclose\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.4799700000000002em;\"><span style=\"top:-1.65598em;\"><span class=\"pstrut\" style=\"height:2.606em;\"></span><span class=\"delimsizinginner delim-size1\"><span>∥</span></span></span><span style=\"top:-2.25698em;\"><span class=\"pstrut\" style=\"height:2.606em;\"></span><span class=\"delimsizinginner delim-size1\"><span>∥</span></span></span><span style=\"top:-2.85798em;\"><span class=\"pstrut\" style=\"height:2.606em;\"></span><span class=\"delimsizinginner delim-size1\"><span>∥</span></span></span><span style=\"top:-2.87897em;\"><span class=\"pstrut\" style=\"height:2.606em;\"></span><span class=\"delimsizinginner delim-size1\"><span>∥</span></span></span><span style=\"top:-3.47997em;\"><span class=\"pstrut\" style=\"height:2.606em;\"></span><span class=\"delimsizinginner delim-size1\"><span>∥</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500199999999999em;\"><span></span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.6839780000000002em;\"><span style=\"top:-3.9328700000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size4\">]</span></span></span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">ϵ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∼</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14736em;\">N</span></span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.3000050000000005em;\"><span class=\"pstrut\" style=\"height:3.75em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.16110799999999997em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathbf mtight\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31731428571428577em;\"><span style=\"top:-2.357em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\">ϵ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">[</span></span><span class=\"minner\"><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">∥</span><span class=\"mord mathnormal\">ϵ</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">ϵ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span><span class=\"mclose delimcenter\" style=\"top:0em;\">∥</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.954008em;\"><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">]</span></span></span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">ϵ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∼</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14736em;\">N</span></span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span><span style=\"top:-1.1999849999999996em;\"><span class=\"pstrut\" style=\"height:3.75em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.16110799999999997em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathbf mtight\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31731428571428577em;\"><span style=\"top:-2.357em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\">ϵ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">[</span></span><span class=\"minner\"><span class=\"minner\"><span class=\"mopen\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8679800000000001em;\"><span style=\"top:-2.2559899999999997em;\"><span class=\"pstrut\" style=\"height:2.606em;\"></span><span class=\"delimsizinginner delim-size1\"><span>∥</span></span></span><span style=\"top:-2.26698em;\"><span class=\"pstrut\" style=\"height:2.606em;\"></span><span class=\"delimsizinginner delim-size1\"><span>∥</span></span></span><span style=\"top:-2.86798em;\"><span class=\"pstrut\" style=\"height:2.606em;\"></span><span class=\"delimsizinginner delim-size1\"><span>∥</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35000999999999993em;\"><span></span></span></span></span></span></span><span class=\"mord mathnormal\">ϵ</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">ϵ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.874155em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord overline\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.63056em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span><span style=\"top:-3.55056em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"overline-line\" style=\"border-bottom-width:0.04em;\"></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.834155em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.16584500000000002em;\"><span></span></span></span></span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8810950000000001em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord overline\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.63056em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span><span style=\"top:-3.55056em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"overline-line\" style=\"border-bottom-width:0.04em;\"></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.841095em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15890499999999996em;\"><span></span></span></span></span></span><span class=\"mord mathnormal\">ϵ</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span><span class=\"mclose\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8679800000000001em;\"><span style=\"top:-2.2559899999999997em;\"><span class=\"pstrut\" style=\"height:2.606em;\"></span><span class=\"delimsizinginner delim-size1\"><span>∥</span></span></span><span style=\"top:-2.26698em;\"><span class=\"pstrut\" style=\"height:2.606em;\"></span><span class=\"delimsizinginner delim-size1\"><span>∥</span></span></span><span style=\"top:-2.86798em;\"><span class=\"pstrut\" style=\"height:2.606em;\"></span><span class=\"delimsizinginner delim-size1\"><span>∥</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35000999999999993em;\"><span></span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0851030000000002em;\"><span style=\"top:-3.3339950000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">]</span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">ϵ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∼</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14736em;\">N</span></span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:3.5000350000000005em;\"><span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p>  经过这样一番推导之后就是个 L2-loss。网络的输入是一张和噪声线性组合的图片，然后要估计出来这个噪声。</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>ϵ</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><msqrt><msub><mover accent=\"true\"><mi>α</mi><mo stretchy=\"true\">‾</mo></mover><mi>t</mi></msub></msqrt><msub><mi mathvariant=\"bold\">x</mi><mn>0</mn></msub><mo>+</mo><msqrt><mrow><mn>1</mn><mo>−</mo><msub><mover accent=\"true\"><mi>α</mi><mo stretchy=\"true\">‾</mo></mover><mi>t</mi></msub></mrow></msqrt><mi>ϵ</mi><mo separator=\"true\">,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\epsilon_\\theta(\\sqrt{\\overline{\\alpha}_t}\\mathbf{x}_0+\\sqrt{1-\\overline{\\alpha}_t}\\epsilon,t)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.124155em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">ϵ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.874155em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord overline\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.63056em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span><span style=\"top:-3.55056em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"overline-line\" style=\"border-bottom-width:0.04em;\"></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.834155em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.16584500000000002em;\"><span></span></span></span></span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1310950000000002em;vertical-align:-0.25em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8810950000000001em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord overline\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.63056em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span><span style=\"top:-3.55056em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"overline-line\" style=\"border-bottom-width:0.04em;\"></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.841095em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15890499999999996em;\"><span></span></span></span></span></span><span class=\"mord mathnormal\">ϵ</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<h1 id=\"五-训练过程\"><a class=\"markdownIt-Anchor\" href=\"#五-训练过程\">#</a> 五、训练过程</h1>\n<p><img data-src=\"/images/AI/DiffusionModel/5.1.png\" alt=\"\"></p>\n<p>训练过程如上图左边 Algorithm 1 Training 部分：</p>\n<ol>\n<li>从标准高斯分布采样一个噪声<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>ϵ</mi><mo>∼</mo><mi mathvariant=\"script\">N</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mi mathvariant=\"bold\">I</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\epsilon\\sim\\mathcal{N}(0,\\mathbf{I})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">ϵ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∼</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14736em;\">N</span></span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">I</span></span><span class=\"mclose\">)</span></span></span></span>；</li>\n<li>通过梯度下降最小化损失<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi mathvariant=\"normal\">∇</mi><mi>θ</mi></msub><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"bold-italic\">ϵ</mi><mo>−</mo><mi mathvariant=\"bold\">z</mi><mi>θ</mi><mo stretchy=\"false\">(</mo><msqrt><mrow><mover accent=\"true\"><mi>α</mi><mo>ˉ</mo></mover><mi>t</mi></mrow></msqrt><msub><mi>x</mi><mn>0</mn></msub><mo>+</mo><msqrt><mrow><mn>1</mn><mo>−</mo><msub><mover accent=\"true\"><mi>α</mi><mo>ˉ</mo></mover><mi>t</mi></msub></mrow></msqrt><mi mathvariant=\"bold-italic\">ϵ</mi><mo separator=\"true\">,</mo><mi>t</mi><mo stretchy=\"false\">)</mo><msup><mi mathvariant=\"normal\">∣</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">\\nabla_\\theta|\\boldsymbol{\\epsilon}-\\mathbf{z}\\theta(\\sqrt{\\bar{\\alpha}t}x_0+\\sqrt{1-\\bar{\\alpha}_t}\\boldsymbol{\\epsilon},t)|^2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\">∇</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">ϵ</span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.14254em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">z</span></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mopen\">(</span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.89254em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.56778em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">ˉ</span></span></span></span></span></span></span><span class=\"mord mathnormal\">t</span></span></span><span style=\"top:-2.85254em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.14746000000000004em;\"><span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.08222em;vertical-align:-0.25em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8322200000000001em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.56778em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">ˉ</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.79222em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.20777999999999996em;\"><span></span></span></span></span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">ϵ</span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span>；</li>\n<li>训练到收敛为止；</li>\n</ol>\n<p>测试（采样）如上图右边 Algorithm 2 Sampling 部分：</p>\n<ol>\n<li>从标准高斯分布采样一个噪声<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>T</mi></msub><mo>∼</mo><mi mathvariant=\"script\">N</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mi mathvariant=\"bold\">I</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">x_T\\sim\\mathcal{N}(0,\\mathbf{I})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∼</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14736em;\">N</span></span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">I</span></span><span class=\"mclose\">)</span></span></span></span>；</li>\n<li>从时间步 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span></span></span></span> 开始正向扩散迭代到时间步 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span>；</li>\n<li>如果时间步不为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span>，则从标准高斯分布采样一个噪声<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>z</mi><mo>∼</mo><mi mathvariant=\"script\">N</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mi mathvariant=\"bold\">I</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">z\\sim\\mathcal{N}(0,\\mathbf{I})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∼</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14736em;\">N</span></span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">I</span></span><span class=\"mclose\">)</span></span></span></span>，否则<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>z</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">z=0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span>；</li>\n<li>根据高斯分布计算每个时间步<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span> 的噪声图；</li>\n</ol>\n<h1 id=\"六-代码实现\"><a class=\"markdownIt-Anchor\" href=\"#六-代码实现\">#</a> 六、代码实现</h1>\n<p>参考文章：<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYXNzZW1ibHlhaS5jb20vYmxvZy9kaWZmdXNpb24tbW9kZWxzLWZvci1tYWNoaW5lLWxlYXJuaW5nLWludHJvZHVjdGlvbi8=\">https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/</span></p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> torch</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> denoising_diffusion_pytorch <span class=\"token keyword\">import</span> Unet<span class=\"token punctuation\">,</span> GaussianDiffusion</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>model <span class=\"token operator\">=</span> Unet<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    dim <span class=\"token operator\">=</span> <span class=\"token number\">64</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    dim_mults <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>diffusion <span class=\"token operator\">=</span> GaussianDiffusion<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    model<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    image_size <span class=\"token operator\">=</span> <span class=\"token number\">128</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    timesteps <span class=\"token operator\">=</span> <span class=\"token number\">1000</span><span class=\"token punctuation\">,</span>   <span class=\"token comment\"># number of steps</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    loss_type <span class=\"token operator\">=</span> <span class=\"token string\">'l1'</span>    <span class=\"token comment\"># L1 or L2</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre></pre></td></tr><tr><td data-num=\"16\"></td><td><pre><span class=\"token comment\"># 随机样本</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>training_images <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">128</span><span class=\"token punctuation\">,</span> <span class=\"token number\">128</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>loss <span class=\"token operator\">=</span> diffusion<span class=\"token punctuation\">(</span>training_images<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>loss<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>sampled_images <span class=\"token operator\">=</span> diffusion<span class=\"token punctuation\">.</span>sample<span class=\"token punctuation\">(</span>batch_size <span class=\"token operator\">=</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre></pre></td></tr><tr><td data-num=\"23\"></td><td><pre><span class=\"token comment\"># 自定义样本</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre><span class=\"token comment\"># trainer = Trainer(</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre><span class=\"token comment\">#     diffusion,</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre><span class=\"token comment\">#     'path/to/your/images',</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre><span class=\"token comment\">#     train_batch_size = 32,</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre><span class=\"token comment\">#     train_lr = 2e-5,</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre><span class=\"token comment\">#     train_num_steps = 700000,         # total training steps</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre><span class=\"token comment\">#     gradient_accumulate_every = 2,    # gradient accumulation steps</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre><span class=\"token comment\">#     ema_decay = 0.995,                # exponential moving average decay</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre><span class=\"token comment\">#     amp = True                        # turn on mixed precision</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre><span class=\"token comment\"># )</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre><span class=\"token comment\">#</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre><span class=\"token comment\"># trainer.train()</span></pre></td></tr></table></figure>",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/07/29/AI/LLM_finetune/",
            "url": "http://qianqiu-cell.github.io/2024/07/29/AI/LLM_finetune/",
            "title": "大模型微调",
            "date_published": "2024-07-28T16:00:00.000Z",
            "content_html": "<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzU2NTkxODE0L2FydGljbGUvZGV0YWlscy8xMzEyOTM5NDA=\">https://blog.csdn.net/qq_56591814/article/details/131293940</span>、<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVdrYnplVUVWRC8/c3BtX2lkX2Zyb209MzMzLjg4MC5teV9oaXN0b3J5LnBhZ2UuY2xpY2smYW1wO3ZkX3NvdXJjZT1lMDExNzJlYTI5MmMxYzYwNWIzNDYxMDFkNzAwNmM2MQ==\">https://www.bilibili.com/video/BV1WkbzeUEVD/?spm_id_from=333.880.my_history.page.click&amp;vd_source=e01172ea292c1c605b346101d7006c61</span>、<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82MzUxNTI4MTM=\">https://zhuanlan.zhihu.com/p/635152813</span></p>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL2h1Z2dpbmdmYWNlL3BlZnQ=\">peft 库</span>可以实现几乎所有的微调</p>\n<h1 id=\"一-为什么要对大模型进行微调\"><a class=\"markdownIt-Anchor\" href=\"#一-为什么要对大模型进行微调\">#</a> 一、为什么要对大模型进行微调</h1>\n<p>  通常，要对大模型进行微调，有以下一些原因：</p>\n<ul>\n<li>\n<p>第一个原因是，因为大模型的参数量非常大，训练成本非常高；</p>\n</li>\n<li>\n<p>第二个原因是， <code>Prompt Engineering</code>  的方式是一种相对来说容易上手的使用大模型的方式，但是它的缺点也非常明显。因为通常大模型都会对输入序列的长度有限制， <code>Prompt Engineering</code>  的 <code>Prompt</code>  很长。越长的 <code>Prompt</code> ，大模型的推理成本越高，因为推理成本是跟 <code>Prompt</code>  长度的平方正向相关的。</p>\n</li>\n<li>\n<p>第三个原因是， <code>Prompt Engineering</code>  的效果达不到要求，企业又有比较好的自有数据，能够通过自有数据，更好的提升大模型在特定领域的能力。这时候微调就非常适用。</p>\n</li>\n<li>\n<p>第四个原因是，要在个性化的服务中使用大模型的能力，这时候针对每个用户的数据，训练一个轻量级的微调模型，就是一个不错的方案。</p>\n</li>\n<li>\n<p>第五个原因是，数据安全的问题。如果数据是不能传递给第三方大模型服务的，那么搭建自己的大模型就非常必要。</p>\n</li>\n</ul>\n<h1 id=\"二-大模型微调的技术手段\"><a class=\"markdownIt-Anchor\" href=\"#二-大模型微调的技术手段\">#</a> 二、大模型微调的技术手段</h1>\n<p>  根据微调对整个预训练模型的调整程度，微调可以分为全微调和部分微调两个方法：</p>\n<ul>\n<li>\n<p>全微调（ <code>Full Fine-tuning, FFT</code> ）： <code>FFT</code>  是指对整个预训练模型进行微调，包括所有的模型参数。在这种方法中，预训练模型的所有层和参数都会被更新和优化，以适应目标任务的需求。这种微调方法通常适用于任务和预训练模型之间存在较大差异的情况，或者任务需要模型具有高度灵活性和自适应能力的情况。 <code>FFT</code>  需要较大的计算资源和时间，但可以获得更好的性能。</p>\n</li>\n<li>\n<p>参数高效微调（ <code>Parameter-Efficient Fine-Tuning, PEFT</code> ）： <code>PEFT</code>  旨在通过最小化微调参数数量和计算复杂度，提升预训练模型在新任务上的表现，从而减轻大型预训练模型的训练负担。 <code>PEFT</code>  可以粗略分为以下三大类：增加额外参数（ <code>A</code> ）、选取一部分参数更新（ <code>S</code> ）、引入重参数化（ <code>R</code> ）。而在增加额外参数这类方法中，又主要分为类适配器（ <code>Adapter-like</code> ）方法和软提示（ <code>Soft prompts</code> ）两个小类。</p>\n</li>\n</ul>\n<p><img data-src=\"/images/AI/LLM_finetune/2.1.png\" alt=\"\"></p>\n<h2 id=\"21-additive-methods\"><a class=\"markdownIt-Anchor\" href=\"#21-additive-methods\">#</a> 2.1 Additive methods</h2>\n<p>  主要思想是通过<mark>添加额外的参数或层来扩充现有的预训练模型，并仅训练新添加的参数</mark>。这种方法又分为：</p>\n<ul>\n<li><code>Adapters</code> （类适配器）：即在 <code>Transformer</code>  子层后引入小型全连接网络。 <code>Adapters</code>  有多种变体，例如修改适配器的位置、剪枝以及使用重参数化来减少可训练参数的数量。</li>\n<li><code>Soft Prompts</code> （软提示）：<strong>人工设计的是 hard prompt，模型训练出来的是 soft prompt</strong>。 <code>Soft Prompts</code> <mark> 将模型的一部分输入嵌入通过梯度下降进行微调</mark>，将在离散空间中寻找提示的问题转化为连续优化问题。 <code>Soft Prompts</code>  可以仅对输入层进行训练<span class=\"exturl\" data-url=\"aHR0cHM6Ly9wYXBlcnN3aXRoY29kZS5jb20vcGFwZXIvdGhlLXBvd2VyLW9mLXNjYWxlLWZvci1wYXJhbWV0ZXItZWZmaWNpZW50\"> Prompt Tuning</span>），也可以对所有层进行训练（<span class=\"exturl\" data-url=\"aHR0cHM6Ly9wYXBlcnN3aXRoY29kZS5jb20vcGFwZXIvcHJlZml4LXR1bmluZy1vcHRpbWl6aW5nLWNvbnRpbnVvdXMtcHJvbXB0cw==\">Prefix-Tuning</span>）。</li>\n<li><code>others</code> ：例如 <code>LeTS</code> ,  <code>LST</code>  和 <code>(IA)^3</code></li>\n</ul>\n<p>  尽管这些方法引入了额外的参数到网络中，但它们通过减少梯度和优化器状态的大小，减少了训练时间，提升了内存效率。此外可以对冻结的模型参数进行量化（<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzU2NTkxODE0L2FydGljbGUvZGV0YWlscy8xMzEyOTM5NDA=\">参考论文</span>）， <code>additive PEFT</code>  方法能够微调更大的网络或使用更大的批次大小，这提高了在 <code>GPU</code>  上的训练吞吐量。此外，在分布式设置中优化较少的参数大大减少了通信量。</p>\n<h3 id=\"1-prefix-tuning\"><a class=\"markdownIt-Anchor\" href=\"#1-prefix-tuning\">#</a> (1) Prefix Tuning</h3>\n<p>  <span class=\"exturl\" data-url=\"aHR0cHM6Ly9wYXBlcnN3aXRoY29kZS5jb20vcGFwZXIvcHJlZml4LXR1bmluZy1vcHRpbWl6aW5nLWNvbnRpbnVvdXMtcHJvbXB0cw==\">Prefix-Tuning</span><strong> 在输入 token 之前构造一段任务相关的 virtual tokens 作为 Prefix，然后训练的时候只更新 Prefix 部分的参数</strong>，而 PLM 中的其他部分参数固定。</p>\n<p>  针对不同的模型结构，需要构造不同的 Prefix。</p>\n<ul>\n<li>针对仅编码器架构模型：在句子前面添加前缀，得到 <strong>z = [PREFIX; x; y]</strong>，合适的上文能够在固定 LM 的情况下去引导生成下文（比如：GPT3 的上下文学习）。</li>\n<li>针对编码器 - 解码器架构模型：Encoder 和 Decoder 都增加了前缀，得到 <strong>z = [PREFIX; x; PREFIX0; y]</strong>。Encoder 端增加前缀是为了引导输入部分的编码，Decoder 端增加前缀是为了引导后续 token 的生成。</li>\n</ul>\n<p><img data-src=\"/images/AI/LLM_finetune/2.2.png\" alt=\"\"></p>\n<p>  <strong>Prefix Tuning 和构造 Prompt 类似，只是 Prompt 是人为构造的 “显式” 的提示，并且无法更新参数，而 Prefix 则是可以学习的 “隐式” 的提示</strong>。</p>\n<p>  同时，为了防止直接更新 Prefix 的参数导致训练不稳定和性能下降的情况，<strong>在 Prefix 层前面加了 MLP 结构，训练完成后，只保留 Prefix 的参数</strong>。</p>\n<p>  通过消融实验证实，只调整 embedding 层的表现力不够，将导致性能显著下降，因此，<strong>在每层都加了 prompt 的参数，改动较大</strong>。</p>\n<p>  另外，实验还对比了位置对于生成效果的影响，Prefix-tuning 也是要略优于 Infix-tuning 的。其中，Prefix-tuning 形式为 [PREFIX; x; y]，Infix-tuning 形式为 [x; INFIX; y]。</p>\n<h3 id=\"2-prompt-tuning\"><a class=\"markdownIt-Anchor\" href=\"#2-prompt-tuning\">#</a> (2) Prompt Tuning</h3>\n<p>  人工设计 prompts 提示语，成本比较高，并且效果不太好。<strong>Prompt Tuning 通过反向传播更新参数来学习 prompts，而不是人工设计 prompts；同时冻结模型原始权重，只训练 prompts 参数</strong>，训练完以后，用同一个模型可以做多任务推理。</p>\n<p>  <strong><span class=\"exturl\" data-url=\"aHR0cHM6Ly9wYXBlcnN3aXRoY29kZS5jb20vcGFwZXIvdGhlLXBvd2VyLW9mLXNjYWxlLWZvci1wYXJhbWV0ZXItZWZmaWNpZW50\">Prompt Tuning</span> 可以看作是 Prefix Tuning 的简化版本，它给每个任务定义了自己的 Prompt，然后拼接到数据上作为输入，但只在输入层加入 prompt tokens，并且不需要加入 MLP 进行调整来解决难训练的问题</strong>。</p>\n<p><img data-src=\"/images/AI/LLM_finetune/2.3.png\" alt=\"\"></p>\n<p>  通过实验发现，<strong>随着预训练模型参数量的增加，Prompt Tuning 的方法会逼近全参数微调的结果</strong>。</p>\n<p><img data-src=\"/images/AI/LLM_finetune/2.4.png\" alt=\"\"></p>\n<p>  同时，Prompt Tuning 还提出了 Prompt Ensembling，也就是在一个批次（Batch）里同时训练同一个任务的不同 prompt（即采用多种不同方式询问同一个问题），这样相当于训练了不同模型，比模型集成的成本小多了。</p>\n<p><img data-src=\"/images/AI/LLM_finetune/2.5.png\" alt=\"\"></p>\n<p>  通过消融实验结果发现，<strong>Prompt Tuning 采用类标签初始化模型的效果更好</strong>。不过随着模型参数规模的提升，这种 gap 最终会消失。<strong>Prompt token 的长度在 20 左右时的表现已经不错</strong>。</p>\n<h3 id=\"3-p-tuning\"><a class=\"markdownIt-Anchor\" href=\"#3-p-tuning\">#</a> (3) P-Tuning</h3>\n<p>  大模型的 Prompt 构造方式严重影响下游任务的效果。人工设计的模版的变化特别敏感，加一个词或者少一个词，或者变动位置都会造成比较大的变化。</p>\n<p>  同时，自动化搜索 Prompt 模版成本比较高，离散化的 token 的搜索出来的结果可能并不是最优的，导致性能不稳定。</p>\n<p>  <strong><span class=\"exturl\" data-url=\"aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzIxMDMuMTAzODU=\">P-Tuning</span>，设计了一种连续可微的 virtual token（同 Prefix-Tuning 类似）。P-Tuning 将 Prompt 转换为可以学习的 Embedding 层，并用 MLP+LSTM 的方式来对 Prompt Embedding 进行一层处理</strong>。</p>\n<p>  相比 Prefix Tuning，P-Tuning 加入的可微的 virtual token，但<strong>仅限于输入层</strong>，没有在每一层都加；另外，<strong>virtual token 的位置也不一定是前缀，插入的位置是可选的</strong>。这里的出发点实际是把传统人工设计模版中的真实 token 替换成可微的 virtual token。</p>\n<p><img data-src=\"/images/AI/LLM_finetune/2.6.png\" alt=\"\"></p>\n<p>  经过预训练的 LM 的词嵌入已经变得高度离散，如果随机初始化 virtual token，容易优化到局部最优值，而这些 virtual token 理论是应该有相关关联的。因此，作者通过实验发现<strong>用一个 prompt encoder 来编码会收敛更快，效果更好。即用一个 LSTM+MLP 去编码这些 virtual token 以后，再输入到模型</strong>。</p>\n<h3 id=\"4-p-tuning-v2\"><a class=\"markdownIt-Anchor\" href=\"#4-p-tuning-v2\">#</a> (4) P-Tuning v2</h3>\n<p>  Prompt Tuning 和 P-Tuning 等方法存在两个主要的问题：</p>\n<p>  第一，缺乏模型参数规模和任务通用性。</p>\n<ul>\n<li>缺乏规模通用性：Prompt Tuning 论文中表明当模型规模超过 100 亿个参数时，提示优化可以与全量微调相媲美。<strong>但是对于那些较小的模型（从 100M 到 1B），提示优化和全量微调的表现有很大差异</strong>，这大大限制了提示优化的适用性。</li>\n<li>缺乏任务普遍性：尽管 Prompt Tuning 和 P-tuning 在一些 NLU 基准测试中表现出优势，<strong>但提示调优对硬序列标记任务（即序列标注）的有效性尚未得到验证</strong>。</li>\n</ul>\n<p>  第二，缺少深度提示优化，在 Prompt Tuning 和 P-tuning 中，<strong>连续提示只被插入 transformer 第一层的输入 embedding 序列中，在接下来的 transformer 层中，插入连续提示的位置的 embedding 是由之前的 transformer 层计算出来的，这可能导致两个可能的优化挑战</strong>。</p>\n<ul>\n<li>由于序列长度的限制，可调参数的数量是有限的。</li>\n<li>输入 embedding 对模型预测只有相对间接的影响。</li>\n</ul>\n<p>  考虑到这些问题，<strong>P-tuning v2 利用深度提示优化（如：Prefix Tuning），对 Prompt Tuning 和 P-Tuning 进行改进，作为一个跨规模和 NLU 任务的通用解决方案</strong>。</p>\n<p>  <strong><span class=\"exturl\" data-url=\"aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzIxMTAuMDc2MDI=\">P-Tuning v2</span> 在每一层都加入了 Prompts tokens 作为输入，而不是仅仅加在输入层</strong>，这带来两个方面的好处：</p>\n<ul>\n<li><strong>更多可学习的参数</strong>（从 P-tuning 和 Prompt Tuning 的 0.01% 增加到 0.1%-3%），同时也足够参数高效。</li>\n<li><strong>加入到更深层结构中的 Prompt 能给模型预测带来更直接的影响</strong>。</li>\n</ul>\n<p><img data-src=\"/images/AI/LLM_finetune/2.7.png\" alt=\"\"></p>\n<p>  <strong>具体做法基本同 Prefix Tuning</strong>，可以看作是将文本生成的 Prefix Tuning 技术适配到 NLU 任务中，然后做了一些改进：</p>\n<ul>\n<li><strong>移除重参数化的编码器</strong>。以前的方法利用重参数化功能来提高训练速度和鲁棒性（如：Prefix Tuning 中的 MLP、P-Tuning 中的 LSTM））。在 P-tuning v2 中发现重参数化的改进很小，尤其是对于较小的模型，同时还会影响模型的表现。</li>\n<li><strong>针对不同任务采用不同的提示长度</strong>。不同的文本生成任务可能有不同的最佳提示长度。</li>\n<li><strong>引入多任务学习</strong>。先在多任务的 Prompt 上进行预训练，然后再适配下游任务。多任务学习对 P-tuning v2 来说是可选的，但可能是相当有帮助的。一方面，连续提示的随机惯性给优化带来了困难，这可以通过更多的训练数据或与任务相关的无监督预训练来缓解；另一方面，连续提示是跨任务和数据集的特定任务知识的完美载体。实验表明，在一些困难的序列任务中，多任务学习可以作为 P-tuning v2 的有益补充。</li>\n<li><strong>回归传统的分类标签范式，而不是映射器</strong>。标签词映射器（Label Word Verbalizer）一直是提示优化的核心组成部分，它将 one-hot 类标签变成有意义的词，以利用预训练语言模型头。尽管它在 few-shot 设置中具有潜在的必要性，但在全数据监督设置中，Verbalizer 并不是必须的。它阻碍了提示调优在我们需要无实际意义的标签和句子嵌入的场景中的应用。因此，<strong>P-Tuning v2 回归传统的 CLS 标签分类范式</strong>，采用随机初始化的分类头（Classification Head）应用于 tokens 之上，以增强通用性，可以适配到序列标注任务。</li>\n</ul>\n<p>  论文中展示了 P-tuning v2 在不同模型规模下的表现。对于简单的 NLU 任务，如 SST-2（单句分类），Prompt Tuning 和 P-Tuning 在较小的规模下没有显示出明显的劣势。但是当涉及到复杂的挑战时，如：自然语言推理（RTE）和多选题回答（BoolQ），它们的性能会非常差。相反，P-Tuning v2 在较小规模的所有任务中都与微调的性能相匹配。并且，P-tuning v2 在 RTE 中的表现明显优于微调，特别是在 BERT 中。</p>\n<p>  为了评估 P-Tuning v2 在一些困难的 NLU 挑战中的能力，作者选择了三个典型的序列标注任务（名称实体识别、抽取式问答（QA）和语义角色标签（SRL）），共八个数据集。我们观察到 P-Tuning v2 在所有任务上都能与全量微调相媲美。</p>\n<p>  论文还通过消融实验研究了不同任务上 Prompt Length 的影响：</p>\n<ul>\n<li>针对简单任务：如情感分析，较短的 Prompt（~20）即可取得不错的效果。</li>\n<li>针对复杂任务：如阅读理解，需要更长的 Prompt（~100）。</li>\n</ul>\n<p>  总之，<strong>P-Tuning v2 是一种在不同规模和任务中都可与微调相媲美的提示方法</strong>。P-Tuning v2 对从 330M 到 10B 的模型显示出一致的改进，并在序列标注等困难的序列任务上以很大的幅度超过了 Prompt Tuning 和 P-Tuning。P-Tuning v2 可以成为微调的综合替代方案和未来工作的基线（Baseline）。</p>\n<h3 id=\"5-adapter-tuning\"><a class=\"markdownIt-Anchor\" href=\"#5-adapter-tuning\">#</a> (5) Adapter Tuning</h3>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzE5MDIuMDA3NTE=\">Adapter Tuning</span> 设计了 Adapter 结构，并将其嵌入 Transformer 的结构里面，<strong>针对每一个 Transformer 层，增加了两个 Adapter 结构</strong> (分别是多头注意力的投影之后和第二个 feed-forward 层之后)，在训练时，固定住原来预训练模型的参数不变，只对新增的 Adapter 结构和 Layer Norm 层进行微调，从而保证了训练的高效性。</p>\n<p>每当出现新的下游任务，通过添加 Adapter 模块来产生一个易于扩展的下游模型，从而避免全量微调与灾难性遗忘的问题。</p>\n<p><img data-src=\"/images/AI/LLM_finetune/2.8.png\" alt=\"\"></p>\n<h2 id=\"22-selective-methods\"><a class=\"markdownIt-Anchor\" href=\"#22-selective-methods\">#</a> 2.2 Selective methods</h2>\n<p>  最早的 <code>selective PEFT</code>  方法是仅微调网络的几个顶层（冻结前层），现代方法通常基于层的类型（<span class=\"exturl\" data-url=\"aHR0cHM6Ly9wYXBlcnN3aXRoY29kZS5jb20vcGFwZXIvb24tdGhlLXN0cmVuZ3Rocy1vZi1jcm9zcy1hdHRlbnRpb24taW4=\">Cross-Attention is All You Need</span>）或内部结构，例如仅微调模型的偏置（<span class=\"exturl\" data-url=\"aHR0cHM6Ly9wYXBlcnN3aXRoY29kZS5jb20vcGFwZXIvYml0Zml0LXNpbXBsZS1wYXJhbWV0ZXItZWZmaWNpZW50LWZpbmUtdHVuaW5n\">BitFit</span>）或仅特定的行（<span class=\"exturl\" data-url=\"aHR0cHM6Ly9wYXBlcnN3aXRoY29kZS5jb20vcGFwZXIvZWZmaWNpZW50LWZpbmUtdHVuaW5nLW9mLWJlcnQtbW9kZWxzLW9uLXRoZQ==\">Efficient Fine-Tuning of BERT Models on the Edge</span>）。</p>\n<h3 id=\"1-bitfit\"><a class=\"markdownIt-Anchor\" href=\"#1-bitfit\">#</a> (1) BitFit</h3>\n<p>  <span class=\"exturl\" data-url=\"aHR0cHM6Ly9wYXBlcnN3aXRoY29kZS5jb20vcGFwZXIvYml0Zml0LXNpbXBsZS1wYXJhbWV0ZXItZWZmaWNpZW50LWZpbmUtdHVuaW5n\">BitFit</span> 是一种稀疏的微调方法，它训练时<strong>只更新 bias 的参数或者部分 bias 参数</strong>。涉及到的 bias 参数有 attention 模块中计算 query,key,value 跟合并多个 attention 结果时涉及到的 bias，MLP 层中的 bias，Layernormalization 层的 bias 参数。</p>\n<p>  在 Bert-Base/Bert-Large 这种模型里，<strong>bias 参数仅占模型全部参数量的 0.08%～0.09%</strong>。但是通过在 Bert-Large 模型上基于 GLUE 数据集进行了 BitFit、Adapter 和 Diff-Pruning 的效果对比发现，BitFit 在参数量远小于 Adapter、Diff-Pruning 的情况下，效果与 Adapter、Diff-Pruning 想当，甚至在某些任务上略优于 Adapter、Diff-Pruning。</p>\n<p>  同时，通过实验结果还可以看出，BitFit 微调结果相对全量参数微调而言，只更新极少量参数的情况下，在多个数据集上都达到了不错的效果，<strong>虽不及全量参数微调</strong>，但是远超固定全部模型参数的 Frozen 方式。</p>\n<p>  同时，通过对比 BitFit 训练前后的参数，发现很多 bias 参数并没有太多变化（例如：跟计算 key 所涉及到的 bias 参数）。发现<strong>计算 query 和将特征维度从 N 放大到 4N 的 FFN 层（intermediate）的 bias 参数变化最为明显</strong>，只更新这两类 bias 参数也能达到不错的效果，反之，固定其中任何一者，模型的效果都有较大损失。</p>\n<h2 id=\"23-reparametrization-based-peft重参数化\"><a class=\"markdownIt-Anchor\" href=\"#23-reparametrization-based-peft重参数化\">#</a> 2.3 Reparametrization-based PEFT（重参数化）</h2>\n<p>  利用低秩表示来最小化可训练参数的数量。Aghajanyan 等人（2020）证明了在低秩子空间中可以有效地进行微调，对于更大的模型或经过更长时间预训练的模型，需要进行调整的子空间更小。最知名的基于重参数化的方法 <code>LoRa</code> ，它将参数矩阵进行简单的低秩分解来更新权重。最近的研究（Karimi Mahabadi 等，2021；Edalati 等，2022）还探索了 <code>Kronecker product reparametrization</code>  的使用，它在秩和参数数量之间取得了更有利的权衡。</p>\n<p>   <code>LoRA</code>  背后有一个假设：我们现在看到的这些大语言模型，它们都是被过度参数化的。而过度参数化的大模型背后，都有一个低维的本质模型。</p>\n<p>  大白话说：大模型参数很多，但并不是所有的参数都是发挥同样作用的；大模型中有其中一部分参数，是非常重要的，是影响大模型生成结果的关键参数，这部分关键参数就是上面提到的低维的本质模型。</p>\n<p>   <code>LoRA</code>  的基本思路，包括以下几步：</p>\n<ul>\n<li>\n<p>首先，要适配特定的下游任务，要训练一个特定的模型，将 <code>Y=WX</code>  变成 <code>Y=(W+∆W)X</code> ，这里面 <code>∆W</code>  主是我们要微调得到的结果；</p>\n</li>\n<li>\n<p>其次，将 <code>∆W</code>  进行低维分解 <code>∆W=AB</code>  ( <code>∆W</code>  为 <code>m*n</code>  维， <code>A</code>  为 <code>m*r</code>  维， <code>B</code>  为 <code>r*n</code>  维， <code>r</code>  就是上述假设中的低维)；</p>\n</li>\n<li>\n<p>接下来，用特定的训练数据，训练出 <code>A</code>  和 <code>B</code>  即可得到 <code>∆W</code> ，在推理的过程中直接将 <code>∆W</code>  加到 <code>W</code>  上去，再没有额外的成本。</p>\n</li>\n<li>\n<p>另外，如果要用 <code>LoRA</code>  适配不同的场景，切换也非常方便，做简单的矩阵加法即可： <code>(W+∆W)-∆W+∆W'</code> 。</p>\n</li>\n</ul>\n<p>  该方法认为模型权重矩阵在特定微调后具有较低的本征秩，故基于秩分解的概念，将预训练模型的现有权重矩阵分成两个较小的矩阵。</p>\n<p><img data-src=\"/images/AI/LLM_finetune/2.10.png\" alt=\"\"></p>\n<h2 id=\"24-hybrid-methods\"><a class=\"markdownIt-Anchor\" href=\"#24-hybrid-methods\">#</a> 2.4 Hybrid methods</h2>\n<p>  混合多种 <code>PEFT</code>  方法，例如， <code>MAM Adapter</code>  结合了 <code>Adapters</code>  和 <code>Prompt tuning</code> ； <code>UniPELT</code>  加入了 <code>LoRa</code> ,  <code>Compacter</code>  和 <code>KronAB</code>  对适配器进行了重参数化以减少其参数数量；最后， <code>S4</code>  是一个自动化算法搜索的结果，它结合了所有的 <code>PEFT</code>  类别，额外参数数量增加 0.5% 的情况下最大化准确性。</p>\n<h1 id=\"三-使用llama-factory微调qwen2模型\"><a class=\"markdownIt-Anchor\" href=\"#三-使用llama-factory微调qwen2模型\">#</a> 三、使用 LLaMA-Factory 微调 Qwen2 模型</h1>\n<h2 id=\"31-运行qwen2模型\"><a class=\"markdownIt-Anchor\" href=\"#31-运行qwen2模型\">#</a> 3.1 运行 Qwen2 模型</h2>\n<p>  首先进入下载 Qwen2 的<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL1F3ZW5MTS9Rd2VuMg==\"> github 网页</span>的运行文件。运行 <code>Qwen2/examples/demo/web_demo.py</code>  即可在网页端运行 <code>Qwen2</code>  模型。</p>\n<p>  若本地没有大模型参数文件，则会下载 <code>hugging face</code>  中的参数文件。但是 <code>hugging face</code>  由于网络原因会导致模型下载失败。因此选择国内的<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cubW9kZWxzY29wZS5jbi9teS9vdmVydmlldw==\"> ModelScope</span> 网站下载所需要的 <code>Qwen2</code>  大模型参数文件。找到对应的模型参数文件，依次点击模型文件 - 下载模型 - SDK 下载，即可获得模型参数文件的下载方式，一个示例下载的 <code>python</code>  程序如下所示：</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\">#模型下载</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> modelscope <span class=\"token keyword\">import</span> snapshot_download</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>model_dir <span class=\"token operator\">=</span> snapshot_download<span class=\"token punctuation\">(</span><span class=\"token string\">'qwen/Qwen2-1.5B-Instruct'</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>  待下载完成模型文件后，更改 <code>web_demo.py</code>  文件的 <code>DEFAULT_CKPT_PATH</code>  参数为所下载模型参数文件的路径，一个示例的路径为： <code>DEFAULT_CKPT_PATH = 'E:/python/9_LLM/2_FineTuning/4_Qwen/qwen/Qwen2-1___5B-Instruct'</code></p>\n<p>  之后即可成功运行 <code>web_demo.py</code> ，并与所下载的大模型参数文件对应的大模型进行对话。</p>\n<p><img data-src=\"/images/AI/LLM_finetune/3.1.png\" alt=\"\"></p>\n<h2 id=\"32-下载并运行llama-factory\"><a class=\"markdownIt-Anchor\" href=\"#32-下载并运行llama-factory\">#</a> 3.2 下载并运行 LLaMA-Factory</h2>\n<p>  首先进入 <code>github</code>  的<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL2hpeW91Z2EvTExhTUEtRmFjdG9yeQ==\"> LLaMA-Factory 网页</span>，下载 <code>LLaMA-Factory</code>  工具箱。运行 <code>LLaMA-Factory-main/src/webui.py</code>  即可运行 <code>LLaMA-Factory</code>  的网页可视化界面。可视化界面如下所示：</p>\n<p><img data-src=\"/images/AI/LLM_finetune/3.2.png\" alt=\"\"></p>\n<h2 id=\"33-准备数据集\"><a class=\"markdownIt-Anchor\" href=\"#33-准备数据集\">#</a> 3.3 准备数据集</h2>\n<p>  在 <code>LLaMA-Factory-main/data</code>  文件夹下保存了几组示例数据集的 <code>json</code>  文件。其中 <code>dataset_info.json</code>  包含了所有可用的数据集。参考<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL2hpeW91Z2EvTExhTUEtRmFjdG9yeS9ibG9iL21haW4vZGF0YS9SRUFETUVfemgubWQ=\"> LLaMA-Factory 的说明文件</span>，如果希望使用自定义数据集，需要在 <code>dataset_info.json</code>  文件中添加数据集描述，目前 <code>LLaMA-Factory</code>  仅支持 <code>alpaca</code>  格式和 <code>sharegpt</code>  格式的数据集。完整的数据集描述如下，具体的示例可以参考初始 <code>dataset_info.json</code>  文件：</p>\n<figure class=\"highlight markdown\"><figcaption data-lang=\"markdown\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>\"数据集名称\": &#123;</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>  \"hf_hub_url\": \"Hugging Face 的数据集仓库地址（若指定，则忽略 script_url 和 file_name）\",</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>  \"ms_hub_url\": \"ModelScope 的数据集仓库地址（若指定，则忽略 script_url 和 file_name）\",</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>  \"script_url\": \"包含数据加载脚本的本地文件夹名称（若指定，则忽略 file_name）\",</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>  \"file_name\": \"该目录下数据集文件夹或文件的名称（若上述参数未指定，则此项必需）\",</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>  \"formatting\": \"数据集格式（可选，默认：alpaca，可以为 alpaca 或 sharegpt）\",</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>  \"ranking\": \"是否为偏好数据集（可选，默认：False）\",</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>  \"subset\": \"数据集子集的名称（可选，默认：None）\",</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>  \"split\": \"所使用的数据集切分（可选，默认：train）\",</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>  \"folder\": \"Hugging Face 仓库的文件夹名称（可选，默认：None）\",</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>  \"num_samples\": \"该数据集所使用的样本数量。（可选，默认：None）\",</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>  \"columns（可选）\": &#123;</pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    \"prompt\": \"数据集代表提示词的表头名称（默认：instruction）\",</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    \"query\": \"数据集代表请求的表头名称（默认：input）\",</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    \"response\": \"数据集代表回答的表头名称（默认：output）\",</pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    \"history\": \"数据集代表历史对话的表头名称（默认：None）\",</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>    \"messages\": \"数据集代表消息列表的表头名称（默认：conversations）\",</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    \"system\": \"数据集代表系统提示的表头名称（默认：None）\",</pre></td></tr><tr><td data-num=\"19\"></td><td><pre>    \"tools\": \"数据集代表工具描述的表头名称（默认：None）\",</pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    \"images\": \"数据集代表图像输入的表头名称（默认：None）\",</pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    \"chosen\": \"数据集代表更优回答的表头名称（默认：None）\",</pre></td></tr><tr><td data-num=\"22\"></td><td><pre>    \"rejected\": \"数据集代表更差回答的表头名称（默认：None）\",</pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    \"kto_tag\": \"数据集代表 KTO 标签的表头名称（默认：None）\"</pre></td></tr><tr><td data-num=\"24\"></td><td><pre>  &#125;,</pre></td></tr><tr><td data-num=\"25\"></td><td><pre>  \"tags（可选，用于 sharegpt 格式）\": &#123;</pre></td></tr><tr><td data-num=\"26\"></td><td><pre>    \"role_tag\": \"消息中代表发送者身份的键名（默认：from）\",</pre></td></tr><tr><td data-num=\"27\"></td><td><pre>    \"content_tag\": \"消息中代表文本内容的键名（默认：value）\",</pre></td></tr><tr><td data-num=\"28\"></td><td><pre>    \"user_tag\": \"消息中代表用户的 role_tag（默认：human）\",</pre></td></tr><tr><td data-num=\"29\"></td><td><pre>    \"assistant_tag\": \"消息中代表助手的 role_tag（默认：gpt）\",</pre></td></tr><tr><td data-num=\"30\"></td><td><pre>    \"observation_tag\": \"消息中代表工具返回结果的 role_tag（默认：observation）\",</pre></td></tr><tr><td data-num=\"31\"></td><td><pre>    \"function_tag\": \"消息中代表工具调用的 role_tag（默认：function_call）\",</pre></td></tr><tr><td data-num=\"32\"></td><td><pre>    \"system_tag\": \"消息中代表系统提示的 role_tag（默认：system，会覆盖 system column）\"</pre></td></tr><tr><td data-num=\"33\"></td><td><pre>  &#125;</pre></td></tr><tr><td data-num=\"34\"></td><td><pre>&#125;</pre></td></tr></table></figure><p>  添加完成数据集描述后，即可在在 <code>LLaMA-Factory-main/data</code>  文件夹内创建对应数据集名称的 <code>json</code>  文件，即可完成自定义数据集的添加。数据集的格式需要和数据集描述一致，详细的示例可以参考初始在 <code>LLaMA-Factory-main/data</code>  文件夹下的其他 <code>json</code>  数据集文件。</p>\n<h2 id=\"34-使用llama-factory进行大模型微调\"><a class=\"markdownIt-Anchor\" href=\"#34-使用llama-factory进行大模型微调\">#</a> 3.4 使用 LLaMA-Factory 进行大模型微调</h2>\n<p>  在准备好微调的数据集之后，即可再次运行 <code>LLaMA-Factory-main/src/webui.py</code> ，启动 LLaMA-Factory 的可视化界面，其中的部分参数定义如下，需要注意的是数据路径应该指定为本地计算机 <code>LLaMA-Factory-main/data</code>  文件夹的绝对路径：</p>\n<p><img data-src=\"/images/AI/LLM_finetune/3.2.png\" alt=\"\"></p>\n<p>  定义完成训练参数后即可点击 “开始” 按钮，开始模型的微调训练。模型训练完毕后，点击 <code>Chat</code>  选项卡，检查点路径选择训练好的大模型，即可开始与微调完成的大模型进行在线对话。点击 <code>Export</code>  选项卡，指定导出目录以及其他设置，点击 “开始导出”，即可导出训练完毕的大模型。至此，已经完成使用 <code>LLaMA-Factory</code>  进行大模型微调的全部过程。</p>\n<h1 id=\"总结\"><a class=\"markdownIt-Anchor\" href=\"#总结\">#</a> 总结</h1>\n<p>参考：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82NDk3NTUyNTI=\">https://zhuanlan.zhihu.com/p/649755252</span></p>\n<p>BitFit<br>\n 对微调机制的一种积极探索，也很简单，通过仅调整 bias 效果就能有不错的效果，但没有具体阐述原理，就是通过猜测加实验得到的结果。同时，作者提出一个观点：微调的过程不是让模型适应另外的数据分布，而是让模型更好的应用出本身的表征能力。</p>\n<p>特点：</p>\n<p>训练参数量极小（约 0.1%）。<br>\n在大部分任务上效果会差于 LoRA、Adapter 等方法。<br>\nPrefix Tuning<br>\n 在每一个 Transformer 层都带上一些 virtual token 作为前缀，以适应不同的任务。</p>\n<p>特点：</p>\n<p>前缀 Token 会占用序列长度，有一定的额外计算开销。<br>\nPrefix Tuning 的线性插值是比较复杂的。<br>\nPrompt Tuning<br>\n 该方法可以看着是 Prefix Tuning 的简化版本，针对不同的任务，仅在输入层引入 virtual token 形式的软提示（soft prompt）。</p>\n<p>特点：</p>\n<p>相对于 Prefix Tuning，参与训练的参数量和改变的参数量更小，更节省显存。<br>\n对一些简单的 NLU 任务还不错，但对硬序列标记任务（即序列标注）表现欠佳。<br>\nP-Tuning<br>\n 将 Prompt 转换为可以学习的 Embedding 层，并用 MLP+LSTM 的方式来对 Prompt Embedding 进行一层处理。相比 Prefix Tuning，仅在输入层加入的可微的 virtual token；另外，virtual token 的位置也不一定是前缀，插入的位置是可选的。</p>\n<p>特点：</p>\n<p>引入一个 prompt encoder（由一个双向的 LSTM + 两层 MLP 组成）来建模 virtual token 的相互依赖会收敛更快，效果更好。<br>\nP-Tuning v2<br>\n 该方法在每一个 Transformer 层都加入了 prompt token 作为输入，引入多任务学习，针对不同任务采用不同的提示长度。并且回归传统的分类标签范式，而不是映射器。</p>\n<p>特点：</p>\n<p>解决了 Prompt Tuning 无法在小模型上有效提升的问题。<br>\n移除了对模型效果改进较小的重参数化的编码器（如：Prefix Tuning 中的 MLP、P-Tuning 中的 LSTM）。<br>\n对于一些复杂的硬序列标记任务（即序列标注）取得了不错的效果。<br>\nAdapter Tuning<br>\n 该方法设计了 Adapter 结构，并将其嵌入 Transformer 的结构里面，针对每一个 Transformer 层，增加了两个 Adapter 结构，在训练时，固定住原来预训练模型的参数不变，只对新增的 Adapter 结构和 Layer Norm 层进行微调。</p>\n<p>特点：</p>\n<p>通过在 Transformer 层中嵌入 Adapter 结构，在推理时会额外增加推理时长。<br>\nAdapterFusion<br>\n 一种融合多任务信息的 Adapter 的变体，在 Adapter 的基础上进行优化，通过将学习过程分为两阶段来提升下游任务表现。</p>\n<p>AdapterDrop<br>\n 该方法在不影响任务性能的情况下，对 Adapter 动态高效的移除，尽可能的减少模型的参数量，提高模型在反向传播（训练）和正向传播（推理）时的效率。</p>\n<p>特点：</p>\n<p>通过从较低的 Transformer 层删除可变数量的 Adaper 来提升推理速度。 当对多个任务执行推理时，动态地减少了运行时的计算开销，并在很大程度上保持了任务性能。<br>\nLoRA<br>\n 该方法通过低秩分解来模拟参数的改变量，从而以极小的参数量来实现大模型的间接训练。</p>\n<p>特点：</p>\n<p>将 BA 加到 W 上可以消除推理延迟。<br>\n可以通过可插拔的形式切换到不同的任务。<br>\n设计的比较好，简单且效果好。</p>\n<p>AdaLoRA<br>\n 对 LoRA 的一种改进，它根据重要性评分动态分配参数预算给权重矩阵，将关键的增量矩阵分配高秩以捕捉更精细和任务特定的信息，而将较不重要的矩阵的秩降低，以防止过拟合并节省计算预算。</p>\n<p>QLoRA<br>\n 使用一种新颖的高精度技术将预训练模型量化为 4 bit，然后添加一小组可学习的低秩适配器权重，这些权重通过量化权重的反向传播梯度进行微调。</p>\n<p>特点：</p>\n<p>使用 QLoRA 微调模型，可以显著降低对于显存的要求。同时，模型训练的速度会慢于 LoRA。<br>\nMAM Adapter<br>\n 一种在 Adapter、Prefix Tuning 和 LoRA 之间建立联系的统一方法。最终的模型 MAM Adapter 是用于 FFN 的并行 Adapter 和 软提示的组合。</p>\n<p>特点：</p>\n<p>整体上来说，最终的模型 MAM Adapter 效果会优于单个高效微调方法。<br>\nUniPELT<br>\n 一种将不同的 PELT 方法 LoRA、Prefix Tuning 和 Adapter 作为子模块，并通过门控机制学习激活最适合当前数据或任务的方法。</p>\n<p>特点：</p>\n<p>相对于 LoRA，BitFit，Prefix-tuning，训练的参数量更大；同时，推理更耗时；并且，输入会占用额外的序列长度。<br>\n多种 PELT 方法的混合涉及 PLM 的不同部分对模型有效性和鲁棒性都有好处。</p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/07/23/AI/Prompt_engineering/",
            "url": "http://qianqiu-cell.github.io/2024/07/23/AI/Prompt_engineering/",
            "title": "大模型提示词工程（Prompt Engineering）",
            "date_published": "2024-07-22T16:00:00.000Z",
            "content_html": "<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL3dzeWFkYy9nZW5lcmF0aXZlLWFpLWZvci1iZWdpbm5lcnM=\">https://github.com/wsyadc/generative-ai-for-beginners</span></p>\n<h1 id=\"一-什么是提示词工程\"><a class=\"markdownIt-Anchor\" href=\"#一-什么是提示词工程\">#</a> 一、什么是提示词工程</h1>\n<p>  提示工程被定义为设计和优化文本输入（提示）以提供一致且高质量响应（完成）的过程，以实现特定的应用目标和模型。提示工程是创建将产生所需结果的提示的过程。 提示工程不仅仅是编写文本提示。提示工程不是一门工程学科，它更像是一组可以应用以获得所需结果的技术。我们可以将其视为一个两步过程：</p>\n<ul>\n<li>为特定模型和目标设计初始提示</li>\n<li>迭代地优化提示以提高响应质量</li>\n</ul>\n<p>  这必然是一个需要用户直觉和努力的试错过程，以获得最佳结果。那么，为什么这很重要？要回答这个问题，我们首先需要理解三个概念：</p>\n<ul>\n<li>Tokenization = 模型如何 “看到” 提示</li>\n<li>Base LLMs = 基础模型如何 “处理” 提示</li>\n<li>Instruction-Tuned LLMs = 模型现在如何看到 “任务”</li>\n</ul>\n<h1 id=\"二-为什么我们需要提示词工程\"><a class=\"markdownIt-Anchor\" href=\"#二-为什么我们需要提示词工程\">#</a> 二、为什么我们需要提示词工程</h1>\n<p>  现在我们知道了 LLMs 如何处理提示，让我们谈谈为什么我们需要提示工程。 答案在于，当前的 LLMs 的算法也有许多挑战，如果不及时优化，就很难实现 “可靠且一致的补全”。 例如：</p>\n<ul>\n<li>\n<p>== 模型响应是随机的。== 相同的提示可能会针对不同的模型或模型版本产生不同的响应。 甚至可能在不同时间使用相同模型产生不同的结果。 提示工程技术可以通过提供更好帮助我们最大限度地减少这些变化所带来的影响。</p>\n</li>\n<li>\n<p>== 模型可以产生幻觉响应。== 模型是使用大型但有限数据集进行预训练的，这意味着它们缺乏有关训练范围之外的概念的知识。 因此，它们可能会产生不准确、虚构或与已知事实直接矛盾的完成结果。 提示工程技术可以帮助用户识别和减轻幻觉，例如通过向人工智能询问出处或推理过程。</p>\n</li>\n<li>\n<p>== 模型功能会有所不同。 == 较新的模型或模型迭代将具有更丰富的功能，但也会带来独特的怪癖以及成本和复杂性方面的平衡。 提示工程可以帮助我们开发最佳实践和工作流程，以可扩展和无缝的方式消除差异并适应特定于模型的要求。</p>\n</li>\n</ul>\n<h1 id=\"三-提示工程的技巧\"><a class=\"markdownIt-Anchor\" href=\"#三-提示工程的技巧\">#</a> 三、提示工程的技巧</h1>\n<p>  简单提示的局限性：简单提示可能无法得到你想要的结果，原因如下：（1）大话题；（2）没有限定输出格式。我们可以使用一些基本技巧来提示 LLM。</p>\n<h2 id=\"31-zero-shot-prompting-零样本提示\"><a class=\"markdownIt-Anchor\" href=\"#31-zero-shot-prompting-零样本提示\">#</a> 3.1 Zero-shot prompting （零样本提示）</h2>\n<p>  这种提示风格非常简单，它只有一个提示。当你开始学习 LLM 时，可能就会用到这种方法。下面是一个例子：</p>\n<ul>\n<li>Prompt: “What is Algebra?”</li>\n<li>Answer: “Algebra is a branch of mathematics that studies mathematical symbols and the rules for manipulating these symbols.”</li>\n</ul>\n<h2 id=\"32-few-shot-prompting-少样本提示\"><a class=\"markdownIt-Anchor\" href=\"#32-few-shot-prompting-少样本提示\">#</a> 3.2 Few-shot prompting （少样本提示）</h2>\n<p>  这种提示方式通过在提出请求的同时提供一些示例来帮助模型。它由单个提示和附加的特定任务数据组成。下面是一个例子：</p>\n<ul>\n<li>Prompt: &quot;以莎士比亚的风格写一首诗。下面是一些莎士比亚十四行诗的例子：十四行诗第 18 首：&quot; 我要把你比作夏日吗？你更可爱，更有节制…' 第 116 首十四行诗：&quot; 让我不要为真正心灵的结合设置障碍。爱不是爱，当它发现改变时就会改变…' 十四行诗第 132 首：“我爱你的眼睛，它们怜悯我，知道你的心在折磨我，对我不屑一顾… 现在，请写一首关于月亮之美的十四行诗。”</li>\n<li>Answer：“在天空中，月亮闪烁着柔和的光芒，散发着温柔的光辉，…”</li>\n</ul>\n<p>  示例为 LLM 提供了所需输出的背景、格式或风格。它们有助于模型理解具体任务，并生成更准确、更相关的回复。</p>\n<h2 id=\"33-chain-of-thought-cot-思维链\"><a class=\"markdownIt-Anchor\" href=\"#33-chain-of-thought-cot-思维链\">#</a> 3.3 Chain-of-thought （CoT, 思维链）</h2>\n<p>  链式思维是一种非常有趣的技术，因为它涉及让大型语言模型（LLM）经过一系列步骤。这个想法是以一种方式指导 LLM，使其理解如何完成某项任务。请考虑以下带有和不带链式思维的示例：</p>\n<ul>\n<li>Prompt: “Alice has 5 apples, throws 3 apples, gives 2 to Bob and Bob gives one back, how many apples does Alice have?”</li>\n<li>Answer: 5</li>\n</ul>\n<p>  LLM 给出的答案为 5，这是不正确的。 根据计算结果 (5 -3 -2 + 1 = 1)，正确答案是 1 个苹果。</p>\n<p>  那么我们怎样才能教 LLM 正确地做到这一点呢？让我们尝试一下思维链。 应用思维链意味着：</p>\n<p>  给 LLM 一个类似的例子。展示计算结果，以及如何正确计算。提供原始提示。</p>\n<ul>\n<li>Prompt: “Lisa has 7 apples, throws 1 apple, gives 4 apples to Bart and Bart gives one back: 7 -1 = 6 6 -4 = 2 2 +1 = 3<br>\nAlice has 5 apples, throws 3 apples, gives 2 to Bob and Bob gives one back, how many apples does Alice have?”</li>\n<li>Answer: 1</li>\n</ul>\n<p>  请注意我们如何用另一个示例、计算和原始提示编写更长的提示，然后得出正确答案 1。正如您所看到的，思维链是一种非常强大的技术。</p>\n<p>  其他更加丰富的 CoT，如零样本思维链，自洽性等可以参考<span class=\"exturl\" data-url=\"aHR0cHM6Ly9wcm9tcHRkZXYuYWkvemgtSGFucy9kb2NzL2ludGVybWVkaWF0ZS9zZWxmX2NvbnNpc3RlbmN5\"> https://promptdev.ai/zh-Hans/docs/intermediate/self_consistency</span>。</p>\n<h2 id=\"34-generated-knowledge-知识生成\"><a class=\"markdownIt-Anchor\" href=\"#34-generated-knowledge-知识生成\">#</a> 3.4 Generated knowledge （知识生成）</h2>\n<p>  生成的知识方法（Generated Knowledge Approach）1 要求 LLM 在生成响应之前生成与问题相关的可能有用的信息。该方法由两个中间步骤组成，即<mark>知识生成和知识集成</mark>。</p>\n<p><img data-src=\"/images/AI/Prompt_engineering/3.4.1.png\" alt=\"\"></p>\n<p>（1）知识生成</p>\n<p>  在知识生成步骤中，要求 LLM 生成有关问题的一组事实。大语言模型将以 few-shot 方式进行提示，如下所示。使用相同提示生成 M 个不同的完成。</p>\n<p><img data-src=\"/images/AI/Prompt_engineering/3.4.2.png\" alt=\"\"></p>\n<p>（2）知识集成</p>\n<p>  接下来，我们生成 “知识增强” 问题，并用它们提示 LLM 获得最终答案。最好的理解方法是通过一个例子来说明。</p>\n<p>  假设我们正在尝试回答问题 “大多数袋鼠有 <mask> 肢体”。假设在知识生成步骤中，我们生成了 2 个知识（M=2）：</p>\n<ul>\n<li>\n<p>知识 1：“袋鼠是生活在澳大利亚的有袋动物。”</p>\n</li>\n<li>\n<p>知识 2：“袋鼠是有 5 条肢体的有袋动物。”</p>\n</li>\n</ul>\n<p>  现在，我们将每个知识与问题连接起来，生成知识增强的问题：</p>\n<ul>\n<li>\n<p>知识增强问题 1：“大多数袋鼠有 <mask> 肢体。袋鼠是生活在澳大利亚的有袋动物。”</p>\n</li>\n<li>\n<p>知识增强问题 2：“大多数袋鼠有 <mask> 肢体。袋鼠是有 5 条肢体的有袋动物。”</p>\n</li>\n</ul>\n<p>  然后，我们用这些知识增强的问题提示 LLM，并获得最终答案的提案：</p>\n<ul>\n<li>\n<p>答案 1：“4”</p>\n</li>\n<li>\n<p>答案 2：“5”</p>\n</li>\n</ul>\n<p>  我们选择概率最高的答案作为最终答案。最高概率可能是答案令牌的 softmax 概率，或答案令牌的对数概率。</p>\n<h2 id=\"35-least-to-most-ltm-从少到多\"><a class=\"markdownIt-Anchor\" href=\"#35-least-to-most-ltm-从少到多\">#</a> 3.5 Least to Most （LtM, 从少到多）</h2>\n<p>  从最少到最多提示 (LtM) 1 使 CoT 提示更进一步，首先将问题分解为子问题，然后解决每个问题。这是一种受现实世界儿童教育策略启发的技术。</p>\n<p>  与 CoT 提示一样，要解决的问题被分解为一组相互构建的子问题。第二步，将这些子问题一一解决。与思维链相反，先前子问题的解决方案被输入到尝试解决下一个问题的提示中。</p>\n<p><img data-src=\"/images/AI/Prompt_engineering/3.5.1.png\" alt=\"\"></p>\n<h2 id=\"36-self-refine-critique-the-results-自我完善质疑结果\"><a class=\"markdownIt-Anchor\" href=\"#36-self-refine-critique-the-results-自我完善质疑结果\">#</a> 3.6 Self-refine, critique the results （自我完善，质疑结果）</h2>\n<p>  对于生成式人工智能和 LLMs，你不能相信其输出。 你需要验证一下。 毕竟， LLMs 只是向您展示下一个最有可能说的话，而不是正确的内容。 因此，一个好主意是要求 LLMs 自我批评，这引导我们自我完善技术。</p>\n<p>  其工作原理是按照以下步骤操作：</p>\n<ul>\n<li>要求 LLM 解决问题的初始提示</li>\n<li>LLM 产生答案</li>\n<li>质疑答案并要求人工智能改进</li>\n<li>LLM 再次回答，这次考虑了质疑并提出了解决方案</li>\n</ul>\n<p>  您可以根据需要多次重复此过程。</p>\n<h2 id=\"37-maieutic-prompting-多维度的提示\"><a class=\"markdownIt-Anchor\" href=\"#37-maieutic-prompting-多维度的提示\">#</a> 3.7 Maieutic prompting （多维度的提示）</h2>\n<p>  多维度的提示是一种类似于自我完善的技术，但它更多的是要求 LLMs 解释自己。 目标是减少 LLMs 输出不一致，以确保得出正确的答案。 要遵循的工作流程是：</p>\n<ul>\n<li>请 LLM 回答问题</li>\n<li>对于答案的每一部分，请 LLM 更深入地解释。</li>\n<li>如果存在不一致，则丢弃不一致的部分。</li>\n</ul>\n<p>  重复 2 和 3，直到您完成所有部分并对答案感到满意为止。</p>\n<h1 id=\"四-提示的关键要素\"><a class=\"markdownIt-Anchor\" href=\"#四-提示的关键要素\">#</a> 四、提示的关键要素</h1>\n<p>  在之前的页面中，我们已经讨论了几种不同的提示策略。本页将提供一般建议，这些建议对于提示的实际编写很重要</p>\n<p>（1）基本事实的重要性不大</p>\n<p>  令人惊讶的是，在提示中提供少量 exemplars 时，实际答案 (gold) 并不重要。即使在样本中提供随机标签，性能也几乎不受影响。</p>\n<p>（2）标签空间很重要</p>\n<p>  尽管样本中的黄金标签并不重要，但 labelspace 很重要。即使从标签空间中提供随机标签，也有助于大语言模型更好地理解标签空间并提高结果。此外，正确地在示例中表示标签空间的分布很重要。与在示例中从标签空间中均匀采样不同，最好按照标签的真实分布进行采样。</p>\n<p>（3）格式很重要</p>\n<p>  样本的格式或许是最重要的部分，因为它指示大语言格式如何正确地格式化其对提示的答案。</p>\n<p>  例如，请考虑以下样本。它们使用全大写的单词作为答案。尽管这些答案完全错误（2+2 不是 50），但 GPT-3 正确地回答了最后一个问题，并按照其他样本的格式进行回答。</p>\n<figure class=\"highlight markdown\"><figcaption data-lang=\"markdown\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>2+2等于多少？ </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>五十</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>20+5等于多少？</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>四十三</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>12+9等于多少？</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>二十一</pre></td></tr></table></figure><p>  以下是一些值得考虑的良好做法：</p>\n<ul>\n<li>指定上下文。 上下文很重要，您可以指定的领域、主题等越多越好。</li>\n<li>限制输出。 如果您想要特定数量的项目或特定长度，请指定。</li>\n<li>指定内容和方式。 请记住提及您想要什么以及您想要如何实现，例如 “创建一个包含路由产品和客户的 Python Web API，将其分为 3 个文件”。</li>\n<li>使用模板。 通常，您会希望使用公司的数据来丰富提示。 使用模板来执行此操作。 模板可以包含用实际数据替换的变量。</li>\n<li>拼写正确。 LLMs 可能会为您提供正确的答案，但如果您拼写正确，您会得到更好的答案。</li>\n</ul>\n<h1 id=\"五-din-sql和pet-sql\"><a class=\"markdownIt-Anchor\" href=\"#五-din-sql和pet-sql\">#</a> 五、DIN-SQL 和 PET-SQL</h1>\n<p>  用于参赛《中兴捧月大赛 - 精言妙喻》，主要参考论文有 DIN-SQL：《DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction》，PET-SQL：《PET-SQL: A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency》。两篇论文的主要思路如下：</p>\n<p><img data-src=\"/images/AI/Prompt_engineering/5.1.jpg\" alt=\"\"></p>\n<h1 id=\"六-中兴捧月大赛-精言妙喻个人初赛代码及思路\"><a class=\"markdownIt-Anchor\" href=\"#六-中兴捧月大赛-精言妙喻个人初赛代码及思路\">#</a> 六、《中兴捧月大赛 - 精言妙喻》个人初赛代码及思路</h1>\n<p>  具体文件可见 U 盘备份–&gt; 科研文件–&gt;9、第十四届中兴捧月全球精英挑战赛等。</p>\n",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/05/16/AI/Transformer/",
            "url": "http://qianqiu-cell.github.io/2024/05/16/AI/Transformer/",
            "title": "Transformer模型",
            "date_published": "2024-05-15T16:00:00.000Z",
            "content_html": "<p><img data-src=\"/images/AI/Transformer/0.1.png\" alt=\"\"></p>\n<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly93YXlsYW5kemhhbmcuZ2l0aHViLmlvL2VuL3RyYW5zZm9ybWVyLWFyY2hpdGVjdHVyZS5odG1sIzQtNy1jYWxjdWxhdGUtdi1hdHRlbnRpb24=\">https://waylandzhang.github.io/en/transformer-architecture.html#4-7-calculate-v-attention</span>、<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vMzU0NjYxMTUyNzQ1MzE2MT9zcG1faWRfZnJvbT0zMzMuNzg4LjAuMA==\">https://space.bilibili.com/3546611527453161?spm_id_from=333.788.0.0</span>、<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ubHAuc2Vhcy5oYXJ2YXJkLmVkdS8yMDE4LzA0LzAzL2F0dGVudGlvbi5odG1s\">https://nlp.seas.harvard.edu/2018/04/03/attention.html</span></p>\n<p>   <code>Transformer</code>  模型由两部分组成：编码器和解码器。一般来说，仅编码器的架构精通于从文本中提取信息，用于分类和回归等任务，而仅解码器的模型专门用于生成文本。例如，<mark>专注于文本生成的 <code>GPT</code>  属于仅解码器模型的类别</mark>。</p>\n<p>   <code>Transformer</code>  的大致过程如下：</p>\n<ul>\n<li>首先，我们需要一系列输入字符作为训练数据。这些输入被转换成矢量嵌入格式。</li>\n<li>接下来，我们将位置编码添加到矢量嵌入中，以捕获序列中每个字符的位置。</li>\n<li>随后，该模型通过一系列计算操作处理这些输入嵌入，最终为给定的输入文本生成可能的下一个字符的概率分布。</li>\n<li>该模型根据训练数据集中的实际后续特征来评估预测结果，并相应地调整概率或 “权重”。</li>\n<li>最后，该模型迭代地细化这个过程，不断更新其参数，以提高未来预测的精度。</li>\n</ul>\n<h1 id=\"一-tokenizer\"><a class=\"markdownIt-Anchor\" href=\"#一-tokenizer\">#</a> 一、Tokenizer</h1>\n<p>   <code>Tokenizer</code>  分词算法是 <code>NLP</code>  大模型最基础的组件，基于 <code>Tokenizer</code>  可以<mark>将文本转换成独立的 <code>token</code>  列表，进而转换成输入的向量成为计算机可以理解的输入形式</mark>。</p>\n<p>   <code>tiktoken</code>  是一种快速  <code>BPE</code>  标记器，可与 <code>OpenAI</code>  模型一起使用。</p>\n<p>   <code>tiktoken</code>  使用方法为：</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> tiktoken</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\"># Using TikToken (Same as GPT3) to tokenize the source text</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>encoding <span class=\"token operator\">=</span> tiktoken<span class=\"token punctuation\">.</span>get_encoding<span class=\"token punctuation\">(</span><span class=\"token string\">\"cl100k_base\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># text 保存了 str 变量类型的文本内容 --> 输出为以单词为单位的 int 列表</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>tokenized_text <span class=\"token operator\">=</span> encoding<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\"># 将 tokenized_text 转换为 Tensor.int64 类型的张量</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>tokenized_text <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span>tokenized_text<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">long</span><span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>  上述的代码提供了 <code>encoding</code>  的编码过程，同时还可以根据 <code>tokenized</code>  的编码结果进行解码，只需要通过 <code>decode</code>  函数输入 <code>int</code>  类型的列表集合返回原始的 str 类型文本</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 输出单个编码对应的 str 文本</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>encoding<span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>tokenized_text<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\"># 输出多个编码对应的 str 文本</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>encoding<span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span>tokenized_text<span class=\"token punctuation\">.</span>tolist<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"二-embedding\"><a class=\"markdownIt-Anchor\" href=\"#二-embedding\">#</a> 二、Embedding</h1>\n<p>   <code>Tokenize</code>  完的下一步就是将 <code>token</code>  的 <code>one-hot</code>  编码转换成更 <code>dense</code>  的 <code>embedding</code>  编码。</p>\n<p>   <code>Embedding</code>  矩阵的本质就是一个查找表。由于输入向量是 <code>one-hot</code>  的， <code>embedding</code>  矩阵中有且仅有一行被激活。行间互不干扰。如下图所示，假设词汇表一共有 <code>6</code>  个词，则 <code>one-hot</code>  表示的长度为 <code>6</code> 。现在我们有三个单词组成一个句子，则输入矩阵的形状为 <code>(3,6)</code>  。然后我们学出来一个 <code>embedding</code>  矩阵，根据上面的推导，如果我们的 <code>embedding size</code> （编码向量的长度）为 <code>4</code> ，则 <code>embedding</code>  矩阵的形状应该为 <code>(6,4)</code> 。这样乘出来的输出矩阵的形状应为 <code>(3,4)</code> 。</p>\n<p><img data-src=\"/images/AI/Transformer/2.1.jpg\" alt=\"\"></p>\n<p>  对于第一个单词 <code>I</code> ，假设其 <code>one-hot</code>  编码为 <code>[0,0,1,0,0,0]</code> ，将其与 <code>embedding</code>  矩阵相乘，相当于取出 <code>embedding</code>  矩阵的第 <code>3</code>  行（ <code>index</code>  为 <code>2</code> ）。同理，对于单词 <code>love</code> ，相当于取出 <code>embedding</code>  矩阵的第二行（ <code>index</code>  为 <code>1</code> ）。因此 <code>embedding</code>  矩阵的本质是一个查找表，每个单词会定位这个表中的某一行，而这一行就是这个单词学习到的在嵌入空间的语义。</p>\n<p>  首先准备所需要的数据，在 transformer 的解码器中，需要输入 <code>n_batch * context_length * d_model</code>  维度的 <code>Tensor</code>  数据，其中 <code>n_batch</code>  表示批次大小， <code>contex_length</code>  表示一次输入的单次数量， <code>d_model</code>  表示编码向量的长度。将 <code>Tokenizer</code>  中获得的 <code>tokenized_text</code>  进行数据预处理：</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># Split train and validation</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>split_idx <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>tokenized_text<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">0.9</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>train_data <span class=\"token operator\">=</span> tokenized_text<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>split_idx<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>val_data <span class=\"token operator\">=</span> tokenized_text<span class=\"token punctuation\">[</span>split_idx<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\"># Get input embedding batch</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>data <span class=\"token operator\">=</span> train_data</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>idxs <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>randint<span class=\"token punctuation\">(</span>low<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> high<span class=\"token operator\">=</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> context_length<span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>x_batch <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>stack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>idx<span class=\"token punctuation\">:</span>idx <span class=\"token operator\">+</span> context_length<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> idx <span class=\"token keyword\">in</span> idxs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>y_batch <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>stack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>idx <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>idx <span class=\"token operator\">+</span> context_length <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> idx <span class=\"token keyword\">in</span> idxs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>  之后便可以利用 <code>torch</code>  中的 <code>nn.Embedding</code>  函数构造 <code>Embedding</code>  层。其中 <code>Embedding.weight.data</code>  是一个 <code>max_token_value * d_model</code>  维度的 <code>Tensor</code>  变量，是模型需要训练的参数，同时也是上图中对应的 <code>Embedding</code>  查找表。</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># define input embedding table</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\"># 获取 tokenized_text 中的最大值 + 1，用于构造 Embedding 的行</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>max_token_value <span class=\"token operator\">=</span> tokenized_text<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 使用 nn.Embedding 函数构造 Embedding 层</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\"># `Embedding.weight.data` 是一个 `max_token_value * d_model` 维度的 `Tensor` 变量</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>token_embedding_lookup_table <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>num_embeddings<span class=\"token operator\">=</span>max_token_value<span class=\"token punctuation\">,</span> embedding_dim<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token comment\"># 通过输入 x_batch 或 y_batch 即可获得对应的 Embedding 编码结果</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token comment\"># x_batch_embedding 和 y_batch_embedding 是 `n_batch * context_length * d_model` 维度的 `Tensor` 数据</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>x_batch_embedding <span class=\"token operator\">=</span> token_embedding_lookup_table<span class=\"token punctuation\">(</span>x_batch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>y_batch_embedding <span class=\"token operator\">=</span> token_embedding_lookup_table<span class=\"token punctuation\">(</span>y_batch<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"三-position-encoding\"><a class=\"markdownIt-Anchor\" href=\"#三-position-encoding\">#</a> 三、Position Encoding</h1>\n<p>  在 <code>transformer</code>  的 <code>encoder</code>  和 <code>decoder</code>  的输入层中，均使用了 <code>Positional Encoding</code> ，使得最终的输入满足： <code>input = input_embedding + positional_encoding</code> 。</p>\n<p>   <code>Transformer</code>  位置编码的定义为：</p>\n<p><img data-src=\"/images/AI/Transformer/3.1.png\" alt=\"\"></p>\n<p>  实现位置编码的代码为：</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># get positional encoding</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>position_encoding_lookup_table <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span>context_length<span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\"># unsqueeze 用来扩充一个维度，为了后面的逐元素计算时的广播机制</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>position <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> context_length<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>unsqueeze<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\"># 根据公式计算位置编码</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>div_term <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">-</span>math<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span><span class=\"token number\">10000.0</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> d_model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>position_encoding_lookup_table<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>sin<span class=\"token punctuation\">(</span>position <span class=\"token operator\">*</span> div_term<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>position_encoding_lookup_table<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cos<span class=\"token punctuation\">(</span>position <span class=\"token operator\">*</span> div_term<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token comment\"># 将 context_length*d_model 的矩阵复制 n_epoch 次，形成 n_epoch*context_length*d_model 的矩阵</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>position_encoding_lookup_table <span class=\"token operator\">=</span> position_encoding_lookup_table<span class=\"token punctuation\">.</span>unsqueeze<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>expand<span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>  在获得位置编码之后即可将位置编码与 <code>Embedding</code>  进行相加，获得最终输入至网络的输入：</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># add positional encoding to the input_embedding</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>x <span class=\"token operator\">=</span> x_batch_embedding <span class=\"token operator\">+</span> position_encoding_lookup_table</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>y <span class=\"token operator\">=</span> y_batch_embedding <span class=\"token operator\">+</span> position_encoding_lookup_table</pre></td></tr></table></figure><h1 id=\"四-transformer-block\"><a class=\"markdownIt-Anchor\" href=\"#四-transformer-block\">#</a> 四、Transformer Block</h1>\n<p><img data-src=\"/images/AI/Transformer/4.1.png\" alt=\"\"></p>\n<p>  通过第三步，我们获得了输入 <code>x</code> ，下一步是开始实现多头注意力块（ <code>Muti-head Attention block</code> ）。</p>\n<p>   <code>Transformer</code>  模型的强大来源于 <code>self-attention</code> ，通过 <code>self-attention</code> ， <code>Transformer</code>  模型可以关注到 <code>input</code>  更加重要的部分。</p>\n<p>   <code>Multi-head attention</code>  由几个单独的 <code>heads</code>  堆叠在一起组成。所有 heads 都接收到完全相同的输入，尽管它们在计算过程中使用了自己的特定权重集。在处理输入之后，来自所有 <code>heads</code>  的输出被级联，然后通过线性层。</p>\n<p>   <code>heads</code>  的工作方式是通过三个独特的层处理，即查询（ <code>Q</code> ）、键（ <code>K</code> ）和值（ <code>V</code> ）。 <code>Attention</code>  的计算公式可以从论文《 <code>Attention is all you need</code> 》中得到：</p>\n<p><img data-src=\"/images/AI/Transformer/4.2.png\" alt=\"\"></p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># get Q, K, V</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\"># 所谓的多头就是把 d_model 切成多份，每一个头里面有一部分维度，然后去做这一部分的计算，最后再把所有的计算合并在一起</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>head_size <span class=\"token operator\">=</span> d_model <span class=\"token operator\">//</span> num_heads  <span class=\"token comment\"># head size should be divisible by d_model</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># (1) 计算 Q,K,V 矩阵</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>key_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>query_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>value_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>d_model<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token comment\"># [batch_size, context_length, d_model]</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>q <span class=\"token operator\">=</span> query_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>k <span class=\"token operator\">=</span> key_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>v <span class=\"token operator\">=</span> value_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token comment\"># [batch_size, context_length, num_heads, head_size]</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>q <span class=\"token operator\">=</span> q<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> num_heads<span class=\"token punctuation\">,</span> head_size<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>k <span class=\"token operator\">=</span> k<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> num_heads<span class=\"token punctuation\">,</span> head_size<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>v <span class=\"token operator\">=</span> v<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> num_heads<span class=\"token punctuation\">,</span> head_size<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre><span class=\"token comment\"># [batch_size, num_heads, context_length, head_size]</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>q <span class=\"token operator\">=</span> q<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>k <span class=\"token operator\">=</span> k<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>v <span class=\"token operator\">=</span> v<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre><span class=\"token comment\"># (2) 通过 Q @ K^T /sqrt (d_k) 计算 Attention</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>attention_score <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>q @ k<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1.0</span> <span class=\"token operator\">/</span> math<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>head_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre><span class=\"token comment\"># (3) 计算 Mask</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>mask <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>triu<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>ones<span class=\"token punctuation\">(</span>context_length<span class=\"token punctuation\">,</span> context_length<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> diagonal<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">bool</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>attention_score <span class=\"token operator\">=</span> attention_score<span class=\"token punctuation\">.</span>masked_fill<span class=\"token punctuation\">(</span>mask<span class=\"token punctuation\">,</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span><span class=\"token string\">'-inf'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre><span class=\"token comment\"># (4) 计算 Softmax</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre><span class=\"token comment\"># [batch_size, num_heads, context_length, context_length]</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>attention_score <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>attention_score<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre><span class=\"token comment\"># (5) 通过 $V 计算 A</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre><span class=\"token comment\"># [batch_size, num_heads, context_length, head_size]</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>A <span class=\"token operator\">=</span> attention_score @ v</pre></td></tr><tr><td data-num=\"31\"></td><td><pre><span class=\"token comment\"># (6) 计算 Concatenate</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre><span class=\"token comment\"># [batch_size, context_length, num_heads, head_size]</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>A <span class=\"token operator\">=</span> A<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre><span class=\"token comment\"># [batch_size, context_length, d_model]</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>A <span class=\"token operator\">=</span> A<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre><span class=\"token comment\"># (7) 通过 Wo 计算 Output</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre><span class=\"token comment\"># Define the output weight matrix</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre>Wo <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre><span class=\"token comment\"># [batch_size, context_length, d_model]</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>output <span class=\"token operator\">=</span> Wo<span class=\"token punctuation\">(</span>A<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"五-residual-connection-and-layer-normalization\"><a class=\"markdownIt-Anchor\" href=\"#五-residual-connection-and-layer-normalization\">#</a> 五、Residual Connection and Layer Normalization</h1>\n<p>  残差连接，有时被称为 <code>skip connection</code> ，是让原始输入 <code>X</code>  绕过一个或多个层的连接。通过将原始输入 <code>x</code>  与步骤四多头注意力层的输出 <code>output</code>  相加即可完成操作。</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo>=</mo><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo>+</mo><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">output = output + x\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.80952em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.80952em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span></span></p>\n<p>  在残差连接之后，过程进入层归一化。层归一化（ <code>LayerNorm</code> ）是一种用于对网络中每一层的输出进行归一化的技术。其方法是减去输出的均值，并除以输出的标准差。使用这种技术是为了防止某一层的输出变得过大或过小，从而避免网络的不稳定性。</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># Add residual connection</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>output <span class=\"token operator\">=</span> output <span class=\"token operator\">+</span> X</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># Add Layer Normalization</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>layer_norm <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>LayerNorm<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>output <span class=\"token operator\">=</span> layer_norm<span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"六-feed-forward-network\"><a class=\"markdownIt-Anchor\" href=\"#六-feed-forward-network\">#</a> 六、Feed-Forward Network</h1>\n<p>  一旦我们获得了归一化的注意力权重（概率分数），它将被传递到一个位置级前馈网络中进行处理。前馈神经网络（ <code>FFN</code> ）由两个线性层和它们之间的 ReLU 激活函数组成。</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># update x</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>x <span class=\"token operator\">=</span> output</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># Define Feed Forward Network</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>output <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">,</span> d_model <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>output <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>output <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>d_model <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>output <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>dropout<span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">,</span> p<span class=\"token operator\">=</span>dropout<span class=\"token punctuation\">,</span> train<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\"># Add residual connection</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>output <span class=\"token operator\">=</span> output <span class=\"token operator\">+</span> x</pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token comment\"># Add Layer Normalization</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>layer_norm <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>LayerNorm<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>output <span class=\"token operator\">=</span> layer_norm<span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"七-repeat-step-4-to-6\"><a class=\"markdownIt-Anchor\" href=\"#七-repeat-step-4-to-6\">#</a> 七、Repeat step 4 to 6</h1>\n<p>  以上我们完成的只是一个 <code>transformer</code>  块。在实际应用中，我们会将多个 <code>transformer</code>  块堆叠在一起，形成一个 <code>transformer</code>  解码器。</p>\n<p>  实际上，我们应该将代码封装到类中，并使用 <code>PyTorch</code>  的 <code>nn.Module</code>  来构建我们的 <code>transformer</code>  解码器。但为了演示，我们只使用一个块。</p>\n<h1 id=\"八-output-probabilities\"><a class=\"markdownIt-Anchor\" href=\"#八-output-probabilities\">#</a> 八、Output Probabilities</h1>\n<p>  应用最后一个线性层来获得我们的 <code>logits</code> ：</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>logits <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">,</span> max_token_value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>  最后一步是对逻辑回归输出进行 <code>softmax</code>  操作，以获得每个 <code>token</code>  的概率：</p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># torch.softmax usually used during inference, during training we use torch.nn.CrossEntropyLoss</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\"># but for illustration purpose, we'll use torch.softmax here</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>probabilities <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>logits<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"full-working-code\"><a class=\"markdownIt-Anchor\" href=\"#full-working-code\">#</a> Full Working Code</h1>\n<p>  完整的代码可以参考 <code>github</code> : <span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL3dheWxhbmR6aGFuZy9UcmFuc2Zvcm1lci1mcm9tLXNjcmF0Y2g=\">https://github.com/waylandzhang/Transformer-from-scratch</span></p>\n<figure class=\"highlight py\"><figcaption data-lang=\"Python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> os</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> requests</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">import</span> math</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">import</span> tiktoken</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">import</span> torch</pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">as</span> nn</pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token keyword\">from</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">import</span> functional <span class=\"token keyword\">as</span> F</pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token comment\"># Hyperparameters</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>batch_size <span class=\"token operator\">=</span> <span class=\"token number\">4</span>  <span class=\"token comment\"># How many batches per training step</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>context_length <span class=\"token operator\">=</span> <span class=\"token number\">16</span>  <span class=\"token comment\"># Length of the token chunk each batch</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>d_model <span class=\"token operator\">=</span> <span class=\"token number\">64</span>  <span class=\"token comment\"># The size of our model token embeddings</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>num_blocks <span class=\"token operator\">=</span> <span class=\"token number\">8</span>  <span class=\"token comment\"># Number of transformer blocks</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>num_heads <span class=\"token operator\">=</span> <span class=\"token number\">4</span>  <span class=\"token comment\"># Number of heads in Multi-head attention</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>learning_rate <span class=\"token operator\">=</span> <span class=\"token number\">1e-3</span>  <span class=\"token comment\"># 0.001</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>dropout <span class=\"token operator\">=</span> <span class=\"token number\">0.1</span>  <span class=\"token comment\"># Dropout rate</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>max_iters <span class=\"token operator\">=</span> <span class=\"token number\">5000</span>  <span class=\"token comment\"># Total of training iterations &lt;- Change this to smaller number for testing</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>eval_interval <span class=\"token operator\">=</span> <span class=\"token number\">50</span>  <span class=\"token comment\"># How often to evaluate</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>eval_iters <span class=\"token operator\">=</span> <span class=\"token number\">20</span>  <span class=\"token comment\"># Number of iterations to average for evaluation</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>device <span class=\"token operator\">=</span> <span class=\"token string\">'cuda'</span> <span class=\"token keyword\">if</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>is_available<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">else</span> <span class=\"token string\">'cpu'</span>  <span class=\"token comment\"># Use GPU if it's available.</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>TORCH_SEED <span class=\"token operator\">=</span> <span class=\"token number\">1337</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>torch<span class=\"token punctuation\">.</span>manual_seed<span class=\"token punctuation\">(</span>TORCH_SEED<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre></pre></td></tr><tr><td data-num=\"24\"></td><td><pre><span class=\"token comment\"># Load training data</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre><span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>exists<span class=\"token punctuation\">(</span><span class=\"token string\">'data/sales_textbook.txt'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>    url <span class=\"token operator\">=</span> <span class=\"token string\">'https://huggingface.co/datasets/goendalf666/sales-textbook_for_convincing_and_selling/raw/main/sales_textbook.txt'</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'data/sales_textbook.txt'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'w'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>        f<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span>requests<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span>url<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre></pre></td></tr><tr><td data-num=\"30\"></td><td><pre><span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'data/sales_textbook.txt'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>    text <span class=\"token operator\">=</span> f<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre></pre></td></tr><tr><td data-num=\"33\"></td><td><pre><span class=\"token comment\"># Using TikToken (Same as GPT3) to tokenize the source text</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>encoding <span class=\"token operator\">=</span> tiktoken<span class=\"token punctuation\">.</span>get_encoding<span class=\"token punctuation\">(</span><span class=\"token string\">\"cl100k_base\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>tokenized_text <span class=\"token operator\">=</span> encoding<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>max_token_value <span class=\"token operator\">=</span> <span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>tokenized_text<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span>  <span class=\"token comment\"># the maximum value of the tokenized numbers</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>tokenized_text <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span>tokenized_text<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">long</span><span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># put tokenized text into tensor</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre></pre></td></tr><tr><td data-num=\"39\"></td><td><pre><span class=\"token comment\"># Split train and validation</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>split_idx <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>tokenized_text<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">0.9</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>train_data <span class=\"token operator\">=</span> tokenized_text<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>split_idx<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre>val_data <span class=\"token operator\">=</span> tokenized_text<span class=\"token punctuation\">[</span>split_idx<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"43\"></td><td><pre></pre></td></tr><tr><td data-num=\"44\"></td><td><pre></pre></td></tr><tr><td data-num=\"45\"></td><td><pre><span class=\"token comment\"># Define Feed Forward Network</span></pre></td></tr><tr><td data-num=\"46\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">FeedForward</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"47\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"48\"></td><td><pre>        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"49\"></td><td><pre>        self<span class=\"token punctuation\">.</span>d_model <span class=\"token operator\">=</span> d_model</pre></td></tr><tr><td data-num=\"50\"></td><td><pre>        self<span class=\"token punctuation\">.</span>dropout <span class=\"token operator\">=</span> dropout</pre></td></tr><tr><td data-num=\"51\"></td><td><pre>        self<span class=\"token punctuation\">.</span>ffn <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"52\"></td><td><pre>            nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"53\"></td><td><pre>            nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"54\"></td><td><pre>            nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"55\"></td><td><pre>            nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>dropout<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"56\"></td><td><pre>        <span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"57\"></td><td><pre></pre></td></tr><tr><td data-num=\"58\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"59\"></td><td><pre>        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>ffn<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"60\"></td><td><pre></pre></td></tr><tr><td data-num=\"61\"></td><td><pre></pre></td></tr><tr><td data-num=\"62\"></td><td><pre><span class=\"token comment\"># Define Scaled Dot Product Attention</span></pre></td></tr><tr><td data-num=\"63\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">Attention</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"64\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> head_size<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"65\"></td><td><pre>        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"66\"></td><td><pre>        self<span class=\"token punctuation\">.</span>d_model <span class=\"token operator\">=</span> d_model</pre></td></tr><tr><td data-num=\"67\"></td><td><pre>        self<span class=\"token punctuation\">.</span>head_size <span class=\"token operator\">=</span> head_size</pre></td></tr><tr><td data-num=\"68\"></td><td><pre>        self<span class=\"token punctuation\">.</span>context_length <span class=\"token operator\">=</span> context_length</pre></td></tr><tr><td data-num=\"69\"></td><td><pre>        self<span class=\"token punctuation\">.</span>dropout <span class=\"token operator\">=</span> dropout</pre></td></tr><tr><td data-num=\"70\"></td><td><pre></pre></td></tr><tr><td data-num=\"71\"></td><td><pre>        self<span class=\"token punctuation\">.</span>key_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>head_size<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"72\"></td><td><pre>        self<span class=\"token punctuation\">.</span>query_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>head_size<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"73\"></td><td><pre>        self<span class=\"token punctuation\">.</span>value_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>head_size<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"74\"></td><td><pre>        self<span class=\"token punctuation\">.</span>register_buffer<span class=\"token punctuation\">(</span><span class=\"token string\">'tril'</span><span class=\"token punctuation\">,</span> torch<span class=\"token punctuation\">.</span>tril<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"75\"></td><td><pre>            torch<span class=\"token punctuation\">.</span>ones<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>context_length<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>context_length<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># Lower triangular mask</span></pre></td></tr><tr><td data-num=\"76\"></td><td><pre>        self<span class=\"token punctuation\">.</span>dropout_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>dropout<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"77\"></td><td><pre></pre></td></tr><tr><td data-num=\"78\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"79\"></td><td><pre>        B<span class=\"token punctuation\">,</span> T<span class=\"token punctuation\">,</span> C <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>shape  <span class=\"token comment\"># Batch size, Time steps(current context_length), Channels(dimensions)</span></pre></td></tr><tr><td data-num=\"80\"></td><td><pre>        <span class=\"token keyword\">assert</span> T <span class=\"token operator\">&lt;=</span> self<span class=\"token punctuation\">.</span>context_length</pre></td></tr><tr><td data-num=\"81\"></td><td><pre>        <span class=\"token keyword\">assert</span> C <span class=\"token operator\">==</span> self<span class=\"token punctuation\">.</span>d_model</pre></td></tr><tr><td data-num=\"82\"></td><td><pre>        q <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>query_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"83\"></td><td><pre>        k <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>key_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"84\"></td><td><pre>        v <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>value_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"85\"></td><td><pre></pre></td></tr><tr><td data-num=\"86\"></td><td><pre>        <span class=\"token comment\"># Scaled dot product attention: Q @ K^T / sqrt(d_k)</span></pre></td></tr><tr><td data-num=\"87\"></td><td><pre>        weights <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>q @ k<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1.0</span> <span class=\"token operator\">/</span> math<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>k<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"88\"></td><td><pre>        <span class=\"token comment\"># Apply masked attention</span></pre></td></tr><tr><td data-num=\"89\"></td><td><pre>        weights <span class=\"token operator\">=</span> weights<span class=\"token punctuation\">.</span>masked_fill<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>tril<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>T<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span>T<span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span><span class=\"token string\">'-inf'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"90\"></td><td><pre>        weights <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span><span class=\"token builtin\">input</span><span class=\"token operator\">=</span>weights<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"91\"></td><td><pre>        weights <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>dropout_layer<span class=\"token punctuation\">(</span>weights<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"92\"></td><td><pre></pre></td></tr><tr><td data-num=\"93\"></td><td><pre>        <span class=\"token comment\"># Apply dot product attention: weights @ V</span></pre></td></tr><tr><td data-num=\"94\"></td><td><pre>        out <span class=\"token operator\">=</span> weights @ v</pre></td></tr><tr><td data-num=\"95\"></td><td><pre>        <span class=\"token keyword\">return</span> out</pre></td></tr><tr><td data-num=\"96\"></td><td><pre></pre></td></tr><tr><td data-num=\"97\"></td><td><pre></pre></td></tr><tr><td data-num=\"98\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">MultiHeadAttention</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"99\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> head_size<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"100\"></td><td><pre>        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"101\"></td><td><pre>        self<span class=\"token punctuation\">.</span>num_heads <span class=\"token operator\">=</span> num_heads</pre></td></tr><tr><td data-num=\"102\"></td><td><pre>        self<span class=\"token punctuation\">.</span>head_size <span class=\"token operator\">=</span> head_size</pre></td></tr><tr><td data-num=\"103\"></td><td><pre>        self<span class=\"token punctuation\">.</span>d_model <span class=\"token operator\">=</span> d_model</pre></td></tr><tr><td data-num=\"104\"></td><td><pre>        self<span class=\"token punctuation\">.</span>context_length <span class=\"token operator\">=</span> context_length</pre></td></tr><tr><td data-num=\"105\"></td><td><pre>        self<span class=\"token punctuation\">.</span>dropout <span class=\"token operator\">=</span> dropout</pre></td></tr><tr><td data-num=\"106\"></td><td><pre></pre></td></tr><tr><td data-num=\"107\"></td><td><pre>        self<span class=\"token punctuation\">.</span>heads <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>ModuleList<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>Attention<span class=\"token punctuation\">(</span>head_size<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>head_size<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>num_heads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"108\"></td><td><pre>        self<span class=\"token punctuation\">.</span>projection_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"109\"></td><td><pre>        self<span class=\"token punctuation\">.</span>dropout_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>dropout<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"110\"></td><td><pre></pre></td></tr><tr><td data-num=\"111\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"112\"></td><td><pre>        out <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>h<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> h <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>heads<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"113\"></td><td><pre>        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>projection_layer<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"114\"></td><td><pre>        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>dropout_layer<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"115\"></td><td><pre>        <span class=\"token keyword\">return</span> out</pre></td></tr><tr><td data-num=\"116\"></td><td><pre></pre></td></tr><tr><td data-num=\"117\"></td><td><pre></pre></td></tr><tr><td data-num=\"118\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">TransformerBlock</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"119\"></td><td><pre></pre></td></tr><tr><td data-num=\"120\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> num_heads<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"121\"></td><td><pre>        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"122\"></td><td><pre>        self<span class=\"token punctuation\">.</span>d_model <span class=\"token operator\">=</span> d_model</pre></td></tr><tr><td data-num=\"123\"></td><td><pre>        self<span class=\"token punctuation\">.</span>context_length <span class=\"token operator\">=</span> context_length</pre></td></tr><tr><td data-num=\"124\"></td><td><pre>        self<span class=\"token punctuation\">.</span>head_size <span class=\"token operator\">=</span> d_model <span class=\"token operator\">//</span> num_heads  <span class=\"token comment\"># head size should be divisible by d_model</span></pre></td></tr><tr><td data-num=\"125\"></td><td><pre>        self<span class=\"token punctuation\">.</span>num_heads <span class=\"token operator\">=</span> num_heads</pre></td></tr><tr><td data-num=\"126\"></td><td><pre>        self<span class=\"token punctuation\">.</span>dropout <span class=\"token operator\">=</span> dropout</pre></td></tr><tr><td data-num=\"127\"></td><td><pre></pre></td></tr><tr><td data-num=\"128\"></td><td><pre>        self<span class=\"token punctuation\">.</span>multi_head_attention_layer <span class=\"token operator\">=</span> MultiHeadAttention<span class=\"token punctuation\">(</span>head_size<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>head_size<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"129\"></td><td><pre>        self<span class=\"token punctuation\">.</span>feed_forward_layer <span class=\"token operator\">=</span> FeedForward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"130\"></td><td><pre>        self<span class=\"token punctuation\">.</span>layer_norm_1 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>LayerNorm<span class=\"token punctuation\">(</span>normalized_shape<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"131\"></td><td><pre>        self<span class=\"token punctuation\">.</span>layer_norm_2 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>LayerNorm<span class=\"token punctuation\">(</span>normalized_shape<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"132\"></td><td><pre></pre></td></tr><tr><td data-num=\"133\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"134\"></td><td><pre>        <span class=\"token comment\"># Note: The order of the operations is different from the original Transformer paper</span></pre></td></tr><tr><td data-num=\"135\"></td><td><pre>        <span class=\"token comment\"># The order here is: LayerNorm -> Multi-head attention -> LayerNorm -> Feed forward</span></pre></td></tr><tr><td data-num=\"136\"></td><td><pre>        x <span class=\"token operator\">=</span> x <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>multi_head_attention_layer<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>layer_norm_1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># Residual connection</span></pre></td></tr><tr><td data-num=\"137\"></td><td><pre>        x <span class=\"token operator\">=</span> x <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>feed_forward_layer<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>layer_norm_2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># Residual connection</span></pre></td></tr><tr><td data-num=\"138\"></td><td><pre>        <span class=\"token keyword\">return</span> x</pre></td></tr><tr><td data-num=\"139\"></td><td><pre></pre></td></tr><tr><td data-num=\"140\"></td><td><pre></pre></td></tr><tr><td data-num=\"141\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">TransformerLanguageModel</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"142\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"143\"></td><td><pre>        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"144\"></td><td><pre>        self<span class=\"token punctuation\">.</span>d_model <span class=\"token operator\">=</span> d_model</pre></td></tr><tr><td data-num=\"145\"></td><td><pre>        self<span class=\"token punctuation\">.</span>context_length <span class=\"token operator\">=</span> context_length</pre></td></tr><tr><td data-num=\"146\"></td><td><pre>        self<span class=\"token punctuation\">.</span>num_heads <span class=\"token operator\">=</span> num_heads</pre></td></tr><tr><td data-num=\"147\"></td><td><pre>        self<span class=\"token punctuation\">.</span>num_blocks <span class=\"token operator\">=</span> num_blocks</pre></td></tr><tr><td data-num=\"148\"></td><td><pre>        self<span class=\"token punctuation\">.</span>dropout <span class=\"token operator\">=</span> dropout</pre></td></tr><tr><td data-num=\"149\"></td><td><pre>        self<span class=\"token punctuation\">.</span>max_token_value <span class=\"token operator\">=</span> max_token_value</pre></td></tr><tr><td data-num=\"150\"></td><td><pre>        <span class=\"token comment\"># Set up token embedding look-up table</span></pre></td></tr><tr><td data-num=\"151\"></td><td><pre>        self<span class=\"token punctuation\">.</span>token_embedding_lookup_table <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>num_embeddings<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>max_token_value <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> embedding_dim<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"152\"></td><td><pre></pre></td></tr><tr><td data-num=\"153\"></td><td><pre>        <span class=\"token comment\"># Run all the transformer blocks</span></pre></td></tr><tr><td data-num=\"154\"></td><td><pre>        <span class=\"token comment\"># Different from original paper, here we add a final layer norm after all the blocks</span></pre></td></tr><tr><td data-num=\"155\"></td><td><pre>        self<span class=\"token punctuation\">.</span>transformer_blocks <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span><span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"156\"></td><td><pre>                <span class=\"token punctuation\">[</span>TransformerBlock<span class=\"token punctuation\">(</span>num_heads<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>num_heads<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>num_blocks<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span></pre></td></tr><tr><td data-num=\"157\"></td><td><pre>                <span class=\"token punctuation\">[</span>nn<span class=\"token punctuation\">.</span>LayerNorm<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"158\"></td><td><pre>        <span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"159\"></td><td><pre>        self<span class=\"token punctuation\">.</span>language_model_out_linear_layer <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>in_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">,</span> out_features<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>max_token_value<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"160\"></td><td><pre></pre></td></tr><tr><td data-num=\"161\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> idx<span class=\"token punctuation\">,</span> targets<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"162\"></td><td><pre>        B<span class=\"token punctuation\">,</span> T <span class=\"token operator\">=</span> idx<span class=\"token punctuation\">.</span>shape</pre></td></tr><tr><td data-num=\"163\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"164\"></td><td><pre>        # Set up position embedding look-up table</pre></td></tr><tr><td data-num=\"165\"></td><td><pre>        # following the same approach as the original Transformer paper (Sine and Cosine functions)</pre></td></tr><tr><td data-num=\"166\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"167\"></td><td><pre>        position_encoding_lookup_table <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>context_length<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"168\"></td><td><pre>        position <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>context_length<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>unsqueeze<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"169\"></td><td><pre>        div_term <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">-</span>math<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span><span class=\"token number\">10000.0</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"170\"></td><td><pre>        position_encoding_lookup_table<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>sin<span class=\"token punctuation\">(</span>position <span class=\"token operator\">*</span> div_term<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"171\"></td><td><pre>        position_encoding_lookup_table<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cos<span class=\"token punctuation\">(</span>position <span class=\"token operator\">*</span> div_term<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"172\"></td><td><pre>        <span class=\"token comment\"># change position_encoding_lookup_table from (context_length, d_model) to (T, d_model)</span></pre></td></tr><tr><td data-num=\"173\"></td><td><pre>        position_embedding <span class=\"token operator\">=</span> position_encoding_lookup_table<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>T<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"174\"></td><td><pre>        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>token_embedding_lookup_table<span class=\"token punctuation\">(</span>idx<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> position_embedding</pre></td></tr><tr><td data-num=\"175\"></td><td><pre>        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>transformer_blocks<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"176\"></td><td><pre>        <span class=\"token comment\"># The \"logits\" are the output values of our model before applying softmax</span></pre></td></tr><tr><td data-num=\"177\"></td><td><pre>        logits <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>language_model_out_linear_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"178\"></td><td><pre></pre></td></tr><tr><td data-num=\"179\"></td><td><pre>        <span class=\"token keyword\">if</span> targets <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"180\"></td><td><pre>            B<span class=\"token punctuation\">,</span> T<span class=\"token punctuation\">,</span> C <span class=\"token operator\">=</span> logits<span class=\"token punctuation\">.</span>shape</pre></td></tr><tr><td data-num=\"181\"></td><td><pre>            logits_reshaped <span class=\"token operator\">=</span> logits<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>B <span class=\"token operator\">*</span> T<span class=\"token punctuation\">,</span> C<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"182\"></td><td><pre>            targets_reshaped <span class=\"token operator\">=</span> targets<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>B <span class=\"token operator\">*</span> T<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"183\"></td><td><pre>            loss <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>cross_entropy<span class=\"token punctuation\">(</span><span class=\"token builtin\">input</span><span class=\"token operator\">=</span>logits_reshaped<span class=\"token punctuation\">,</span> target<span class=\"token operator\">=</span>targets_reshaped<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"184\"></td><td><pre>        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"185\"></td><td><pre>            loss <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span></pre></td></tr><tr><td data-num=\"186\"></td><td><pre>        <span class=\"token keyword\">return</span> logits<span class=\"token punctuation\">,</span> loss</pre></td></tr><tr><td data-num=\"187\"></td><td><pre></pre></td></tr><tr><td data-num=\"188\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">generate</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> idx<span class=\"token punctuation\">,</span> max_new_tokens<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"189\"></td><td><pre>        <span class=\"token comment\"># idx is (B,T) array of indices in the current context</span></pre></td></tr><tr><td data-num=\"190\"></td><td><pre>        <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>max_new_tokens<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"191\"></td><td><pre>            <span class=\"token comment\"># Crop idx to the max size of our positional embeddings table</span></pre></td></tr><tr><td data-num=\"192\"></td><td><pre>            idx_crop <span class=\"token operator\">=</span> idx<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span>self<span class=\"token punctuation\">.</span>context_length<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"193\"></td><td><pre>            <span class=\"token comment\"># Get predictions</span></pre></td></tr><tr><td data-num=\"194\"></td><td><pre>            logits<span class=\"token punctuation\">,</span> loss <span class=\"token operator\">=</span> self<span class=\"token punctuation\">(</span>idx_crop<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"195\"></td><td><pre>            <span class=\"token comment\"># Get the last time step from logits where the dimensions of the logits are (B,T,C)</span></pre></td></tr><tr><td data-num=\"196\"></td><td><pre>            logits_last_timestep <span class=\"token operator\">=</span> logits<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"197\"></td><td><pre>            <span class=\"token comment\"># Apply softmax to get probabilities</span></pre></td></tr><tr><td data-num=\"198\"></td><td><pre>            probs <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span><span class=\"token builtin\">input</span><span class=\"token operator\">=</span>logits_last_timestep<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"199\"></td><td><pre>            <span class=\"token comment\"># Sample from the probabilities' distribution.</span></pre></td></tr><tr><td data-num=\"200\"></td><td><pre>            idx_next <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>multinomial<span class=\"token punctuation\">(</span><span class=\"token builtin\">input</span><span class=\"token operator\">=</span>probs<span class=\"token punctuation\">,</span> num_samples<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"201\"></td><td><pre>            <span class=\"token comment\"># Append the sampled indexes idx_next to idx</span></pre></td></tr><tr><td data-num=\"202\"></td><td><pre>            idx <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>idx<span class=\"token punctuation\">,</span> idx_next<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"203\"></td><td><pre>        <span class=\"token keyword\">return</span> idx</pre></td></tr><tr><td data-num=\"204\"></td><td><pre></pre></td></tr><tr><td data-num=\"205\"></td><td><pre></pre></td></tr><tr><td data-num=\"206\"></td><td><pre><span class=\"token comment\"># Initialize the model</span></pre></td></tr><tr><td data-num=\"207\"></td><td><pre>model <span class=\"token operator\">=</span> TransformerLanguageModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"208\"></td><td><pre>model <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"209\"></td><td><pre></pre></td></tr><tr><td data-num=\"210\"></td><td><pre></pre></td></tr><tr><td data-num=\"211\"></td><td><pre><span class=\"token comment\"># Get input embedding batch</span></pre></td></tr><tr><td data-num=\"212\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">get_batch</span><span class=\"token punctuation\">(</span>split<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"213\"></td><td><pre>    data <span class=\"token operator\">=</span> train_data <span class=\"token keyword\">if</span> split <span class=\"token operator\">==</span> <span class=\"token string\">'train'</span> <span class=\"token keyword\">else</span> val_data</pre></td></tr><tr><td data-num=\"214\"></td><td><pre>    idxs <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>randint<span class=\"token punctuation\">(</span>low<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> high<span class=\"token operator\">=</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> context_length<span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"215\"></td><td><pre>    x <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>stack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>idx<span class=\"token punctuation\">:</span>idx <span class=\"token operator\">+</span> context_length<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> idx <span class=\"token keyword\">in</span> idxs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"216\"></td><td><pre>    y <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>stack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>idx <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>idx <span class=\"token operator\">+</span> context_length <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> idx <span class=\"token keyword\">in</span> idxs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"217\"></td><td><pre>    <span class=\"token keyword\">return</span> x<span class=\"token punctuation\">,</span> y</pre></td></tr><tr><td data-num=\"218\"></td><td><pre></pre></td></tr><tr><td data-num=\"219\"></td><td><pre></pre></td></tr><tr><td data-num=\"220\"></td><td><pre><span class=\"token comment\"># Calculate loss</span></pre></td></tr><tr><td data-num=\"221\"></td><td><pre><span class=\"token decorator annotation punctuation\">@torch<span class=\"token punctuation\">.</span>no_grad</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"222\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">estimate_loss</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"223\"></td><td><pre>    out <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"224\"></td><td><pre>    model<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"225\"></td><td><pre>    <span class=\"token keyword\">for</span> split <span class=\"token keyword\">in</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'train'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'valid'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"226\"></td><td><pre>        losses <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span>eval_iters<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"227\"></td><td><pre>        <span class=\"token keyword\">for</span> k <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>eval_iters<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"228\"></td><td><pre>            x_batch<span class=\"token punctuation\">,</span> y_batch <span class=\"token operator\">=</span> get_batch<span class=\"token punctuation\">(</span>split<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"229\"></td><td><pre>            logits<span class=\"token punctuation\">,</span> loss <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>x_batch<span class=\"token punctuation\">,</span> y_batch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"230\"></td><td><pre>            losses<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> loss<span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"231\"></td><td><pre>        out<span class=\"token punctuation\">[</span>split<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> losses<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"232\"></td><td><pre>    model<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"233\"></td><td><pre>    <span class=\"token keyword\">return</span> out</pre></td></tr><tr><td data-num=\"234\"></td><td><pre></pre></td></tr><tr><td data-num=\"235\"></td><td><pre></pre></td></tr><tr><td data-num=\"236\"></td><td><pre><span class=\"token comment\"># Use AdamW optimizer</span></pre></td></tr><tr><td data-num=\"237\"></td><td><pre>optimizer <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>optim<span class=\"token punctuation\">.</span>AdamW<span class=\"token punctuation\">(</span>params<span class=\"token operator\">=</span>model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span>learning_rate<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"238\"></td><td><pre>tracked_losses <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"239\"></td><td><pre><span class=\"token keyword\">for</span> step <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>max_iters<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"240\"></td><td><pre>    <span class=\"token keyword\">if</span> step <span class=\"token operator\">%</span> eval_iters <span class=\"token operator\">==</span> <span class=\"token number\">0</span> <span class=\"token keyword\">or</span> step <span class=\"token operator\">==</span> max_iters <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"241\"></td><td><pre>        losses <span class=\"token operator\">=</span> estimate_loss<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"242\"></td><td><pre>        tracked_losses<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>losses<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"243\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Step:'</span><span class=\"token punctuation\">,</span> step<span class=\"token punctuation\">,</span> <span class=\"token string\">'Training Loss:'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>losses<span class=\"token punctuation\">[</span><span class=\"token string\">'train'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Validation Loss:'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"244\"></td><td><pre>              <span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>losses<span class=\"token punctuation\">[</span><span class=\"token string\">'valid'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"245\"></td><td><pre></pre></td></tr><tr><td data-num=\"246\"></td><td><pre>    xb<span class=\"token punctuation\">,</span> yb <span class=\"token operator\">=</span> get_batch<span class=\"token punctuation\">(</span><span class=\"token string\">'train'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"247\"></td><td><pre>    logits<span class=\"token punctuation\">,</span> loss <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>xb<span class=\"token punctuation\">,</span> yb<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"248\"></td><td><pre>    optimizer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span>set_to_none<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"249\"></td><td><pre>    loss<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"250\"></td><td><pre>    optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"251\"></td><td><pre></pre></td></tr><tr><td data-num=\"252\"></td><td><pre><span class=\"token comment\"># Save the model state dictionary</span></pre></td></tr><tr><td data-num=\"253\"></td><td><pre>torch<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>state_dict<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'model-ckpt.pt'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"254\"></td><td><pre></pre></td></tr><tr><td data-num=\"255\"></td><td><pre><span class=\"token comment\"># Generate</span></pre></td></tr><tr><td data-num=\"256\"></td><td><pre>model<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"257\"></td><td><pre>start <span class=\"token operator\">=</span> <span class=\"token string\">'The salesperson'</span></pre></td></tr><tr><td data-num=\"258\"></td><td><pre>start_ids <span class=\"token operator\">=</span> encoding<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span>start<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"259\"></td><td><pre>x <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span>start_ids<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">long</span><span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"260\"></td><td><pre>y <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>generate<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> max_new_tokens<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"261\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'---------------'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"262\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>encoding<span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>tolist<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"263\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'---------------'</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure>",
            "tags": [
                "AI"
            ]
        },
        {
            "id": "http://qianqiu-cell.github.io/2024/02/01/AI/Neural_networks_classification/",
            "url": "http://qianqiu-cell.github.io/2024/02/01/AI/Neural_networks_classification/",
            "title": "神经网络大致分类",
            "date_published": "2024-01-31T16:00:00.000Z",
            "content_html": "<p>参考文章：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8yNjg3MDk2MTg=\">https://zhuanlan.zhihu.com/p/268709618</span><br>\n<img data-src=\"/images/AI/Neural_networks_classification/0.1.png\" alt=\"\"></p>\n<h1 id=\"一-mp神经元模型\"><a class=\"markdownIt-Anchor\" href=\"#一-mp神经元模型\">#</a> 一、MP 神经元模型</h1>\n<p>  MP 模型是针对生物神经元的一些基本生理特征所提出的形式神经元的数学模型与结构，其权值被认为是不可调整的。MP 神经元模型是其他神经网络的基础。<br>\n<img data-src=\"/images/AI/Neural_networks_classification/1.1.png\" alt=\"\"></p>\n<h1 id=\"二-前馈神经网络fnn\"><a class=\"markdownIt-Anchor\" href=\"#二-前馈神经网络fnn\">#</a> 二、前馈神经网络（FNN）</h1>\n<p>  对于前馈网络，根据神经元的传递函数不同，以及学习算法和网络结构上的区别，可以细分类感知器网络、线性网络、BP 网络、径向基网络及 GMDH 网络等不同的网络模型。</p>\n<h2 id=\"21-感知器pla\"><a class=\"markdownIt-Anchor\" href=\"#21-感知器pla\">#</a> 2.1 感知器（PLA）</h2>\n<p>  感知器模型（Percetron Learning Algorithm，简称 PLA）是由美国学者 F.Rosenblatt 于 1958 年提出的。它与 MP 模型的不同之处是它假定神经元的突触权值是可变的，这样就可以进行学习。感知器是最简单形式的前馈神经网络，是一种二元线性分类器。<br>\n<img data-src=\"/images/AI/Neural_networks_classification/1.2.png\" alt=\"\"><br>\n  感知器具有如下的局限性：</p>\n<ul>\n<li>感知器神经网络的传输函数一般采用阈值函数，所以输出值只有两种；</li>\n<li>单层感知器网络只能用于解决线性可分的分类问题，而对线性不可分的分类问题无能为力；</li>\n<li>感知器学习算法只适于单层感知器网络，所以一般感知器网络都是单层的。</li>\n</ul>\n<h2 id=\"22-多层感知器mlp\"><a class=\"markdownIt-Anchor\" href=\"#22-多层感知器mlp\">#</a> 2.2 多层感知器（MLP）</h2>\n<p>  多层感知器（Multilayer Perceptron, 简称 MLP）是感知器的推广，克服了感知器不能对线性不可分数据进行识别的弱点。对于非线性函数的模拟，需要采用 MLP，即在最初的输入和输出层之间隐藏着一到多个层。<br>\n  <mark>全连接神经网络（Fully Connected Neural Network，简称 FNN），深度神经网络（ Deep Neural Networks，简称 DNN）和 MLP 的概念相似，只是侧重点不同。一个多层全连接神经网络即使 MLP，又是 FNN，同时也是 DNN。</mark><br>\n  <mark>BP 神经网络是指使用了 BP 算法（ Back Propagation，反向传播）进行训练的 MLP 模型。</mark></p>\n<h2 id=\"23-径向基神经网络rbfnn\"><a class=\"markdownIt-Anchor\" href=\"#23-径向基神经网络rbfnn\">#</a> 2.3 径向基神经网络（RBFNN）</h2>\n<p>参考链接： <span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDgwMjY3Ni9hcnRpY2xlL2RldGFpbHMvMTAwODA1NTQ1\">https://blog.csdn.net/weixin_40802676/article/details/100805545</span><br>\n  首先介绍径向基函数（ Radial Basis Function，简称 RBF）：<br>\n<img data-src=\"/images/AI/Neural_networks_classification/1.3.png\" alt=\"\"><br>\n  最常用的径向基函数是高斯函数（radbas）。<br>\n<img data-src=\"/images/AI/Neural_networks_classification/1.4.png\" alt=\"\"><br>\n  RBFNN 的神经网络节后如上图所示。三层的神经网络就可以拟合任何一个函数，RBFNN 即为三层（单隐层）且隐藏层使用径向基函数的神经网络。因此 RBFNN 完全可以拟合任何一个函数（只要隐藏层神经元足够多）。输入层到隐藏层的神经元之间的权重全部为 1。隐藏层是使用径向基函数作为激活函数的神经元。隐藏层与输出层之间就是普通的神经网络的连接关系，他们之间的权重可以训练而改变。<br>\n  RBFNN 的关键就在于径向基函数的确定，中心点在哪，径基宽度多大，多少个径向基函数，都是会影响神经网络的效果的。广义回归神经网络 (General Regression Neural Network，简称 GRNN) 和广义回归神经网络 (General Regression Neural Network，简称 GPNN) 都是 RBFNN 的变化形式。</p>\n<h2 id=\"24-卷积神经网络cnn\"><a class=\"markdownIt-Anchor\" href=\"#24-卷积神经网络cnn\">#</a> 2.4 卷积神经网络（CNN）</h2>\n<p>  卷积神经网络（Convolutional Neural Networks，简称 CNN）是一种深度学习模型或类似于人工神经网络的多层感知器，常用来分析视觉图像。<br>\n<img data-src=\"/images/AI/Neural_networks_classification/1.5.png\" alt=\"\"><br>\n  一个卷积神经网络主要由以下 5 层组成：</p>\n<ul>\n<li>数据输入层 / Input layer</li>\n<li>卷积计算层 / CONV layer</li>\n<li>ReLU 激励层 / ReLU layer</li>\n<li>池化层     / Pooling layer</li>\n<li>全连接层   / FC layer</li>\n</ul>\n<h2 id=\"25-线性神经网咯\"><a class=\"markdownIt-Anchor\" href=\"#25-线性神经网咯\">#</a> 2.5 线性神经网咯</h2>\n<p>  线性神经网络与感知器的主要区别在于感知器的激活函数只能输出两种可能值（-1 或 1），而线性神经网络的输出可以取任意值，其激活函数是线性函数。<br>\n  线性神经网络采用 Widrow-Hoff 学习规则（最小均方规则），即 LMS（Least Mean Square）算法来调整网络的权值和偏置值。结构图如下。这里使用 purelin 激活函数进行模型训练，这样可以得到一个更好的效果。输出结果的时候还是使用 sign 激活函数。<br>\n<img data-src=\"/images/AI/Neural_networks_classification/1.6.png\" alt=\"\"><br>\n<img data-src=\"/images/AI/Neural_networks_classification/1.7.png\" alt=\"\"></p>\n<h1 id=\"三-反馈神经网络\"><a class=\"markdownIt-Anchor\" href=\"#三-反馈神经网络\">#</a> 三、反馈神经网络</h1>\n<p>  所谓反馈网络是指在网络中至少含有一个反馈回路的神经网络。反馈网络可以包含一个单层神经元，其中每个神经元将自身的输出信号反馈给其他所有神经元的输入 反馈神经网络中神经元不但可以接收其他神经元的信号，而且可以接收自己的反馈信号。和前馈神经网络相比，反馈神经网络中的神经元具有记忆功能，在不同时刻具有不同的状态。反馈神经网络中的信息传播可以是单向也可以是双向传播，因此可以用一个有向循环图或者无向图来表示。</p>\n<h2 id=\"31-循环神经网络rnn\"><a class=\"markdownIt-Anchor\" href=\"#31-循环神经网络rnn\">#</a> 3.1 循环神经网络（RNN）</h2>\n<p>  循环神经网络（Recurrent Neural Network，简称 RNN）是一种深度学习模型，专门用于处理序列数据和具有时间依赖性的任务。相比于传统神经网络，RNN 具有一种递归结构，使其能够对序列信息进行处理。<br>\n  RNN 的主要特点是它能够保持对之前输入信息的记忆，这使得它在处理时间序列、自然语言处理等任务时非常有效。它的基本结构包括一个隐藏层，其中的神经元可以接收输入数据和前一个时间步的隐藏状态，并输出一个新的隐藏状态。这种递归结构使得 RNN 能够捕捉序列中的上下文信息，从而更好地理解和处理序列数据。<br>\n  然而，传统的 RNN 存在梯度消失和梯度爆炸等问题，导致难以捕捉长期依赖关系。为了解决这些问题，一些改进型的循环神经网络被提出，如长短时记忆网络（Long Short-Term Memory，简称 LSTM）和门控循环单元（Gated Recurrent Unit，简称 GRU）。这些改进模型引入了门控机制，使得网络能够更好地处理长期依赖关系，从而提高了性能。<br>\n  总的来说，循环神经网络在处理序列数据方面具有广泛的应用，包括自然语言处理、语音识别、时间序列预测等领域。</p>\n<h2 id=\"32-hopfield神经网络\"><a class=\"markdownIt-Anchor\" href=\"#32-hopfield神经网络\">#</a> 3.2 Hopfield 神经网络</h2>\n<p>  Hopfield 神经网络是一种反馈型的人工神经网络，最初由物理学家约翰・霍普菲尔德（John Hopfield）于 1982 年提出。它主要用于模拟和处理离散型动力系统，尤其在解决优化问题和模式识别方面应用广泛。根据其激活函数的不同，Hopfield 神经网络有两种：离散 Hopfield 网络（Discrete Hopfield Neural Network，简称 DHNN）和连续 Hopfield 网络（Continues Hopfield Neural Network，简称 CHNN）。</p>\n<h1 id=\"四-对抗神经网络gan\"><a class=\"markdownIt-Anchor\" href=\"#四-对抗神经网络gan\">#</a> 四、对抗神经网络（GAN）</h1>\n<p>  简介：对抗神经网络其实是两个网络的组合，可以理解为一个网络生成模拟数据，另一个网络判断生成的数据是真实的还是模拟的。生成模拟数据的网络要不断优化自己让判别的网络判断不出来，判别的网络也要不断优化自己让判断的更加精确。两者的关系形成对抗，因此叫对抗神经网络。<br>\n  结构：GAN 由 generator（生成模型）和 discriminator（判别式模型）两部分构成。二者结合之后，经过大量次数的迭代训练会使 generator 尽可能模拟出以假乱真的样本，而 discrimator 会有更精确的鉴别真伪数据的能力，最终整个 GAN 会达到所谓的纳什均衡，即 discriminator 对于 generator 的数据鉴别结果为正确率和错误率各占 50%。</p>\n<h1 id=\"五-自组织神经网络\"><a class=\"markdownIt-Anchor\" href=\"#五-自组织神经网络\">#</a> 五、自组织神经网络</h1>\n<p>  在生物神经系统中，存在着一种侧抑制现象，即一个神经细胞兴奋以后，会对周围其他神经细胞产生抑制作用。这种抑制作用会使神经细胞之间出现竞争，其结果是某些获胜，而另一些则失败。表现形式是获胜神经细胞兴奋，失败神经细胞抑制。自组织（竞争型）神经网络就是模拟上述生物神经系统功能的人工神经网络。</p>\n<h1 id=\"六-反馈神经网络\"><a class=\"markdownIt-Anchor\" href=\"#六-反馈神经网络\">#</a> 六、反馈神经网络</h1>\n<p>  一般的神经网络模型通常假定网络结构是事先固定的，训练的目的是利用训练样本来确定合适的连接权、阙值等参数。与此不同，结构自适应网络则将网络结构也当作学习的目标之一，并希望能在训练过程中找到最利合数据特点的网络结构</p>\n<h1 id=\"七-反馈神经网络\"><a class=\"markdownIt-Anchor\" href=\"#七-反馈神经网络\">#</a> 七、反馈神经网络</h1>\n<p>  随机神经网络是对神经网络引入随机机制，认为神经元是按照概率的原理进行工作的，这就是说，每个神经元的兴奋或抑制具有随机性，其概率取决于神经元的输入。</p>\n",
            "tags": [
                "AI"
            ]
        }
    ]
}